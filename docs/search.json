[
  {
    "objectID": "42-ANSPA-regress.html",
    "href": "42-ANSPA-regress.html",
    "title": "Régression spatiale",
    "section": "",
    "text": "Cette séance va permettre :\n\nde revoir plus en détail le concept de potentiel en utilisant le package R potential qui en facilite le calcul et la cartographie.\nde revoir les modèles de régression multiple et de régression Poisson en les appliquant à la prédiction du nombre de clubs de sport présents ou absent d’une commune.\nde mélanger des variables explicatives de type endogène (caractéristiques internes de la commune) et exogènes (situation de la commune par rapport aux espaces envrionnants)\n\n\n\n\nL’installation est a priori la même que dans les sessions précédentes. On reprend juste pour mémoire la liste, à l’intention de ceux qui n’auraient pas suivi la séance précédente. On y ajoute un package pour le calcul de potentiel (potential) et un autre pour l’analyse des résultats de régression (car)\n\nlibrary(knitr)\nlibrary(dplyr)\n\nlibrary(sf)\nlibrary(mapsf)\nlibrary(RColorBrewer)\nlibrary(leaflet)\nlibrary(htmlwidgets)\nlibrary(htmltools)\n\nlibrary(ggplot2)\nlibrary(plotly)\n\n\nlibrary(potential)\nlibrary(car)"
  },
  {
    "objectID": "42-ANSPA-regress.html#introduction",
    "href": "42-ANSPA-regress.html#introduction",
    "title": "Régression spatiale",
    "section": "",
    "text": "Cette séance va permettre :\n\nde revoir plus en détail le concept de potentiel en utilisant le package R potential qui en facilite le calcul et la cartographie.\nde revoir les modèles de régression multiple et de régression Poisson en les appliquant à la prédiction du nombre de clubs de sport présents ou absent d’une commune.\nde mélanger des variables explicatives de type endogène (caractéristiques internes de la commune) et exogènes (situation de la commune par rapport aux espaces envrionnants)\n\n\n\n\nL’installation est a priori la même que dans les sessions précédentes. On reprend juste pour mémoire la liste, à l’intention de ceux qui n’auraient pas suivi la séance précédente. On y ajoute un package pour le calcul de potentiel (potential) et un autre pour l’analyse des résultats de régression (car)\n\nlibrary(knitr)\nlibrary(dplyr)\n\nlibrary(sf)\nlibrary(mapsf)\nlibrary(RColorBrewer)\nlibrary(leaflet)\nlibrary(htmlwidgets)\nlibrary(htmltools)\n\nlibrary(ggplot2)\nlibrary(plotly)\n\n\nlibrary(potential)\nlibrary(car)"
  },
  {
    "objectID": "42-ANSPA-regress.html#donnees",
    "href": "42-ANSPA-regress.html#donnees",
    "title": "Régression spatiale",
    "section": "DONNEES",
    "text": "DONNEES\nOn reprend les trois jeux de données précédents en y ajoutant les deux bases de données sur le nombre de licences et le nombre de clubs présents dans chaque commune.\n\n## Contour des communes\ncom&lt;-readRDS(\"ParisPC/mapcom_parisPC.RDS\")\n\n## Population sur grille de 200 m\ngri&lt;-readRDS(\"ParisPC/gridpop_parisPC.RDS\")\n\n## Equipements localisés en latitude longitude\nequ&lt;-readRDS(\"ParisPC/equip_ParisPC.RDS\") \n\n## Nombre de licences\nlic &lt;- readRDS(\"ParisPC/lic2018_ParisPC.RDS\")\n\n## Nombre de clubs\nclu &lt;-readRDS(\"ParisPC/clu2018_ParisPC.RDS\")\n\n\nTableau de variables endogènes\nOn extrait de chaque fichier les informations relatives au sport retenu pour l’analyse et on centralise les résultats dans le fichier communal. On choisit de travailler sur l’exemple du football en prenant comme code de fédération 111 et comme code d’équipement 2802.\n\n# Zone d'étude\ntabcom &lt;- st_drop_geometry(com)\n\n# Extraction des clubs\nmyfede&lt;-c(\"111\")\nmyclu&lt;- clu %&gt;% filter(code_federation %in% myfede) %&gt;%\n                select(insee_com, nbclu =clubs_sportifs_2018)\n\n# Extraction des licences du sport choisi\nmyfede&lt;-c(\"111\")\nmylic&lt;- lic %&gt;% filter(code_fed %in% myfede) %&gt;%\n                group_by(insee_com) %&gt;%\n                summarise(nblic=sum(nblic))\n\n# Extraction du nombre total de licences\nlictot&lt;- lic %&gt;%  group_by(insee_com) %&gt;%\n                  summarise(lictot=sum(nblic))\n\n# Extraction des équipements\ntypequ &lt;- c(\"2802\")\nmyequ &lt;- equ %&gt;% st_drop_geometry() %&gt;%\n                 filter(typ_code %in% typequ) %&gt;%\n                  group_by(insee_com) %&gt;%\n                  summarise(nbequ=n())\n\n# Variables socio-eco\nsoceco&lt;- gri %&gt;% st_drop_geometry() %&gt;%\n                group_by(insee_com) %&gt;%\n                summarise(Ind = sum(Ind),\n                          Men = sum(Men),\n                          Men_pauv = sum(Men_pauv),\n                          Ind_snv = sum(Ind_snv)) %&gt;%\n                mutate(pop = Ind,\n                       men = Men,\n                       txpauv = 100*Men_pauv/Men,\n                       revhab = Ind_snv/Ind) %&gt;%\n                select(insee_com, pop,men, txpauv, revhab)\n  \n\n# Assemblage des tableaux\ntabcom&lt;- tabcom %&gt;% left_join(soceco) %&gt;%\n                    mutate(denpop = pop/sup) %&gt;%\n                    left_join(lictot) %&gt;%\n                    left_join(mylic) %&gt;%\n                    mutate(pctlic = 100*nblic/lictot) %&gt;%\n                    left_join(myclu) %&gt;%  \n                    left_join(myequ) %&gt;%\n                     arrange(insee_com)\n\n# Remplacement des NA par des 0\ntabcom$nbclu[is.na(tabcom$nbclu)]&lt;-0\ntabcom$nblic[is.na(tabcom$nblic)]&lt;-0\ntabcom$nbequ[is.na(tabcom$nbequ)]&lt;-0\n\n# données + fonds de carte\nmapcom &lt;-left_join(com, tabcom)"
  },
  {
    "objectID": "42-ANSPA-regress.html#cartographie",
    "href": "42-ANSPA-regress.html#cartographie",
    "title": "Régression spatiale",
    "section": "CARTOGRAPHIE",
    "text": "CARTOGRAPHIE\nPrenons l’exemple d’une cartographie du nombre de licenciés (stock) et de la part du total des licences (taux).\n\nAvec mapsf\nNormalement vous connaissez toutes les fonctions utilisez. Bien noter le changement de projection de la carte en crs = 2154.\n\nmapcom&lt;-mapcom %&gt;% st_transform(2154)\n\nmapdep&lt;-mapcom %&gt;% group_by(dept) %&gt;% \n                summarise()\n\n# Choix des classes \n    mybreaks&lt;-c(0, 1,2,4,8,16,32,100)\n# Choix de la palette \n    mypal&lt;-brewer.pal(7, \"RdYlBu\")\n\n# Carte de taux (choroplethe)\nmf_map(mapcom, type=\"choro\",\n       var=\"pctlic\",\n       breaks= mybreaks,\n       pal=mypal,\n       border=\"white\",\n       lwd=0.5,\n       leg_title = \"% total licence\",\n       leg_val_rnd = 0,\n       leg_pos = \"topright\")\n\n# Ajout des départements\nmf_map(mapdep, type=\"base\",\n       col=NA,\n       border=\"black\",\n       lwd=1,\n       add=T )\n\n# Carte de stock (proportionelle)\nmf_map(mapcom, typ = \"prop\",\n       var = \"nblic\",\n       inches = 0.05,\n       col=\"gray50\",\n       leg_title = \"nombre de licences\",\n       leg_pos = \"topleft\")\n\n# Cadre, titre, ..\nmf_layout(title = \"Distribution des licences de golf dans Paris PC\",\n          credits = \"Source : INSEE et Min. des Sports\",\n          frame = T,\n          arrow=F,\n          scale=T)\n\n\n\n\n\n\nAvec leaflet\nProgramme plus compliqué … mais qui permet d’aboutir au même résultat avec une carte interactive. Noter que la projection n’est pas modifiée et demeure crs = 4326.\n\nmap&lt;-mapcom %&gt;% select(dept,insee_com, nom_com, nblic, pctlic ) %&gt;% st_transform(4326)\nmap$lng&lt;-st_coordinates(st_centroid(map))[,1]\nmap$lat&lt;-st_coordinates(st_centroid(map))[,2]\n\nmapdep&lt;-mapcom %&gt;% group_by(dept) %&gt;% \n                summarise() %&gt;%\n                st_transform(4326)\n\n\n# Choix de la variable\n   myvar &lt;-map$pctlic\n# Choix des classes \n    mybreaks&lt;-c(0, 1,2,4,8,16,32,100)\n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('RdYlBu', \n                       myvar,\n                       bins=mybreaks)\n  \n# Calcul du diamètre des cercles\n   myradius &lt;-8*sqrt(map$nblic/max(map$nblic, na.rm=T))  \n   \n# Préparation des popups\n      mypopups &lt;- lapply(seq(nrow(map)), function(i) {\n      paste0(  paste(\"Commune               : \",map$nom_com[i]), '&lt;br&gt;',\n               paste(\"Code INSEE           : \" ,map$insee_com[i]), '&lt;br&gt;', \n               paste(\"Nb. de licences        : \" ,map$nblic[i]), '&lt;br&gt;', \n               paste(\"% total licence    :\", round(map$pctlic[i],1))\n            ) \n            })\n      mypopups&lt;-lapply(mypopups, htmltools::HTML)\n\n\n\n\n\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n\n  # Réalisation de la carte choroplèthe\n            addPolygons(data = map,\n                        fillColor = ~mypal(pctlic),\n                        fillOpacity = 0.5,\n                        color = \"white\",\n                        popup = mypopups,\n                        weight = 1,\n                        highlightOptions = highlightOptions(weight = 3, color = 'green')) %&gt;%\n\n  # Ajout de la carte des départements\n              addPolygons(data = mapdep,\n                        fill = FALSE,\n                        color = \"black\",\n                        weight = 2) %&gt;%\n\n  # Ajout de la carte de stocks    \n               addCircleMarkers(data=map,\n                              lat = ~lat,\n                              lng = ~lng,\n                              radius = myradius,\n                              stroke = FALSE,\n                              label = ~nblic,\n                              fillColor = \"gray50\",\n                              fillOpacity = 0.5)%&gt;%\n   \n  # Ajout de la légende \n            addLegend(data = map,\n                      pal = mypal, \n                      title = \"% licences\",\n                      values = ~pctlic, \n                      position = 'topright') \n\n\n\nmap"
  },
  {
    "objectID": "42-ANSPA-regress.html#regression-lineaire",
    "href": "42-ANSPA-regress.html#regression-lineaire",
    "title": "Régression spatiale",
    "section": "REGRESSION LINEAIRE",
    "text": "REGRESSION LINEAIRE\nOn va ici un modèle de régression n’utilisant que des variables endogènes (internes aux communes). On essaye de modéliser Y = % de licences pour le sport considéré\n\nChoix des variables\nAu vu de la carte précédente, on peut penser à plusieurs variables explicatives et faire des hypothèses sur le résultat attendu\n\nX1 : densité de population (relation positive car il faut de la place pour installer un terrain de football)\nX2 : revenu moyen par habitant (relation négative car les riches pratiquent plutôt des sports d’élites ce qui n’est pas le cas du football)\nX3 : % de ménages pauvres (relation positive car le football est considéré à tort ou à raison comme un outil de promotion sociale)\n\nOn crée un tableau avec Y, X1, X2, X3\n\ndon&lt;-tabcom %&gt;% select(insee_com, nom_com, Y=pctlic, X1=denpop, X2=revhab,X3=txpauv)\nhead(don)\n\n  insee_com                  nom_com        Y        X1       X2       X3\n1     75101 PARIS-1ER-ARRONDISSEMENT 1.703085  8391.209 38433.52 13.23255\n2     75102  PARIS-2E-ARRONDISSEMENT 5.564024 21350.505 34985.14 15.00129\n3     75103  PARIS-3E-ARRONDISSEMENT 3.400690 30778.632 36195.03 13.99706\n4     75104  PARIS-4E-ARRONDISSEMENT 4.714971 15908.750 36304.64 13.55867\n5     75105  PARIS-5E-ARRONDISSEMENT 3.075031 19597.619 37720.86 13.18044\n6     75106  PARIS-6E-ARRONDISSEMENT 4.521818 16633.721 43607.03 12.49411\n\n\n\n\nAnalyse des corrélations\nOn analyse la matrice de corrélation :\n\ncor(don[,3:6])\n\n            Y          X1         X2          X3\nY   1.0000000 -0.35258137 -0.8156021  0.72652758\nX1 -0.3525814  1.00000000  0.2526739  0.04524385\nX2 -0.8156021  0.25267387  1.0000000 -0.72002742\nX3  0.7265276  0.04524385 -0.7200274  1.00000000\n\n\nOn vérifie la forme des relations et on teste leur significativité\n\nDensité de population\n\n\nscatterplot(don$X1,don$Y)\n\n\n\ncor.test(don$X1,don$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$X1 and don$Y\nt = -4.474, df = 141, p-value = 0.00001569\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.4884600 -0.2000084\nsample estimates:\n       cor \n-0.3525814 \n\n\n\nRichesse par habitant\n\n\nscatterplot(don$X2,don$Y)\n\n\n\ncor.test(don$X2,don$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$X2 and don$Y\nt = -16.738, df = 141, p-value &lt; 0.00000000000000022\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8640692 -0.7521516\nsample estimates:\n       cor \n-0.8156021 \n\n\n\n% ménages pauvres\n\n\nscatterplot(don$X3,don$Y)\n\n\n\ncor.test(don$X3,don$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$X3 and don$Y\nt = 12.555, df = 141, p-value &lt; 0.00000000000000022\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6385290 0.7957734\nsample estimates:\n      cor \n0.7265276 \n\n\nToutes les variables affichent des corrélations linéaires significatives ! Mais on note que la forme des relations n’est pas forcément linéaire. On y reviendra …\n\n\nModélé additif\nOn teste le modèle additif suivant\n\\(Y = a_0+a_1.X_1+a_2.X_2+a_3.X_3+ \\epsilon\\)\n\nmodlin&lt;-lm(Y ~ X1 + X2 + X3, data=don)\nsummary(modlin)\n\n\nCall:\nlm(formula = Y ~ X1 + X2 + X3, data = don)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.7420 -1.9405 -0.2735  1.5522 12.0714 \n\nCoefficients:\n               Estimate  Std. Error t value             Pr(&gt;|t|)    \n(Intercept) 19.59836228  2.06344477   9.498 &lt; 0.0000000000000002 ***\nX1          -0.00020419  0.00003642  -5.607       0.000000107254 ***\nX2          -0.00039364  0.00005677  -6.934       0.000000000141 ***\nX3           0.35444421  0.05503644   6.440       0.000000001810 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.117 on 139 degrees of freedom\nMultiple R-squared:  0.7598,    Adjusted R-squared:  0.7546 \nF-statistic: 146.6 on 3 and 139 DF,  p-value: &lt; 0.00000000000000022\n\nanova(modlin)\n\nAnalysis of Variance Table\n\nResponse: Y\n           Df Sum Sq Mean Sq F value                Pr(&gt;F)    \nX1          1  699.1   699.1  71.940   0.00000000000002938 ***\nX2          1 3170.6  3170.6 326.279 &lt; 0.00000000000000022 ***\nX3          1  403.0   403.0  41.476   0.00000000180962499 ***\nResiduals 139 1350.7     9.7                                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nConclusion : toutes les variables sont significatives et affichent les signes attendus. L’analyse de variance montre cependant que c’est la variable X2 (revenu par habitant) qui est la plus déterminante. La qualité de l’ajustement est élevée (r2 = 76%)\n\n\n\nModèle multiplicatif\nEssayons maintenant un modèle multiplicatif de la forme\n\\(log(Y) = a_0+a_1.X_1+a_2.X_2+a_3.X_3+ \\epsilon\\)\nqui correspond à une forme multiplicative de l’effet des variables puisque l’on a :\n\\(Y = exp(a_0+a_1.X_1+a_2.X_2+a_3.X_3+ \\epsilon)\\)\net donc :\n\\(Y = exp(a_0).exp(a_1.X_1).exp(a_2.X_2).exp(a_3.X_3)\\)\n\nmodexp&lt;-lm(log(Y) ~ X1 + X2 + X3, data=don)\nsummary(modexp)\n\n\nCall:\nlm(formula = log(Y) ~ X1 + X2 + X3, data = don)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.2206 -0.1266  0.0045  0.1464  0.5606 \n\nCoefficients:\n                Estimate   Std. Error t value             Pr(&gt;|t|)    \n(Intercept)  3.817787144  0.157533985  24.235 &lt; 0.0000000000000002 ***\nX1          -0.000012995  0.000002781  -4.673           0.00000692 ***\nX2          -0.000053438  0.000004334 -12.330 &lt; 0.0000000000000002 ***\nX3           0.007414592  0.004201765   1.765               0.0798 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.238 on 139 degrees of freedom\nMultiple R-squared:  0.7949,    Adjusted R-squared:  0.7905 \nF-statistic: 179.6 on 3 and 139 DF,  p-value: &lt; 0.00000000000000022\n\n\n\nConclusion : Pas de différences dans le signe des coefficients et leur significativité. Mais la qualité de l’ajustement est plus élevée (r2 = 79%) ce qui signifie que le modèle multiplicatif décrit plus fidèlement les effets constatés."
  },
  {
    "objectID": "42-ANSPA-regress.html#potentiels",
    "href": "42-ANSPA-regress.html#potentiels",
    "title": "Régression spatiale",
    "section": "POTENTIELS",
    "text": "POTENTIELS\nOn va maintenant utiliser le package potential pour créer des variables de type exogène mesurant la distribution des indicateurs non pas dans la commune mais dans le voisinage de celle-ci.\n\nPotentiel d’équipement\n\n# Extraction des équipements et projection 2154\ntypequ &lt;- c(\"2802\")\nmyequ &lt;- equ %&gt;%filter(typ_code %in% typequ) %&gt;%\n                  mutate(nb = 1) %&gt;%\n                  st_transform(2154)\n\n# projection des communes en 2154\nmapcom &lt;- mapcom %&gt;% st_transform(2154)\n\n# Distance communes-équipement\ndist&lt;-create_matrix(myequ,mapcom)\n\n# calcul du potentiel\nmapcom$pot_equ_2000&lt;-potential(x=myequ,   # Ressources\n                               y=mapcom,  # Population\n                               d=dist,    # Distance population x Ressources\n                               var = \"nb\", # Quantité de ressource\n                               fun=\"e\",    # famille exponentielle\n                               span = 2000, # distance ou f(Dij) = 0.5\n                               beta=2)      # Exposant de la distance\n\n\n# Cartographie du résultat\nmf_map(mapcom, type=\"choro\",var=\"pot_equ_2000\")\nmf_map(myequ, type=\"base\",add=T,col=\"red\")\n\n\n\n\n\nCommentaire : La carte montre que les arrondissements du centre de Paris qui ne disposent pas de terrain de football ont cependant un potentiel d’acès à ceux-ci dans un voisinage gaussien de 2 km.\n\n\n\nPotentiel de licences\n\n# Extraction des licences projection 2154\nmaplic&lt;-mapcom%&gt;% select(nblic) %&gt;%st_transform(2154)\n\n# projection des communes en 2154\nmapcom &lt;- mapcom %&gt;% st_transform(2154)\n\n# Distance communes-équipement\ndist&lt;-create_matrix(maplic,mapcom)\n\n# calcul du potentiel\nmapcom$pot_lic_2000&lt;-potential(x=maplic,y=mapcom,d=dist,var = \"nblic\", fun=\"e\",span = 2000,beta=2)\n\n# Cartographie du résultat\nmf_map(mapcom, type=\"choro\",var=\"pot_lic_2000\")\nmf_map(maplic, type=\"prop\",var=\"nblic\",col=\"red\", inches=0.05)\n\n\n\n\n\nCommentaire : La carte montre que le potentiel de sportifs ayant une licence de football est maximale dans les arrondissements périphériques de Paris et dans la banlieue Nord."
  },
  {
    "objectID": "42-ANSPA-regress.html#regression-de-poisson",
    "href": "42-ANSPA-regress.html#regression-de-poisson",
    "title": "Régression spatiale",
    "section": "REGRESSION DE POISSON",
    "text": "REGRESSION DE POISSON\nOn va construire un modèle de régression de Poisson pour prévoir le potentiel de clubs du potentiel d’équipement et de son potentiel de licence.\n\nChoix des variables\nLe tableau comporte uniquement des stocks et des potentiels\nY : nombre de clubs X1a : nombre d’équipements dans la commune X1b : potentiel d’équipement dans un voisinage gaussien de 2.5km X2a : nombre de joueurs ayant une licence dans la commune X2b : potentiel de joueurs ayant une licence dans un voisinage gaussien de 2.5km\nOn crée un tableau avec Y, X1a, X1b X2a,X2b\n\ndon&lt;-mapcom %&gt;% select(insee_com, nom_com, \n                       Y=nbclu, \n                       X1a = nbequ,\n                       X1b = pot_equ_2000, \n                       X2a = nblic,\n                       X2b = pot_lic_2000) %&gt;%\n  st_drop_geometry()\nhead(don)\n\n  insee_com                  nom_com  Y X1a       X1b  X2a       X2b\n1     75119 PARIS-19E-ARRONDISSEMENT 17   3 37.262588 2162 22122.189\n2     75106  PARIS-6E-ARRONDISSEMENT  5   0  6.116627  400 14617.246\n3     93071                   SEVRAN  3  13 47.018154 1190 10356.941\n4     94056                  PERIGNY  2   1  5.746092   84   814.633\n5     94041           IVRY-SUR-SEINE  5  10 38.133234 1305 17336.098\n6     75112 PARIS-12E-ARRONDISSEMENT 14  29 65.061731 1393 28111.675\n\n\n\n\nAnalyse des corrélations\nOn analyse la matrice de corrélation :\n\ncor(don[,3:7])\n\n            Y       X1a       X1b       X2a       X2b\nY   1.0000000 0.4315624 0.2416476 0.7516748 0.5794876\nX1a 0.4315624 1.0000000 0.6279578 0.5791498 0.2387389\nX1b 0.2416476 0.6279578 1.0000000 0.5980269 0.4025822\nX2a 0.7516748 0.5791498 0.5980269 1.0000000 0.5992941\nX2b 0.5794876 0.2387389 0.4025822 0.5992941 1.0000000\n\n\nOn vérifie la forme des relations et on teste leur significativité\n\nEquipement de la commune\n\n\nscatterplot(don$X1a,don$Y)\n\n\n\ncor.test(don$X1a,don$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$X1a and don$Y\nt = 5.6808, df = 141, p-value = 0.00000007394\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2878018 0.5563023\nsample estimates:\n      cor \n0.4315624 \n\n\n\nPotentiel d’équipement dans le voisinage de la commune\n\n\nscatterplot(don$X1b,don$Y)\n\n\n\ncor.test(don$X1b,don$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$X1b and don$Y\nt = 2.957, df = 141, p-value = 0.003643\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.08070004 0.39031390\nsample estimates:\n      cor \n0.2416476 \n\n\n\nNombre de licences dans la commune\n\n\nscatterplot(don$X2a,don$Y)\n\n\n\ncor.test(don$X2a,don$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$X2a and don$Y\nt = 13.533, df = 141, p-value &lt; 0.00000000000000022\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6702226 0.8152346\nsample estimates:\n      cor \n0.7516748 \n\n\n\nPotentiel de licences dans le voisinage de la commune\n\n\nscatterplot(don$X2b,don$Y)\n\n\n\ncor.test(don$X2b,don$Y)\n\n\n    Pearson's product-moment correlation\n\ndata:  don$X2b and don$Y\nt = 8.4432, df = 141, p-value = 0.00000000000003385\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4590001 0.6790441\nsample estimates:\n      cor \n0.5794876 \n\n\n\n\nModèle\nOn teste le modèle suivant :\n\\(Y = exp(\\alpha+\\beta_{1a}.X_{1a}+\\beta_{1b}.X_{1b}+\\beta_{2a}.X_{2a}+\\beta_{2b}.X_{2b} +\\epsilon)\\)\nOn emploie une régression de Poisson car le nombre de clubs est une variable quantitative discrète composée d’entier. On suppose qu’elle obéit à une loi de Poisson et on vérifie si c’est exact en comparant la moyenne et l’écart-type de Y.\n\nmean(don$Y)\n\n[1] 3.79021\n\nsd(don$Y)\n\n[1] 3.711143\n\n\nDes tests plus précis pourraient être utilisés mais dans le cas présent on voit que les deux valeurs sont très proche et qu’il est acceptable de considérer que le nombre de club obéit bien à une loi de Poisson.\n\nmodpoi&lt;-glm(Y ~ X1a + X1b + X2a + X2b, data=don, family=\"poisson\")\nsummary(modpoi)\n\n\nCall:\nglm(formula = Y ~ X1a + X1b + X2a + X2b, family = \"poisson\", \n    data = don)\n\nCoefficients:\n               Estimate  Std. Error z value             Pr(&gt;|z|)    \n(Intercept)  0.25253750  0.16302149   1.549             0.121356    \nX1a          0.03330562  0.00952547   3.496             0.000471 ***\nX1b         -0.02185387  0.00406491  -5.376         0.0000000761 ***\nX2a          0.00086511  0.00008965   9.650 &lt; 0.0000000000000002 ***\nX2b          0.00005579  0.00001095   5.096         0.0000003464 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 417.02  on 142  degrees of freedom\nResidual deviance: 121.44  on 138  degrees of freedom\nAIC: 534.46\n\nNumber of Fisher Scoring iterations: 5\n\nAnova(modpoi,type=\"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Y\n    LR Chisq Df            Pr(&gt;Chisq)    \nX1a   11.676  1             0.0006331 ***\nX1b   29.632  1         0.00000005223 ***\nX2a   94.633  1 &lt; 0.00000000000000022 ***\nX2b   25.540  1         0.00000043329 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nDiscussion\nLes quatre facteurs conditionnent bien l’apparition des clubs de football dans les communes et sont tous significatifs. Le nombre de terrain de football dans la commune a un effet positif sur l’apparition d’un ou plusieurs club dans la commune ce qui parait logique. Par contre la quantité de terrains de football dans les communes voisines a un effet négatif ce qui peut se comprendre comme un effet de concurrence. Quant au nombre de personnes détenant une licence, il a un effet positif à la fois dans la commune et dans les communes voisines.\nLa régression de Poisson n’offre pas directement de qualité d’ajustement comme dans le cas de la régression par la méthode des moindres carrés ordinaires. On peut néanmoins calculer un pseudo-R2 dit de Mc Fadden en calculant la part de déviance expliquée c’est-à-dire en effectuant le calcul suivant :\n\\(R^2_{McFadden} = \\frac{NullDeviance-ResidualDeviance}{NullDeviance}\\)\n\n(417.02-121.44)/(417.02)\n\n[1] 0.7087909\n\n\nDans notre exemple on trouve un \\(R^2\\) de Mc Fadden d’environ 71% ce qui est très satisfaisant et montre que la connaissance de la localisation des terrains et des licences permet dans une large mesure de prédire le nombre de clubs présents dans une commune."
  },
  {
    "objectID": "42-ANSPA-regress.html#prolongements",
    "href": "42-ANSPA-regress.html#prolongements",
    "title": "Régression spatiale",
    "section": "PROLONGEMENTS",
    "text": "PROLONGEMENTS\nPour en savoir plus sur les modèles de régression, le plus simple est de partir du petit billet introduction au GLM de Claire Della Vedova qui explique bien la différence entre le modèle linéaire classique et les modèles de régression logistique ou de régression de Poisson.\nEnsuite … il faudra s’attaquer à un bon manuel de statistiques. Nous recommandons celui de Daniel J. Denis Univariate, Bivariate Multivariate Statistics using R qui est très pédagogique et fournit les programmes d’application en R ou en Python."
  },
  {
    "objectID": "11-API-OPENDATASOFT.html",
    "href": "11-API-OPENDATASOFT.html",
    "title": "Pratique des API",
    "section": "",
    "text": "Le but de ce chapitre n’est pas d’apprendre en détail l’ensemble des possibilités qu’offrent les API pour des utilisateurs avancés, mais de fournir aux étudiants en data mining un certain nombre de solutions simples (mais efficaces) pour extraire des données de façon interactive et assurer leur mise à jour régulière.\nOn charge les packages utiles :\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(httr)\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(dplyr, warn.conflicts = T, quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#choix-dune-api",
    "href": "11-API-OPENDATASOFT.html#choix-dune-api",
    "title": "Pratique des API",
    "section": "Choix d’une API",
    "text": "Choix d’une API\nLa première étape consiste à choisir l’API qui nous intéresse parmi plus de 600.\n\nLe site public.opendatasoft\nNous allons centrer notre chapitre sur le site public.opendatasoft qui permet d’accèder à des centaines d’API à l’aide de requêtes normalisées. Sans apprendre en détail le fonctionnement de cette API, on va montrer comment créer de petites fonctions facilitant le travail d’exportation des variables ou des données.\nOn peut se rendre sur le site pour parcourir les API proposées en allant à l’adresse : https://public.opendatasoft.com\n\n\n\n\n\n\n\nCatalogue des API\nPlutôt que de pacourir le site web, on peut télécharger le catalogue général des bases de données du site public.opendatasoft … en se servant d’une requête API\n\nx&lt;-GET('https://public.opendatasoft.com/api/datasets/1.0/search/?q=&rows=1000&start=0')\ny&lt;-fromJSON(rawToChar((x$content)))\ncat&lt;-y$datasets$metas\nrow.names(cat)&lt;-y$datasets$datasetid\nkable(head(cat[,c(12,1,6,7,8)]),row.names = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\nlicense_url\ndomain\nlicense\ndescription\npublisher\n\n\n\n\nanalytical-house-prices-indicators\n\npublic\nCustom License (see reference link)\n\nOECD\n\n\nsirene-v3-liens-de-successions-siret\nhttps://www.etalab.gouv.fr/wp-content/uploads/2018/11/open-licence.pdf\npublic\nOpen License v2.0\n\nINSEE\n\n\nregionales-2015-1tour-communes\nhttps://www.etalab.gouv.fr/wp-content/uploads/2014/05/Licence_Ouverte.pdf\npublic\nOpen License v1.0\nRésultats du 1er tour des élections régionales, de l’Assemblée de Corse et des assemblées de Guyane et de Martinique du 6 décembre 2015 par communes. Résultats de la soirée électorale, sous réserve de corrections éventuelles des commissions de recensement.\nMinistère de l’Intérieur\n\n\ndecred\nNA\npublic\nMIT License\nDaily cryptocurrency data (transaction count, on-chain transaction volume, value of created coins, price, market cap, and exchange volume) in CSV format. The data sample stretches back to December 2013. Daily on-chain transaction volume is calculated as the sum of all transaction outputs belonging to the blocks mined on the given day. “Change” outputs are not included. Transaction count figure doesn’t include coinbase transactions. Zcash figures for on-chain volume and transaction count reflect data collected for transparent transactions only. In the last month, 10.5% (11/18/17) of ZEC transactions were shielded, and these are excluded from the analysis due to their private nature. Thus transaction volume figures in reality are higher than the estimate presented here, and NVT and exchange to transaction value lower. Data on shielded and transparent transactions can be found here and here. Decred data doesn’t include tickets and voting transactions. Monero transaction volume is impossible to calculate due to RingCT which hides transaction amounts.\nhttps://coinmetrics.io\n\n\nlinked-open-vocabularies-classes\nhttps://creativecommons.org/licenses/by/4.0/\npublic\nCC BY 4.0\n\nOntology Engineering Group - UPM\n\n\ngeoref-switzerland-bezirk-millesime\nhttps://opendata.swiss/en/terms-of-use/#terms_by_ask\npublic\nOpendata.swiss BY ASK\n\nOpendatasoft\n\n\n\n\n\nOn a donc récupéré un tableau qui comporte 605 lignes correspondant à 605 bases de données. Le nom des lignes du tableau indique le code de la base de données que l’on va utiliser ensuite dans les requêtes.\n\n\nChoix d’un tableau de données\nOn suppose que le choix s’est porté sur la base de données dont le nom de code est prix-des-carburants-j-1\n\n\n\n\n\nL’onglet information nous indique qu’il s’agit d’un site produit par le minstère de l’économie et des finances pour faciliter l’accès en temps réel au prix des carburants dans les stations services. Le but est d’informer les conosmmateurs des stations les moins chères à proximité de son domicile afin de stimuler la concurrence et faire baisser les prix.\nIl est indiqué que la base se limite aux prix des douze derniers mois mais nous avons pu vérifier qu’on trouve en fait des données sur plus de trois ans.\n\n\nListe des variables\nAvant de télécharger les données, on regarde précisément la liste des variables disponibles. On peut le faire sur le site web en parcourant les onglets. Mais il est également possible de lancer une requête pour connaître les variables du tableau que l’on va télécharger ainsi que les variables pouvant servir de “facettes” c’est-à-dire permettant d’effectuer des requêtes.\n\ntab&lt;-\"prix-des-carburants-j-1\"\nurl&lt;-paste(\"https://public.opendatasoft.com/api/v2/catalog/datasets/\",tab,\"?\",sep=\"\")\nx&lt;-GET(url)\ny&lt;-fromJSON(rawToChar(x$content))\nvar&lt;-y$dataset$fields\n\nhead(var)\n\n            name description annotations.facet annotations.multivalued\n1             id          NA                NA                    &lt;NA&gt;\n2             cp          NA              TRUE                    &lt;NA&gt;\n3            pop          NA              TRUE                    &lt;NA&gt;\n4        address          NA                NA                    &lt;NA&gt;\n5   com_arm_name          NA              TRUE                    &lt;NA&gt;\n6 automate_24_24          NA              TRUE                    &lt;NA&gt;\n  annotations.facetsort annotations.timeserie_precision annotations.unit\n1                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n2                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n3                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n4                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n5                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n6                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n  annotations.decimals\n1                   NA\n2                   NA\n3                   NA\n4                   NA\n5                   NA\n6                   NA\n                                                      label type\n1                                               Identifiant text\n2                                               Code Postal text\n3                                                  Présence text\n4                                                   Adresse text\n5 Nom Officiel Commune / Arrondissement Municipal Majuscule text\n6                                            Automate 24-24 text\n\n\nOn extrait du tableau les colonnes qui fournissent le nom des variables, leur définition et leur type\n\nvar &lt;- var  %&gt;% select(name, label, type)\nkable(var)\n\n\n\n\n\n\n\n\n\nname\nlabel\ntype\n\n\n\n\nid\nIdentifiant\ntext\n\n\ncp\nCode Postal\ntext\n\n\npop\nPrésence\ntext\n\n\naddress\nAdresse\ntext\n\n\ncom_arm_name\nNom Officiel Commune / Arrondissement Municipal Majuscule\ntext\n\n\nautomate_24_24\nAutomate 24-24\ntext\n\n\ntimetable\nTimetable\ntext\n\n\nfuel\nCarburant\ntext\n\n\nshortage\nRupture\ntext\n\n\nupdate\nMise à jour\ndatetime\n\n\nprice_gazole\nPrix Gazole\ndouble\n\n\nprice_sp95\nPrix SP95\ndouble\n\n\nprice_sp98\nPrix SP98\ndouble\n\n\nprice_gplc\nPrix GPLc\ndouble\n\n\nprice_e10\nPrix E10\ndouble\n\n\nprice_e85\nPrix E85\ndouble\n\n\nservices\nServices\ntext\n\n\nbrand\nMarque\ntext\n\n\nname\nNom\ntext\n\n\ngeo_point\nGeo Point\ngeo_point_2d\n\n\ncom_arm_code\nCode officiel commune ou arrondissement\ntext\n\n\nepci_code\nCode Officiel EPCI\ntext\n\n\nepci_name\nNom Officiel EPCI\ntext\n\n\ndep_code\nCode Officiel Département\ntext\n\n\ndep_name\nNom Officiel Département\ntext\n\n\nreg_code\nCode Officiel Région\ntext\n\n\nreg_name\nNom Officiel Région\ntext\n\n\n\n\n\nOn peut transformer le programme que l’on vient d’executer en fonction pour un usage plus simple :\n\nget_variables&lt;-function(idtab = \"prix-des-carburants-j-1\") {\n  url&lt;-paste(\"https://public.opendatasoft.com/api/v2/catalog/datasets/\",idtab,\"?\",sep=\"\")\n  x&lt;-GET(url)\n  y&lt;-fromJSON(rawToChar((x$content)))\n  var&lt;-y$dataset$fields\n  var &lt;- var %&gt;% select(name, label, type)\n  return(var)\n}\n\nOn peut désormais appliquer notre fonction sur n’importe quel autre tableau du catalogue. Par exemple, si on choisit le tableau qualite_de-lair-france on obtient la liste de variables suivante :\n\nvar&lt;-get_variables(\"qualite-de-lair-france\")\nkable(var)\n\n\n\n\nname\nlabel\ntype\n\n\n\n\ncountry\nCountry Code\ntext\n\n\ncity\nCity\ntext\n\n\nlocation\nLocation\ntext\n\n\ncoordinates\nCoordinates\ngeo_point_2d\n\n\nmeasurements_parameter\nPollutant\ntext\n\n\nmeasurements_sourcename\nSource Name\ntext\n\n\nmeasurements_unit\nUnit\ntext\n\n\nmeasurements_value\nValue\ndouble\n\n\nmeasurements_lastupdated\nLast Updated\ndatetime\n\n\ncountry_name_en\nCountry Label\ntext"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#récupération-des-données",
    "href": "11-API-OPENDATASOFT.html#récupération-des-données",
    "title": "Pratique des API",
    "section": "Récupération des données",
    "text": "Récupération des données\nPour des utilisateurs non spécialiste, il est difficile de lancer une requête complexe qui suppose une maîtrise avancée des API et des protocoles de requête SOAP et REST. Nous allons opter ici pour une stratégie pragmatique (mais efficace) qui consiste à :\n\nUtiliser l’interface public.opendatasoft pour rédiger une requête\nRécupérer le lien de téléchargement\nTélécharger les données correspondant à la requête\nEffectuer les opérations de nettoyage des données et réaliser un graphique\nModifier le lien et effectuer à nouveau le étapes 3 et 4\nConstruire une fonction paramétrique de téléchargement + nettoyage + visualisation …\n\nPour illustrer cette stratégie, nous allons essayer de créer dans R une fonction automatisée qui télécharge le prix du carburant d’une commune et produit un graphique montrant son évolution au cours du temps dans les dfférentes stations. Nous allons ainsi essayer de reconstituer une application assez proche de celle du ministère de l’économie intitulée “essence pas cher”.\n\n\n\nEssence pas cher\n\n\nNous ne chercherons toutefois pas à obtenir uniquement le dernier prix en date des stations mais plutôt à voir lesquelles sont les plus ou les mons chers sur une période de quelques années.\n\n1. Rédaction d’une requête sur public opendatasoft\nOn utilise les filtres de l’interface pour sélectionner la commune cible à l’aide de son code postal (ex. 94370 = Sucy-en-Brie) et du type carburant (ex. Gazole) :\n\n\n\nFiltres\n\n\n\n\n2. Récupération du lien de téléchargement\nUne fois terminée la mise en place des filtres, on se déplace vers la fenêtre “Export” et on choisit le type de format de sortie que l’on souhaite obtenir. Nous pourrions obtenir des fichiers au format texte (.csv) ou tableur (.xls) mais nous allons adopter ici le format .json qui est plus universel dans le domaine de la data science et qui simplifie les transferts de données entre utilisateurs de différents langages de programmation tels que R ou Python.\nUn click de souris sur le lien nous permet de récupérer l’URL de téléchargement :\n\n\n\nURL\n\n\nMême si certains caractères spéciaux sont difficiles à comprendre comme %3A ou %22 on devine assez facilement la fonction des différents segments de la chaine de caractère qui constitue l’URL de requête :\n\nadresse du site web opendatasoft : https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/\nchoix de la base de données : prix-des-carburants-j-1\nformat d’export et langue : exports/json?lang=fr\nselection du carburant : &refine=fuel%3A%22Gazole%22\nselection de la commune par son code postal : &qv1=(94370)\nfuseau horaire (pour dater la requête) : &timezone=Europe%2FParis\n\n\n\n3. Recupération des données à partir de l’URL\nNous pouvons maintenant rédiger un petit programme très simple qui va récupérer les données à partir de ce lien\n\nlink&lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(94370)&timezone=Europe%2FParis\"\ny&lt;-fromJSON(link)\nhead(y)\n\n        id    cp pop                     address com_arm_name automate_24_24\n1 94370003 94370   R              1 Rue de Paris SUCY-EN-BRIE            Oui\n2 94370003 94370   R              1 Rue de Paris SUCY-EN-BRIE            Oui\n3 94370007 94370   R     13 Rue Maurice Berteaux SUCY-EN-BRIE            Non\n4 94370007 94370   R     13 Rue Maurice Berteaux SUCY-EN-BRIE            Non\n5 94370008 94370   R 63/71 AV DU GENERAL LECLERC SUCY-EN-BRIE            Oui\n6 94370003 94370   R              1 Rue de Paris SUCY-EN-BRIE            Oui\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               timetable\n1                                                                                                                                                                                                                                                                                                                     {\"Dimanche\": {\"ouvert\": 1}, \"Jeudi\": {\"ouvert\": 1}, \"Lundi\": {\"ouvert\": 1}, \"Mardi\": {\"ouvert\": 1}, \"Mercredi\": {\"ouvert\": 1}, \"Samedi\": {\"ouvert\": 1}, \"Vendredi\": {\"ouvert\": 1}}\n2                                                                                                                                                                                                                                                                                                                     {\"Dimanche\": {\"ouvert\": 1}, \"Jeudi\": {\"ouvert\": 1}, \"Lundi\": {\"ouvert\": 1}, \"Mardi\": {\"ouvert\": 1}, \"Mercredi\": {\"ouvert\": 1}, \"Samedi\": {\"ouvert\": 1}, \"Vendredi\": {\"ouvert\": 1}}\n3 {\"Dimanche\": {\"fermeture\": \"22.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Jeudi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Lundi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Mardi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Mercredi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Samedi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Vendredi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}}\n4 {\"Dimanche\": {\"fermeture\": \"22.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Jeudi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Lundi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Mardi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Mercredi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Samedi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Vendredi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}}\n5 {\"Dimanche\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Jeudi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Lundi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mardi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mercredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Samedi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Vendredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}}\n6                                                                                                                                                                                                                                                                                                                     {\"Dimanche\": {\"ouvert\": 1}, \"Jeudi\": {\"ouvert\": 1}, \"Lundi\": {\"ouvert\": 1}, \"Mardi\": {\"ouvert\": 1}, \"Mercredi\": {\"ouvert\": 1}, \"Samedi\": {\"ouvert\": 1}, \"Vendredi\": {\"ouvert\": 1}}\n               fuel              shortage                    update\n1 Gazole, E10, SP98                  SP95 2022-01-10T06:17:00+01:00\n2 Gazole, E10, SP98                  SP95 2022-01-19T06:16:00+01:00\n3            Gazole E85, SP95, GPLc, SP95 2022-02-26T07:53:28+01:00\n4 Gazole, E10, SP98 E85, SP95, GPLc, SP95 2022-03-08T06:54:26+01:00\n5 Gazole, E10, SP98       SP95, GPLc, E85 2022-02-09T00:01:00+01:00\n6 Gazole, E10, SP98                  SP95 2021-03-09T06:03:00+01:00\n  price_gazole price_sp95 price_sp98 price_gplc price_e10 price_e85\n1        1.618         NA      1.745         NA     1.668        NA\n2        1.646         NA      1.763         NA     1.687        NA\n3        1.817         NA      1.985         NA     1.875        NA\n4        2.119         NA      2.147         NA     2.037        NA\n5        1.705         NA      1.839         NA     1.729        NA\n6        1.385         NA      1.537         NA     1.463        NA\n                                                                                                                                                                                                                              services\n1                                                                                                                                                                                                                                 NULL\n2                                                                                                                                                                                                                                 NULL\n3 Restauration à emporter, Carburant additivé, Boutique alimentaire, Station de gonflage, Boutique non alimentaire, Vente de gaz domestique (Butane, Propane), Lavage automatique, Vente de fioul domestique, Wifi, Automate CB 24, 24\n4 Restauration à emporter, Carburant additivé, Boutique alimentaire, Station de gonflage, Boutique non alimentaire, Vente de gaz domestique (Butane, Propane), Lavage automatique, Vente de fioul domestique, Wifi, Automate CB 24, 24\n5                     Carburant additivé, Boutique alimentaire, Station de gonflage, Boutique non alimentaire, Vente de gaz domestique (Butane, Propane), DAB (Distributeur automatique de billets), Lavage automatique, Lavage manuel\n6                                                                                                                                                                                                                                 NULL\n         brand              name geo_point.lon geo_point.lat com_arm_code\n1 Esso Express ESSO PETIT MARAIS       2.49956      48.77306        94071\n2 Esso Express ESSO PETIT MARAIS       2.49956      48.77306        94071\n3        Total       SARL DURMUS       2.51743      48.77333        94071\n4        Total       SARL DURMUS       2.51743      48.77333        94071\n5         &lt;NA&gt;              &lt;NA&gt;            NA            NA         &lt;NA&gt;\n6 Esso Express ESSO PETIT MARAIS       2.49956      48.77306        94071\n  epci_code                epci_name dep_code     dep_name reg_code\n1 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n2 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n3 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n4 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n5      &lt;NA&gt;                     &lt;NA&gt;     &lt;NA&gt;         &lt;NA&gt;     &lt;NA&gt;\n6 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n       reg_name\n1 Île-de-France\n2 Île-de-France\n3 Île-de-France\n4 Île-de-France\n5          &lt;NA&gt;\n6 Île-de-France\n\n\nA la différence de la méthode GET vue au chapitre précédent, nous récupérons directement le fichier de données sans avoir besoin d’effectuer des transformations de type RawToChar. C’est donc beaucoup plus simple mais, en contrepartie, nous perdons toute une série d’informations qu’apportait la procédure dans les règles de l’art (date de téléchargement, messages d’erreur, version des données, etc.).\n\n\n4. Nettoyage des données\nNous procédons ensuite à un petit nettoyage pour ne garder que les variables utiles :\n\nnames(y)\n\n [1] \"id\"             \"cp\"             \"pop\"            \"address\"       \n [5] \"com_arm_name\"   \"automate_24_24\" \"timetable\"      \"fuel\"          \n [9] \"shortage\"       \"update\"         \"price_gazole\"   \"price_sp95\"    \n[13] \"price_sp98\"     \"price_gplc\"     \"price_e10\"      \"price_e85\"     \n[17] \"services\"       \"brand\"          \"name\"           \"geo_point\"     \n[21] \"com_arm_code\"   \"epci_code\"      \"epci_name\"      \"dep_code\"      \n[25] \"dep_name\"       \"reg_code\"       \"reg_name\"      \n\ndon &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\nIl y a toutefois une mauvaise surprise … les données semblent erronées à partir d’une certaine date\n\nggplot(don) +aes(x=update, y=price, col=address) + geom_point()\n\n\n\n\nEn fait … les chiffres qui sont fournis après le 26 mars ont été divisés mystérieusement par 1000. Il faut donc corriger ce problème :\n\nlibrary(ggplot2)\ndon&lt;-don %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\nggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\n\n\n\nOn note qu’il este une valeur aberrante mais sinon il est désormais possible de bien suivre l’évolution des prix au cours des trois dernières années et de repérer quelles est la station la moins chèr aux différentes dates.\n\n\n5. Changement de lien\nEssayons maintenant de reprendre l’ensemble de notre programme en changeant juste de commune dans le lien initial. On va ici soigner la rédaction du programme car nous comptons ensuite le transformer en fonction\nOn remplace le code postal de Sucy-en-Brie (94370) par celui d’Ivry-sur-Seine(94200).\n\n# Choix du lien (changement du code postal)\nlink&lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(94200)&timezone=Europe%2FParis\"\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ndon &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ndon&lt;-don %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\n# Réalisation d'un graphique\nggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\n\n\n\n\n\n6. Rédaction d’une Fonction\nOn peut maintenant écrire une fonction qui ne va dépendre que du code postal et va fournir en sortie le tableau de données. Tout ce que nous avons à faire est de modifier le lien en fonction du code postal qui sera le paramètre de la fonction.\nPour cela nous utilisons la commande R pasteO()qui permet de coller des chaînes de caractères sans ajouter d’expaces. Ici nous recollons le début de l’URL, le code de la commune que nous avons modifié et la fin de l’URL.\n\ngazole_tab &lt;- function(code=\"94370\") { \n# Choix du lien (changement du code postal)\nlink&lt;-paste0(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(\", code,\")&timezone=Europe%2FParis\")\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ntab &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ntab&lt;-tab %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\nreturn(tab)\n\n}\n\nPour tester notre fonction gazole_tab(), on prend en exemple une nouvelle commune, par exemple Saint-Maur des Fossés (94100) :\n\nres&lt;-gazole_tab(\"94100\")\nhead(res)\n\n              name            address     update price price_OK\n1 Carrefour Market    57, Rue Delenue 2021-02-18 1.366    1.366\n2             &lt;NA&gt;   57 BD DE CRETEIL 2021-02-18 1.499    1.499\n3             &lt;NA&gt;  29 bvd de créteil 2021-02-18 1.452    1.452\n4        ESSO FOCH 99/101 Avenue Foch 2021-02-18 1.366    1.366\n5        ESSO FOCH 99/101 Avenue Foch 2021-02-19 1.371    1.371\n6        ESSO FOCH 99/101 Avenue Foch 2021-02-19 1.376    1.376\n\n\nMais on pourrait aussi faire une fonction gazole_graph()qui renvoie non pas le tableau mais le graphique :\n\ngazole_graph &lt;- function(code=\"94370\") { \n# Choix du lien (changement du code postal)\nlink&lt;-paste0(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(\", code,\")&timezone=Europe%2FParis\")\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ndon &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ndon&lt;-don %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\n# Réalisation d'un graphique\ngraph&lt;-ggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\nreturn(graph)\n\n}\n\nOn teste la fonction sur Saint-Maur des Fossés (94100) :\n\ngazole_graph(\"94100\")\n\n\n\n\nMais le plus intéressant est de faire une fonction unique gazole()qui permet de renvoyer à la fois le tableau et le graphique en indiquant en sortie une liste d’objets comprenant à la fois le tableau (objet de type data.frame) et le graphique (objet de type ggplot2).\n\ngazole &lt;- function(code=\"94370\") { \n# Choix du lien (changement du code postal)\nlink&lt;-paste0(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(\", code,\")&timezone=Europe%2FParis\")\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ntab &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ntab&lt;-tab %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\n# Réalisation d'un graphique\ngraph&lt;-ggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\nreturn(list(\"tab\"=tab, \"graph\"=graph))\n\n}\n\nIl suffit maintenant d’executer une seule fois la fonction (un seul appel de l’API) pour pouvoir ensuite au choix utiliser le tableau ou afficher le graphique.\n\nres&lt;-gazole(\"94100\")\nhead(res$tab)\n\n              name            address     update price price_OK\n1             &lt;NA&gt;   57 BD DE CRETEIL 2021-02-18 1.499    1.499\n2             &lt;NA&gt;  29 bvd de créteil 2021-02-18 1.452    1.452\n3 Carrefour Market    57, Rue Delenue 2021-02-18 1.366    1.366\n4        ESSO FOCH 99/101 Avenue Foch 2021-02-18 1.366    1.366\n5 Carrefour Market    57, Rue Delenue 2021-02-19 1.371    1.371\n6        ESSO FOCH 99/101 Avenue Foch 2021-02-19 1.371    1.371\n\nres$graph"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#conclusion",
    "href": "11-API-OPENDATASOFT.html#conclusion",
    "title": "Pratique des API",
    "section": "Conclusion",
    "text": "Conclusion\nCe chapitre a permis de combiner trois apprentissages fondamentaux du data mining qui seront repris ensuie à plusieurs reprises :\n\nUtiliser des API pour récupérer directement ses données sans effectuer de téléchargement “à la main”.\nNettoyer les données reçues avant de les utiliser et automatiser autant que possible les procédures de nettoyages.\nCréer ses propres fonctions pour automatiser les tâches de récupération des données, nettoyage et production de tableaux ou graphiques."
  },
  {
    "objectID": "22-CARTO-mapsf.html",
    "href": "22-CARTO-mapsf.html",
    "title": "Carto. statique",
    "section": "",
    "text": "Le package mapsf permet de réaliser des cartes statiques de très haute qualité. Il a en effet été mis au point par des cartographes et des géomaticiens professionnels de l’UMS RIATE. Il prend la suite du package cartography dont la maintenance demeurera assuré quelque temps encore mais ne fera plus l’objet de développements futurs. Le package mapsf présente l’avantage d’être totalement compatibvle avec le package sf ce qui n’était pas autant le cas pour le package cartography, plus ancien, et créé pour être compatible avec l’ancien package sp.\nOn trouvera la documentation du package mapsf à l’adresse suivante :\nhttps://riatelab.github.io/mapsf/index.html"
  },
  {
    "objectID": "22-CARTO-mapsf.html#le-package-map_sf",
    "href": "22-CARTO-mapsf.html#le-package-map_sf",
    "title": "Carto. statique",
    "section": "",
    "text": "Le package mapsf permet de réaliser des cartes statiques de très haute qualité. Il a en effet été mis au point par des cartographes et des géomaticiens professionnels de l’UMS RIATE. Il prend la suite du package cartography dont la maintenance demeurera assuré quelque temps encore mais ne fera plus l’objet de développements futurs. Le package mapsf présente l’avantage d’être totalement compatibvle avec le package sf ce qui n’était pas autant le cas pour le package cartography, plus ancien, et créé pour être compatible avec l’ancien package sp.\nOn trouvera la documentation du package mapsf à l’adresse suivante :\nhttps://riatelab.github.io/mapsf/index.html"
  },
  {
    "objectID": "22-CARTO-mapsf.html#création-dun-template-cartographique",
    "href": "22-CARTO-mapsf.html#création-dun-template-cartographique",
    "title": "Carto. statique",
    "section": "Création d’un template cartographique",
    "text": "Création d’un template cartographique\nNous allons dans un premier temps apprendre à créer un fonds de carte vierge mais comportant tout l’habillage nécessaire (“template”). Pour cela nous allons charger différentes couches cartographiques correspondant respectivement au département, aux communes et aux iris.\nAfin d’éviter les déformations, les fonds de carte sont projetés selon la projection de référence en France (code 2154)\n\nmap_iris&lt;-readRDS(\"data/RP/map_iris_csp.RDS\") %&gt;% st_transform(crs=2154)\nmap_com &lt;-readRDS(\"data/RP/map_com_csp.RDS\") %&gt;% st_transform(crs=2154)\nmap_dep &lt;-readRDS(\"data/RP/map_dep.RDS\") %&gt;% st_transform(crs=2154)\n\n\ntracé d’un fonds de carte vierge\n\n mf_map(map_iris, type = \"base\")\n\n\n\n\n\n\nSuperposition de couches\nOn peut toutefois ajouter toute une série de paramètres supplémentaire (col=, border=, lwd=, …) et superposer plusieurs fonds de carte avec le paramètre add = TRUE. L’ajout de la fonction layout permet de rajouter un cadre une légende.\n\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\n# Ajoute un cadre, un titre et des sources\nmf_layout(title = \"Paris et Petite Couronne\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\n\n\nAjout d’un thème\nOn peut finalement modifier l’ensemble de la carte en lui ajoutant une instruction mf_theme() qui peut reprendre des styles existants ( “default”, “brutal”, “ink”, “dark”, “agolalight”, “candy”, “darkula”, “iceberg”, “green”, “nevermind”, “jsk”, “barcelona”) mais aussi créer ses propres thèmes\n\n#Choix du thème\nmf_theme(\"dark\")\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\nmf_layout(title = \"Theme dark\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\nAutre exemple\n\n#Choix du thème\nmf_theme(\"agolalight\")\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\nmf_layout(title = \"Theme agolalight\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\n\n\nAjout de texte\nOn peut ajouter une couche de texte avec la fonction mf_label(). Par exemple, on va ajouter à la carte précédente le nom des communes\n\n#Choix du thème\nmf_theme(\"agolalight\")\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\n# Ajoute les noms des départements\nmf_label(map_dep, \n         var=\"dep_name\",\n         cex=0.8, \n         col=\"blue\",\n         overlap = FALSE)\n\n# Ajoute un cadre, un titre et des sources\nmf_layout(title = \"Communes et Iris de Paris + PC en 2019\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-de-stock",
    "href": "22-CARTO-mapsf.html#carte-de-stock",
    "title": "Carto. statique",
    "section": "Carte de stock",
    "text": "Carte de stock\nUne carte de stock représente la localisation de quantités que l’on peut aditionner et dont le total a un sens. Par exemple un nombre d’habitants, un nombre de ménages, un nombre d’automobiles. Ce quantités doivent être représentées par des figures (cercles, carrés, …) dont la surface est proportionelle au stock afin que l’oeil du lecteur puisse les aditionner visuellement.\nDans le package mapsf, on réalise ce type de carte à l’aide de la fonction mf_map()en lui donnant le paramètre type=\"prop\".\nOn va tenter à titre d’exemple de représenter la distribution des actifs et du taux de chômage dans le Val de Marne:\n\nmap_iris_94 &lt;- map_iris %&gt;% filter(dep_code==\"94\")\nmap_com_94 &lt;- map_com %&gt;% filter(dep_code==\"94\")\nmap_dep_94 &lt;- map_dep %&gt;% filter(dep_code==\"94\")\nmap_iris_94$ACT&lt;-map_iris_94$CHO+map_iris_94$EMP\n\n\nCarte de stock minimale\nLes instructions minimales sont les suivantes :\n\n# Trace les contours des communes\nmf_map(x= map_iris_94, \n       type = \"base\")\n\n# Ajoute le nombre d'actifs\nmf_map(x =map_iris_94, \n      type =\"prop\",\n      var = \"ACT\",\n      add=TRUE)\n\n13 'NA' values are not plotted on the map.\n\n\n\n\n\nMais le résultat est peu satisfaisant car les cercles sont trop grands. Il faut en pratique toujours effectuer un réglage de ceux-ci avec l’instruction inches=\n\n\nCarte de stock habillée\n\nmf_theme(\"agolalight\")\nmf_map(map_iris_94, type = \"base\",  \n       col = \"lightyellow\",border=\"gray80\", lwd=0.3)\nmf_map(map_com_94, type = \"base\", \n       col = NA,border=\"black\",lwd=1,add = TRUE)\n\nmf_map(map_iris_94, var = \"ACT\",type = \"prop\",\n  inches = 0.1, col = \"red\",leg_pos = \"left\",  \n  leg_title = \"Nombre d'actifs\", add=TRUE)\n\n13 'NA' values are not plotted on the map.\n\nmf_layout(title = \"Distribution des actifs en 2019\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-choroplèthe",
    "href": "22-CARTO-mapsf.html#carte-choroplèthe",
    "title": "Carto. statique",
    "section": "Carte choroplèthe",
    "text": "Carte choroplèthe\nUne carte choroplèthe ou d’intensité représente un phénomène relatif dont la somme n’a pas de sens. Par exemple, il serait absurde d’aditionner les % de logement HLM des IRIS du Val de Marne. Ces variables d’intensité caractèrisent donc l’état général d’une zone (choros) et elles vont être représentées par une couleur appliquée à toute la surface de la zone, d’où leur nom de cartes choroplèthes.\nLa fonction du package mapsf adaptée aux variables d’intensité est la fonction mf_map()munie du paramètre type = \"choro\".\nOn va prendre l’exemple du taux de chômage\n\nmap_iris_94$TxCHO&lt;-100*map_iris_94$CHO/map_iris_94$ACT\n\n\nCarte choroplèthe minimale\nSi on ne précise rien, la carte est réalisée à l’aide de la palette par défaut avec un découpage des classes en quantiles (effectifs égaux).\n\n# Carte choroplèthe\nmf_map(\n  x = map_iris_94, \n  var = \"TxCHO\",\n  type = \"choro\")\n\n\n\n\n\n\nChoix d’une palette\nPlusieus packages proposent des palettes de couleurs. On prendra ici l’exemple du package RcolorBrewer. On commence par examiner la liste des palettes disponibles.\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\n\nPuis on créer une palette personelle en indiquant son nom et le nombre de classes. Ici on choisit la palette orange-vert mais on va l’inverser pour que l’orange corresponde aux valeurs fortes\n\ndisplay.brewer.pal(n = 10,name = \"RdYlGn\")\n\n\n\nmypal&lt;-rev(brewer.pal(n = 10,name = \"RdYlGn\"))\n\n\n\nCarte choroplèthe habillée\nOn peut arriver à une carte beaucoup plus satisfaisante en contrôlant l’ensemble des paramètres de couleur et de découpage des classes. Puis en superposant les contours de communes au dessus de la carte des IRIS pour faciliter le repérage.\n\n# Choisir les classes et la palette\nmybreaks = c(0, 4, 6, 8, 10, 12, 14, 16, 18,20,30)\n\n# Tracer la carte choroplèthe\nmf_map( map_iris_94, var = \"TxCHO\",type = \"choro\",\n  breaks = mybreaks,pal = mypal,\n  border=\"white\",col_na = \"gray80\",\n leg_title = \"% chômeurs\",\n leg_val_rnd = 0)\n# Ajouter les contours des communes\nmf_map(map_com_94, type = \"base\", col = NA,\n       border=\"black\",lwd=1,add = TRUE)\n# Ajouter un cadre, un titre et des sources\nmf_layout(title = \"Taux de chômage en 2019\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-stock-choroplèthe",
    "href": "22-CARTO-mapsf.html#carte-stock-choroplèthe",
    "title": "Carto. statique",
    "section": "Carte stock + choroplèthe",
    "text": "Carte stock + choroplèthe\nMais on peut aussi utiliser le type prop_choro\n\nmf_theme(\"agolalight\")\nmybreaks = c(0, 4, 6, 8, 10, 12, 14, 16, 18,20,30)\n\nmf_map(map_iris_94, type = \"base\",  \n       col = \"gray80\",border=\"white\", lwd=0.3)\nmf_map(map_com_94, type = \"base\", \n       col = NA,border=\"white\",lwd=1,add = TRUE)\nmf_prop_choro( x = map_iris_94,  var = c(\"ACT\", \"TxCHO\"), \n  inches = 0.08, col_na = \"grey\", pal=mypal,\n  breaks = mybreaks, nbreaks = 4, lwd = 0.1,\n  leg_pos = c(\"right\", \"left\"),leg_val_rnd = c(0,0),\n  leg_title = c(\"nb. actifs\", \"% chômeurs\"),\n  add = TRUE)\n\n13 'NA' values are not plotted on the map.\n\nmf_layout(title = \"Les actifs au chômage dans le Val de Marne au RP 2019\",\n        frame = TRUE, credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#typologie",
    "href": "22-CARTO-mapsf.html#typologie",
    "title": "Carto. statique",
    "section": "Typologie",
    "text": "Typologie\nOn se propose d’examiner le cas d’une variable qualitative résultant d’une classification ascendante hiérarchique. On travaille cette fois-ci à l’échelle des communes\n\nExtraction du tableau de contingence\nOn élimine la géométrie et on extrait le tableau de contingence des actifs :\n\n# Extrait les colonnes utiles\ntab&lt;-map_com %&gt;% st_drop_geometry() %&gt;% select(com_code, CHO, DIV, EMP, ETU, RET) %&gt;% filter(is.na(CHO)==F)\n\n\n# Transforme en matrice de % en ligne\nmat&lt;-as.matrix(tab[,-1])\nrownames(mat)&lt;-tab$com_code\n\nmatpct&lt;-100*prop.table(mat,1)\n\n\n\nCalcul de l’ACP et de la CAH\n\n# Calcule l'AFC puis la CAH\nlibrary(FactoMineR)\nacp&lt;-PCA(matpct)\n\n\n\n\n\n\ncah&lt;-HCPC(acp,nb.clust =4)\n\n\n\n\n\n\n\n\n\n# Récupère les résultats\ntab$typo &lt;- cah$data.clust$clust\n\n# analyse les profils\ntabres&lt;-cah$data.clust\nplot.catdes(catdes(tabres,6,proba = 1),level = 1,barplot = T)\n\n\n\n\n\n\n\n\n\nCartographie des résultats\n\n# Ajoute la typo au fonds de carte\nmap_com_typo &lt;-map_com %&gt;% select(com_code,com_name, geometry) %&gt;%\n                                left_join(tab)\n\nJoining with `by = join_by(com_code)`\n\n# Transforme la typo en facteur\nmap_com_typo$typoqual&lt;-as.factor(map_com_typo$typo)\nlevels(map_com_typo$typoqual) &lt;- c(\"(1) Chômeurs et inactifs\",\n                                   \"(2) Profil moyen\",\n                                   \"(3) Actifs en emploi\",\n                                   \"(4) Etudiants et retraités\")\n\n# Carte de typologie\nmf_theme(\"darkula\")\nmf_map(map_com_typo, \n       type = \"typo\",\n       var = \"typoqual\",\n       pal= c(\"orange\",\"lightyellow\",\"lightgreen\",\"lightblue\"),\n       leg_title = \"Spécificités\",\n       col_na = \"gray70\",\n       leg_no_data = \"Données manquantes\")\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,lwd=2,\n       add = TRUE)\n# Ajoute les noms des départements\nmf_label(map_dep, \n         var=\"dep_name\",\n         cex=0.8, \n         col=\"black\",\n         overlap = FALSE)\n\nmf_layout(title = \"Typologie des profls activités des communes de Paris et Petite Couronne en 2019\",\n        frame = TRUE, credits = \"Sources : IGN et INSEE RP 2019\",\n        arrow = F\n        )"
  },
  {
    "objectID": "10-API-INTRO.html",
    "href": "10-API-INTRO.html",
    "title": "Introduction aux API",
    "section": "",
    "text": "library(knitr,warn.conflicts = T,quietly = T)\nlibrary(dplyr, warn.conflicts = T,quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "10-API-INTRO.html#introduction",
    "href": "10-API-INTRO.html#introduction",
    "title": "Introduction aux API",
    "section": "Introduction",
    "text": "Introduction\n\nDéfinition\nOn peut partir de la définition suivante:\n\nEn informatique, API est l’acronyme d’Application Programming Interface, que l’on traduit en français par interface de programmation applicative ou interface de programmation d’application. L’API peut être résumée à une solution informatique qui permet à des applications de communiquer entre elles et de s’échanger mutuellement des services ou des données. Il s’agit en réalité d’un ensemble de fonctions qui facilitent, via un langage de programmation, l’accès aux services d’une application. (Source : Journal du Net)\n\n\n\nFonctions\nUne API peut remplir des fonctions très diverses :\n\nDans le domaine d’internet, l’API permet aux développeurs de pouvoir utiliser un programme sans avoir à se soucier du fonctionnement complexe d’une application. Les API peuvent par exemple être utilisées pour déclencher des campagnes publicitaires d’e-mailing de façon automatique sans avoir à passer par la compréhension d’une telle application (c’est le cas avec l’API AdWords de Google, par exemple). On les retrouve aujourd’hui dans de nombreux logiciels, en particulier dans les systèmes d’exploitation, les serveurs d’applications, dans le monde du graphisme (OpenGL), dans les applications SaaS (Office 365, G Suite, Salesforce…), les bases de données, l’open data, etc.(Source : Journal du Net)\n\n\n\nProtocoles\nD’une manière générale, les API supposent un échange d’informations entre un client et un serveur.\n\nCes échanges d’informations suivent un protocole c’est-à-dire un ensemble de règles. Il existe deux grands protocoles de communication sur lesquels s’adossent les API : Simple Object Access Protocol (SOAP) et Representational State Transfer (REST). Le second s’est désormais largement imposé face au premier car il est plus flexible. Il a donné naissance aux API dites REST ou RESTful (Source : Journal du Net)\n\n\n\nAPI et Data Science\nLe métier de data analyst implique presque nécessairement l’emploi d’API. Les langages de programmation R ou Python ont donc l’un comme l’autre mis au point des packages pour faciliter l’envoi de requêtes sur des serveurs dotés d’API.\n\n«API» est un terme général désignant le lieu où un programme informatique interagit avec un autre ou avec lui-même. Dans ce didacticiel, nous travaillerons spécifiquement avec des API Web, où deux ordinateurs différents - un client et un serveur - interagiront l’un avec l’autre pour demander et fournir des données, respectivement.\n\n\nLes API offrent aux scientifiques des données un moyen raffiné de demander des données propres et organisées à partir d’un site Web. Lorsqu’un site Web comme Facebook met en place une API, il met essentiellement en place un ordinateur qui attend les demandes de données.\n\n\nUne fois que cet ordinateur reçoit une demande de données, il effectuera son propre traitement des données et les enverra à l’ordinateur qui l’a demandé. De notre point de vue en tant que demandeur, nous devrons écrire du code dans R qui crée la demande et indique à l’ordinateur exécutant l’API ce dont nous avons besoin. Cet ordinateur lira ensuite notre code, traitera la requête et renverra des données bien formatées qui peuvent être facilement analysées par les bibliothèques R existantes.\n\n\nPourquoi est-ce précieux? Comparez l’approche API au scraping Web pur. Lorsqu’un programmeur gratte une page Web, il reçoit les données dans un morceau de HTML désordonné. Bien qu’il existe certainement des bibliothèques qui facilitent l’analyse du texte HTML, ce sont toutes des étapes de nettoyage qui doivent être prises avant même de mettre la main sur les données que nous voulons!\n\n\nSouvent, nous pouvons immédiatement utiliser les données que nous obtenons d’une API, ce qui nous fait gagner du temps et de la frustration.\n\nSource : Traduction française d’un billet de Pascual C., 2020"
  },
  {
    "objectID": "10-API-INTRO.html#lapi-de-la-nasa",
    "href": "10-API-INTRO.html#lapi-de-la-nasa",
    "title": "Introduction aux API",
    "section": "l’API de la NASA",
    "text": "l’API de la NASA\nA titre d’exemple, C. Pascual propose de travailler avec l’API Open Notify, qui donne accès à des données sur divers projets de la NASA. À l’aide de l’API Open Notify, nous pouvons notamment en savoir plus sur l’emplacement de la Station spatiale internationale et sur le nombre de personnes actuellement dans l’espace.\n\nInstaller les packages jsonlite et httr\nPour travailler avec des API dans R, nous devons intégrer certaines bibliothèques (library). Ces bibliothèques prennent toutes les complexités d’une requête d’API et les enveloppent dans des fonctions que nous pouvons utiliser dans des lignes de code uniques. Les bibliothèques R que nous utiliserons sont httr et jsonlite. Elles remplissent des rôles différents dans notre introduction des API, mais les deux sont essentiels.Si vous ne disposez pas de ces bibliothèques dans votre console R ou RStudio, vous devez d’abord les télécharger.\n\nlibrary(httr)\nlibrary(jsonlite)\n\n\n\nFormulation d’une requête GET()\nUne requête adressé à une API va suivre le schéma suivant :\n\nknitr::include_graphics(\"img/API_GET.png\",)\n\n\n\n\nIl existe plusieurs types de requêtes que l’on peut adresser à un serveur API. Pour nos besoins, nous allons simplement demander des données, ce qui correspond à une demande GET. Les autres types de requêtes sont POST et PUT, mais nous n’avons pas à nous en préoccuper dans l’immédiat\nAfin de créer une requête GET, nous devons utiliser la fonction GET() de la bibliothèque httr. La fonction GET() nécessite une URL, qui spécifie l’adresse du serveur auquel la demande doit être envoyée.\nNotre programme télécharge les données disponibles à l’adresse du serveur et les stocke dans un objet auquel on peut donner le nom que l’on souhaite, par exemple ovni dans la mesure où le résultat est de prime abord assez mystérieux…\n\novni &lt;- GET(\"http://api.open-notify.org/astros.json\")\nclass(ovni)\n\n[1] \"response\"\n\n\nOn sait que la classe de l’objet est de type response ce qui ne nous avance pas beaucoup.\nToutefois, si on demande à l’objet de s’afficher il nous apporte quatre renseignements utiles\n\novni\n\nResponse [http://api.open-notify.org/astros.json]\n  Date: 2024-05-31 13:59\n  Status: 200\n  Content-Type: application/json\n  Size: 360 B\n\n\n\nDate : le moment exact du téléchargement, très utile pour suivre les mises à jour\nStatus : le code informatique de résultat de la requête. La valeur 200 indique un succès alors que les autres valeurs signaleront un problème.\nContent-Type : le type d’information recueillie. Ici, une application au format json\nSize : la taille du fichier résultant du transfert.\n\nOn poursuit notre enquête en tapant la commande str() qui permet d’avoir plus de détail sur le contenu de l’objet.\n\nstr(ovni)\n\nList of 10\n $ url        : chr \"http://api.open-notify.org/astros.json\"\n $ status_code: int 200\n $ headers    :List of 6\n  ..$ server                     : chr \"nginx/1.10.3\"\n  ..$ date                       : chr \"Fri, 31 May 2024 13:59:19 GMT\"\n  ..$ content-type               : chr \"application/json\"\n  ..$ content-length             : chr \"360\"\n  ..$ connection                 : chr \"keep-alive\"\n  ..$ access-control-allow-origin: chr \"*\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ all_headers:List of 1\n  ..$ :List of 3\n  .. ..$ status : int 200\n  .. ..$ version: chr \"HTTP/1.1\"\n  .. ..$ headers:List of 6\n  .. .. ..$ server                     : chr \"nginx/1.10.3\"\n  .. .. ..$ date                       : chr \"Fri, 31 May 2024 13:59:19 GMT\"\n  .. .. ..$ content-type               : chr \"application/json\"\n  .. .. ..$ content-length             : chr \"360\"\n  .. .. ..$ connection                 : chr \"keep-alive\"\n  .. .. ..$ access-control-allow-origin: chr \"*\"\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ cookies    :'data.frame':    0 obs. of  7 variables:\n  ..$ domain    : logi(0) \n  ..$ flag      : logi(0) \n  ..$ path      : logi(0) \n  ..$ secure    : logi(0) \n  ..$ expiration: 'POSIXct' num(0) \n  ..$ name      : logi(0) \n  ..$ value     : logi(0) \n $ content    : raw [1:360] 7b 22 6d 65 ...\n $ date       : POSIXct[1:1], format: \"2024-05-31 13:59:19\"\n $ times      : Named num [1:6] 0 0.0226 0.169 0.1691 0.3158 ...\n  ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n $ request    :List of 7\n  ..$ method    : chr \"GET\"\n  ..$ url       : chr \"http://api.open-notify.org/astros.json\"\n  ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. ..- attr(*, \"names\")= chr \"Accept\"\n  ..$ fields    : NULL\n  ..$ options   :List of 2\n  .. ..$ useragent: chr \"libcurl/8.1.2 r-curl/5.0.2 httr/1.4.7\"\n  .. ..$ httpget  : logi TRUE\n  ..$ auth_token: NULL\n  ..$ output    : list()\n  .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  ..- attr(*, \"class\")= chr \"request\"\n $ handle     :Class 'curl_handle' &lt;externalptr&gt; \n - attr(*, \"class\")= chr \"response\"\n\n\nNous savons désormais que notre objet ovni est une liste comportant 10 branches, elles-mêmes divisées en sous branches qui peuvent être elles-même des listes…\n\n\nRemarque sur les listes\nLes listes sont des objets complexes mais fondamentaux pour la programmation en R. On peut accèder aux branches d’une liste soit en utilisant une série de $ soit en se servant de doubles crochets [[ ]]. Par exemple, si on veut accèder à la date de la réponse on peut taper au choix :\n\novni$headers$date\n\n[1] \"Fri, 31 May 2024 13:59:19 GMT\"\n\novni[[\"headers\"]][[\"date\"]]\n\n[1] \"Fri, 31 May 2024 13:59:19 GMT\"\n\n\nOn peut également afficher les noms des branches en partant de la racine puis en suivant l’arbre à l’aide de l’instruction names()\n\nnames(ovni$headers)\n\n[1] \"server\"                      \"date\"                       \n[3] \"content-type\"                \"content-length\"             \n[5] \"connection\"                  \"access-control-allow-origin\"\n\n\n\nnames(ovni$fields)\n\nNULL\n\n\n\n\nExtraction des données\nLes données contenues dans la réponse ont été stockées au format JSON (JavaScript Object Notation) qui est devenu un standard pour les échanges de données. Mais elles ont été ensuite comprimées en format binaire pour limiter la taille du fichier transféré. Il va donc falloir procéder en quatre étapes pour les extraire\n\nétape 1 : récupérer les données au format binaire\nOn extrait le champ de données dans la liste. Le résultat est assez étrange :\n\nlibrary(rvest)\ndon_bin&lt;-ovni$content\ndon_bin\n\n  [1] 7b 22 6d 65 73 73 61 67 65 22 3a 20 22 73 75 63 63 65 73 73 22 2c 20 22 70\n [26] 65 6f 70 6c 65 22 3a 20 5b 7b 22 6e 61 6d 65 22 3a 20 22 4a 61 73 6d 69 6e\n [51] 20 4d 6f 67 68 62 65 6c 69 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53\n [76] 22 7d 2c 20 7b 22 6e 61 6d 65 22 3a 20 22 41 6e 64 72 65 61 73 20 4d 6f 67\n[101] 65 6e 73 65 6e 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 2c 20\n[126] 7b 22 6e 61 6d 65 22 3a 20 22 53 61 74 6f 73 68 69 20 46 75 72 75 6b 61 77\n[151] 61 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 2c 20 7b 22 6e 61\n[176] 6d 65 22 3a 20 22 4b 6f 6e 73 74 61 6e 74 69 6e 20 42 6f 72 69 73 6f 76 22\n[201] 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 2c 20 7b 22 6e 61 6d 65\n[226] 22 3a 20 22 4f 6c 65 67 20 4b 6f 6e 6f 6e 65 6e 6b 6f 22 2c 20 22 63 72 61\n[251] 66 74 22 3a 20 22 49 53 53 22 7d 2c 20 7b 22 6e 61 6d 65 22 3a 20 22 4e 69\n[276] 6b 6f 6c 61 69 20 43 68 75 62 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53\n[301] 53 22 7d 2c 20 7b 22 6e 61 6d 65 22 3a 20 22 4c 6f 72 61 6c 20 4f 27 48 61\n[326] 72 61 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 5d 2c 20 22 6e\n[351] 75 6d 62 65 72 22 3a 20 37 7d\n\n\n\n\nétape 2 : convertir les données binaires au format caractère\nLa conversion est effectuée à l’aide de la fonction rawToChar() qui fait partie de R-Base.\n\n# conversion du contenu de toto en mode character\ndon_car&lt;-rawToChar(don_bin)\ndon_car\n\n[1] \"{\\\"message\\\": \\\"success\\\", \\\"people\\\": [{\\\"name\\\": \\\"Jasmin Moghbeli\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Andreas Mogensen\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Satoshi Furukawa\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Konstantin Borisov\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Oleg Kononenko\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Nikolai Chub\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Loral O'Hara\\\", \\\"craft\\\": \\\"ISS\\\"}], \\\"number\\\": 7}\"\n\n\nOn commence à mieux voir le résultat mais ce n’est pas encore très lisible car il s’agit de données au format JSON\n\n\nétape 3 : convertir les données JSON en objet R\nOn convertit les données de type JSON en données utilisables par R à l’aide de la fonction fromJson() du package jsonlite()\n\ndon_R &lt;- fromJSON(don_car)\nstr(don_R)\n\nList of 3\n $ message: chr \"success\"\n $ people :'data.frame':    7 obs. of  2 variables:\n  ..$ name : chr [1:7] \"Jasmin Moghbeli\" \"Andreas Mogensen\" \"Satoshi Furukawa\" \"Konstantin Borisov\" ...\n  ..$ craft: chr [1:7] \"ISS\" \"ISS\" \"ISS\" \"ISS\" ...\n $ number : int 7\n\n\nOn obtient finalement une liste de trois éléments dont le dernier est un data.frame décrivant les astronautes présents dans la station spatiale internationale au moment de l’execution du programme.\n\n\nétape 4 : Récupérer le tableau de résultats\n\ntab&lt;-don_R$people\nkable(tab,caption = \"Passagers de l'ISS en temps réel\")\n\n\nPassagers de l’ISS en temps réel\n\n\nname\ncraft\n\n\n\n\nJasmin Moghbeli\nISS\n\n\nAndreas Mogensen\nISS\n\n\nSatoshi Furukawa\nISS\n\n\nKonstantin Borisov\nISS\n\n\nOleg Kononenko\nISS\n\n\nNikolai Chub\nISS\n\n\nLoral O’Hara\nISS\n\n\n\n\n\n\n\n\nEcriture d’une fonction\nUne fois que l’on a bien compris la procédure d’extraction de cette API, on peut construire une fonction d’extraction pour simplifier la tâche et l’automatiser :\n\n## Fonction\nextract_ISS &lt;- function(){\n  ovni &lt;- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin&lt;-ovni$content\n  don_char&lt;-rawToChar(don_bin)\n  don_R&lt;-fromJSON(don_char)\n  tab&lt;-don_R$people\n  return(tab)\n}\n\n## Application\nextract_ISS()\n\n                name craft\n1    Jasmin Moghbeli   ISS\n2   Andreas Mogensen   ISS\n3   Satoshi Furukawa   ISS\n4 Konstantin Borisov   ISS\n5     Oleg Kononenko   ISS\n6       Nikolai Chub   ISS\n7       Loral O'Hara   ISS\n\n\nOn peut améliorer la fonction en lui faisant ajouter un champ qui indique la date à laquelle a été effectué le relevé :\n\n## Fonction\nextract_ISS2 &lt;- function(){\n  ovni &lt;- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin&lt;-ovni$content\n  don_char&lt;-rawToChar(don_bin)\n  don_R&lt;-fromJSON(don_char)\n  tab&lt;-don_R$people\n  tab$date&lt;-ovni$headers$date\n  return(tab)\n}\n\n## Application\nextract_ISS2()\n\n                name craft                          date\n1    Jasmin Moghbeli   ISS Fri, 31 May 2024 13:59:19 GMT\n2   Andreas Mogensen   ISS Fri, 31 May 2024 13:59:19 GMT\n3   Satoshi Furukawa   ISS Fri, 31 May 2024 13:59:19 GMT\n4 Konstantin Borisov   ISS Fri, 31 May 2024 13:59:19 GMT\n5     Oleg Kononenko   ISS Fri, 31 May 2024 13:59:19 GMT\n6       Nikolai Chub   ISS Fri, 31 May 2024 13:59:19 GMT\n7       Loral O'Hara   ISS Fri, 31 May 2024 13:59:19 GMT\n\n\nEt si on est à l’aise avec les listes, on peut aussi exporter les résultats sous la forme d’une liste plutôt que d’un tableau, ce qui évite de répéter plusieurs fois la date d’extraction des données\n\n## Fonction\nextract_ISS3 &lt;- function(){\n  ovni &lt;- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin&lt;-ovni$content\n  don_char&lt;-rawToChar(don_bin)\n  don_R&lt;-fromJSON(don_char)\n  tab&lt;-don_R$people\n  date&lt;-ovni$headers$date\n  result&lt;-list(\"Update\" = date,\"Data\" =tab)\n  return(result)\n}\n\n## Application\nx&lt;-extract_ISS3()\nkable(x$Data, caption=paste(\"Passagers de l'ISS :\", x$Update))\n\n\nPassagers de l’ISS : Fri, 31 May 2024 13:59:19 GMT\n\n\nname\ncraft\n\n\n\n\nJasmin Moghbeli\nISS\n\n\nAndreas Mogensen\nISS\n\n\nSatoshi Furukawa\nISS\n\n\nKonstantin Borisov\nISS\n\n\nOleg Kononenko\nISS\n\n\nNikolai Chub\nISS\n\n\nLoral O’Hara\nISS\n\n\n\n\n\n\n\nAPI et mise à jour en temps réel\nSur le site web du billet proposé par C. Pascual en février 2020, on trouve une autre liste ne comportant que 6 passagers et avec des noms totalement différents :\n\n\n\nPassagers de l’ISS en février 2020\n\n\ncraft\nname\n\n\n\n\nISS\nChristina Koch\n\n\nISS\nAlexander Skvortsov\n\n\nISS\nLuca Parmitano\n\n\nISS\nAndrew Morgan\n\n\nISS\nOleg Skripochka\n\n\nISS\nJessica Meir\n\n\n\n\n\nEn effet, l’API renvoie les résultats au moment de l’execution de la fonction GET() ce qui correspond à février 2020 pour le billet de blog. Or, les astronautes sont remplacés au plus tous les six mois ce qui explique que tous les noms soient différents un an après.\nNB : Cet exemple permet de mettre en évidence une fonction centrale des API qui est la mise à jour en temps réel des données !"
  },
  {
    "objectID": "32-PROJET-shiny.html",
    "href": "32-PROJET-shiny.html",
    "title": "Projet-Shiny",
    "section": "",
    "text": "library(knitr)\n## Global options\noptions(max.print=\"80\")\nopts_chunk$set(echo=TRUE,\n               cache=FALSE,\n               prompt=FALSE,\n               tidy=FALSE,\n               comment=NA,\n               message=FALSE,\n               warning=FALSE,\n               options(scipen=999))\nopts_knit$set(width=75)\n\n# Packages utilitaires\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n#library(rmdformats)\n\n# Packages graphiques\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n#packages cartographiques \nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n#library(leaflet)\n#library(htmlwidgets)\n#library(htmltools)\n\n# Appel d'API\n#library(httr)\n#library(jsonlite)\n#library(geojsonsf)\nL’objectif de ce chapitre est de montrer comment construire un programme shiny prenant en entrée un fichier sf (spatial features) pour construire ensuite pour différents indicateurs une application interactive de visualisation :\nNous avons construit un projet R dans dossier appelée Shiny_carto. Ce dossier contient différentes versions de l’application Shiny et un dossier sport contenant :"
  },
  {
    "objectID": "32-PROJET-shiny.html#pgm001-mise-en-page",
    "href": "32-PROJET-shiny.html#pgm001-mise-en-page",
    "title": "Projet-Shiny",
    "section": "pgm001 : mise en page",
    "text": "pgm001 : mise en page\nOn commence par créer une application shiny très simple sur le modèle de celle qui est fournie en exemple par Rstudio :\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(sf)\n\n\n# Chargement du tableau de données\ndon &lt;- readRDS(\"sport/licpop_idf_2018.RDS\") %&gt;% mutate(pop=as.numeric(pop))\n\n# selection de la zone d'étude et du sport\ncom &lt;- don %&gt;% filter(substr(code_com,1,2) %in% c(\"75\",\"92\",\"93\",\"94\")) %&gt;%\n         mutate(sport=code_fed==111,\n                sportlic = sport*nblic) %&gt;%\n          group_by(code_com) %&gt;%\n             summarise(tot=sum(nblic),\n                       spo=sum(sportlic)) %&gt;%\n          mutate(pct = 100*spo/tot)\n         \n\n\n\n\n\nui &lt;- fluidPage(\n    # Titre de l'application\n  titlePanel(\"Le Football dans le Grand Paris en 2017-2018\"),\n    \n    # Définition du Widget - ici un slider en vue de construire un histogramme\n    sidebarLayout(\n        sidebarPanel(\n   \n            \n            \n            \n            \n            sliderInput(inputId = \"Classes\",\n                        label = \"Nombres de classes : \",\n                        min = 1,\n                        max = 10,\n                        value = 5)\n        ),\n        mainPanel(\n            plotOutput(\"histplot\")\n        )\n    )\n)\n\nserver &lt;- function(input, \n                   output) {\n    output$histplot&lt;-renderPlot({hist(com$pct, breaks=input$Classes)})\n   \n}\n\nshinyApp(ui = ui, server = server)\n\nL’application marche, ce qui n’est pas si mal, et elle permet de visualiser la distribution de l’IDH des pays africains avec différents choix de classes en agissant sur le curseur.\n\n\n\n\n\n\n\n\nToutefois on note plusieurs points d’amélioration possibles\n\nNombre de classes non conforme aux attentes : nous avons utilisé la fonction hist() avec le paramètre breaks = k pour fixer le nombre de classes à k. Mais malheureusement le logiciel R estime souvent pouvoir mieux choisir les classes que l’utilisateur. Et ainsi quand on demande 3 classes (k=3) il décide sans prévenir d’en faire 4 ou lorsque l’on demande 10 classes il n’en fait que 7 …\nHabillage de l’histogramme incomplet : il manque des renseignements sur les axes, la source des données, etc…"
  },
  {
    "objectID": "32-PROJET-shiny.html#pgm002-histogramme",
    "href": "32-PROJET-shiny.html#pgm002-histogramme",
    "title": "Projet-Shiny",
    "section": "pgm002 : histogramme",
    "text": "pgm002 : histogramme\nOn décide d’améliorer la qualité graphique de l’histogramme et on force R à respecter le nombre de classe choisi en lui imposant un découpage en effectifs égaux (quantiles) que l’on calcule. On a par ailleurs superposé sur l’histogramme une courbe de densité de probabilité qui sera plus ou moins généralisée selon le nombre de classes retenu afin de repérer si la distribution est multimodale. On a utilisé pour cela le paramètre bw (bandwidth) de la fonction density()pour qu’elle utilise un kernel de paramètre égal à deux fois l’écart-type divisé par le nombre de classes. Enfin, on rajoute un habillage correct sur l’histogramme :\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(sf)\n\n# Chargement du tableau de données\ndon &lt;- readRDS(\"sport/licpop_idf_2018.RDS\") %&gt;% mutate(pop=as.numeric(pop))\n\n# selection de la zone d'étude et du sport\ncom &lt;- don %&gt;% filter(substr(code_com,1,2) %in% c(\"75\",\"92\",\"93\",\"94\")) %&gt;%\n  mutate(sport=code_fed==111,\n         sportlic = sport*nblic) %&gt;%\n  group_by(code_com) %&gt;%\n  summarise(tot=sum(nblic),\n            spo=sum(sportlic)) %&gt;%\n  mutate(pct = 100*spo/tot)\n\n\n# Définition UI et Server de l'application Shiny\nui &lt;- fluidPage(\n    # Titre de l'application\n    titlePanel(\"Le Football dans le Grand Paris en 2017-2018\"),\n    \n    # Définition du Widget - ici un slider en vue de construire un histogramme\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(inputId = \"classes\",\n                        label = \"Nombres de classes\",\n                        min = 1,\n                        max = 10,\n                        value = 5),\n            \n        ),\n        \n        \n        # Graphe montré à l'utilisateur\n        mainPanel(\n            plotOutput(\"histPlot\")\n        )\n    )\n)\n\nserver &lt;- function(input, \n                   output) {\n    output$histPlot &lt;- renderPlot({\n        \n       x&lt;-com$pct\n       mybreaks&lt;-quantile(x,(0:input$classes)/input$classes,na.rm=T)\n       hist(x, \n            breaks=mybreaks,\n            probability=TRUE,\n            col=\"lightyellow\",\n            xlab= \"% des licences\",\n            ylab = \"Densité de probabilité\",\n            main= \"Le Football dans le Grand Paris\",\n            sub = \"Source : Ministère de la Jeunesse et des Sports\")\n        mybw&lt;-2*sd(x,na.rm=T)/input$classes\n       lines(density(x,bw=mybw,na.rm=T),col=\"red\",lwd=2)\n    })\n    \n}\n\nshinyApp(ui = ui, server = server)\n\nLa qualité visuelle de l’histogramme est sérieusement améliorée et on peut désormais obtenir un nombre de classes conforme au choix effectué sur le curseur. On peut bien visualiser le changement du nombre de mode selon le nombre de classes retenues. Ici, on voit que l’application respecte notre choix de faire 3 ou 10 classes sans que R décide à la place de l’utilisateur…\n\n\n\n\n\n\n\n\nCela fait tout de même beaucoup d’efforts pour une seule variable et on ne va pas construire autant d’application qu’il y a d’indicateurs. Il serait donc intéressant de pouvoir choisir la fédération sportive qui nous intéresse dans une liste d’indicateurs en ajoutant un nouveau menu."
  },
  {
    "objectID": "32-PROJET-shiny.html#pgm003-variable",
    "href": "32-PROJET-shiny.html#pgm003-variable",
    "title": "Projet-Shiny",
    "section": "pgm003 : variable",
    "text": "pgm003 : variable\nOn décide de proposer à l’utilisateur le choix entre onze fédérations sportives on introduit un nouveau widget de type selectInput dans le menu de la barre latérale. Ce widget permet de choisir une variable du tableau de données et de lui attribuer un label plus précise que le simple code de la variable.\nIl faut évidemment adapter le code pour que la base de données puisse fournir les renseignements sur chacune des onze fédérations. Il y a donc un travail à faire en amont.\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(sf)\n\n# Chargement du tableau de données\ndon &lt;- readRDS(\"sport/licpop_idf_2018.RDS\") %&gt;% mutate(pop=as.numeric(pop))\n\n# selection de la zone d'étude et des sports\nsel &lt;- don %&gt;% filter(substr(code_com,1,2) %in% c(\"75\",\"92\",\"93\",\"94\")) %&gt;%\n  mutate(sport= case_when(code_fed==\"111\"~ \"Football\",\n                          code_fed==\"123\"~ \"Tennis\",\n                          code_fed==\"132\"~ \"Golf\",\n                          code_fed==\"119\"~ \"Natation\",\n                          code_fed==\"117\"~ \"Judo\",    \n                          code_fed==\"113\"~ \"Gymnastique\",\n                          code_fed==\"219\"~ \"Danse\",  \n                          code_fed==\"109\"~ \"Equitation\",\n                          code_fed==\"115\"~ \"Handball\", \n                          code_fed==\"133\"~ \"Rugby\",\n                          code_fed==\"101\"~ \"Athlétisme\", \n                          TRUE ~ \"Other\"))\n\n# Groupement par commune\nspo &lt;- sel %&gt;% group_by(code_com,sport) %&gt;%\n  summarise(spo=sum(nblic)) \ntot&lt;-sel %&gt;% group_by(code_com) %&gt;%\n  summarise(tot=sum(nblic)) \ntab&lt;-left_join(spo,tot) %&gt;% mutate(pct=100*spo/tot) %&gt;% as.data.frame()\n\n\n\n\n\n# Définition UI et Server de l'application Shiny\nui &lt;- fluidPage(\n    # Titre de l'application\n  titlePanel(\"Les sports dans le Grand Paris en 2017-2018\"),\n    \n    # Définition du Widget - ici un slider en vue de construire un histogramme\n    sidebarLayout(\n        sidebarPanel(\n            selectInput(inputId = \"variable\",\n                        label = \"Choix de l'indicateur\",\n                        choices = c(\"Football\" = \"Football\",\n                                    \"Golf\" = \"Golf\",\n                                    \"Tennis\" = \"Tennis\",\n                                    \"Natation\" = \"Natation\",\n                                  \"Judo\"=\"Judo\",\n                                  \"Gymnastique\" = \"Gymnastique\",\n                                  \"Danse\" = \"Danse\",\n                                  \"Equitation\" = \"Equitation\",\n                                  \"Handball\" = \"Handball\",\n                                  \"Rugby\" = \"Rugby\",\n                                  \"Athlétisme\" = \"Athlétisme\"\n                                  ),\n                        \n                        selected = \"Football\"\n            ),\n            \n            \n            sliderInput(inputId = \"classes\",\n                        label = \"Nombres de classes\",\n                        min = 1,\n                        max = 10,\n                        value = 5),\n            \n        ),\n        \n        \n        # Graphe montré à l'utilisateur\n        mainPanel(\n            plotOutput(\"histPlot\")\n        )\n    )\n)\n\nserver &lt;- function(input, \n                   output) {\n    output$histPlot &lt;- renderPlot({\n        \n       com&lt;-tab %&gt;% filter(sport==input$variable)\n       x&lt;-com$pct\n       mybreaks&lt;-quantile(x,(0:input$classes)/input$classes,na.rm=T)\n       hist(x, \n            breaks=mybreaks,\n            probability=TRUE,\n            col=\"lightyellow\",\n            xlab= \"% des licences\",\n            ylab = \"Densité de probabilité\",\n            main= paste(\"Les sports dans le Grand Paris : \", input$variable),\n            sub = \"Source : Ministère de la jeunesse et des sports\")\n       mybw&lt;-2*sd(x,na.rm=T)/input$classes\n       lines(density(x,bw=mybw,na.rm=T),col=\"red\",lwd=2)\n    })\n    \n}\n\nshinyApp(ui = ui, server = server)\n\nTout fonctionne bien et on peut désormais comparer la forme de la distribution des variables. Ainsi, le pourcentage de licenciés de la fédération de golf apparaît très dissymétrique à gauche tandis que le rugby montre une distribution plutôt symétrique. Ceci montre que le golf est beaucoup plus concentré spatialement dans quelques commune que le rugby qui est mieux réparti spatialement.\n\n\n\n\n\n\n\n\nNous pouvons considérer que l’analyse de la distribution statistique est désormais correcte et passer à l’analyse de la distribution spatiale, c’est-à-dire a réalisation d’une carte. On a évidemment très envie de connaître les communes ou plus de 10% des licences sportives concernent le golf … même si on se doute un peu de la réponse !"
  },
  {
    "objectID": "32-PROJET-shiny.html#pgm004-cartographie",
    "href": "32-PROJET-shiny.html#pgm004-cartographie",
    "title": "Projet-Shiny",
    "section": "pgm004 : cartographie",
    "text": "pgm004 : cartographie\nPour ajouter une carte à notre application, nous décidons d’utiliser le package mapsf qui offre d’excellente performance et une grande souplesse en matière notamment d’habillage et de choix des palettes. Nous commençons par une fonction de cartographique très simple et nous effectuons réglage pour afficher la carte et l’histogramme dans la partie droite de l’interface en leur donnant des hauteurs respectives de 500 et 300 pixels. On pourrait évidemment adopter d’autres choix de mise en page donnant plus ou moins d’importance à chacune des deux figures.\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapsf)\ndon &lt;- readRDS(\"sport/licpop_idf_2018.RDS\") %&gt;% mutate(pop=as.numeric(pop))\n\n# selection de la zone d'étude et des sports\n\n  sel &lt;- don %&gt;% filter(substr(code_com,1,2) %in% c(\"75\",\"92\",\"93\",\"94\")) %&gt;%\n  mutate(sport= case_when(code_fed==\"111\"~ \"Football\",\n                          code_fed==\"123\"~ \"Tennis\",\n                          code_fed==\"132\"~ \"Golf\",\n                          code_fed==\"119\"~ \"Natation\",\n                          code_fed==\"117\"~ \"Judo\",    \n                          code_fed==\"113\"~ \"Gymnastique\",\n                          code_fed==\"219\"~ \"Danse\",  \n                          code_fed==\"109\"~ \"Equitation\",\n                          code_fed==\"115\"~ \"Handball\", \n                          code_fed==\"133\"~ \"Rugby\",\n                          code_fed==\"101\"~ \"Athlétisme\", \n                          TRUE ~ \"Other\"))\n\n# Groupement par commune\nspo &lt;- sel %&gt;% group_by(code_com,sport) %&gt;%\n  summarise(spo=sum(nblic)) \ntot&lt;-sel %&gt;% group_by(code_com) %&gt;%\n  summarise(tot=sum(nblic)) \ntab&lt;-left_join(spo,tot) %&gt;% mutate(pct=100*spo/tot) %&gt;% as.data.frame()\n\n# Fonds de carte\nmap&lt;-readRDS(\"sport/map_com_idf.RDS\") \n\n\n# Définition UI et Server de l'application Shiny\nui &lt;- fluidPage(\n    # Titre de l'application\n  titlePanel(\"Les sports dans le Grand Paris en 2017-2018\"),\n    \n    # Définition du Widget - ici un slider en vue de construire un histogramme\n    sidebarLayout(\n        sidebarPanel(\n          selectInput(inputId = \"variable\",\n                      label = \"Choix de l'indicateur\",\n                      choices = c(\"Football\" = \"Football\",\n                                  \"Golf\" = \"Golf\",\n                                  \"Tennis\" = \"Tennis\",\n                                  \"Natation\" = \"Natation\",\n                                  \"Judo\"=\"Judo\",\n                                  \"Gymnastique\" = \"Gymnastique\",\n                                  \"Danse\" = \"Danse\",\n                                  \"Equitation\" = \"Equitation\",\n                                  \"Handball\" = \"Handball\",\n                                  \"Rugby\" = \"Rugby\",\n                                  \"Athlétisme\" = \"Athlétisme\"\n                      ),\n                      \n                      selected = \"Football\"\n          ),\n                      \n            \n            \n            sliderInput(inputId = \"classes\",\n                        label = \"Nombres de classes\",\n                        min = 1,\n                        max = 10,\n                        value = 5),\n            \n        ),\n        \n        \n        # Graphe montré à l'utilisateur\n        mainPanel(\n          plotOutput(\"mapPlot\",height = \"400px\"),\n          plotOutput(\"histPlot\", height = \"300px\")\n        )\n    )\n)\n\nserver &lt;- function(input, \n                   output) {\n    output$histPlot &lt;- renderPlot({\n        \n       com&lt;-tab %&gt;% filter(sport==input$variable)\n       x&lt;-com$pct\n       mybreaks&lt;-quantile(x,(0:input$classes)/input$classes,na.rm=T)\n       hist(x, \n            breaks=mybreaks,\n            probability=TRUE,\n            col=\"lightyellow\",\n            xlab= \"% des licences\",\n            ylab = \"Densité de probabilité\",\n            main= paste(\"Les sports dans le Grand Paris : \", input$variable),\n            sub = \"Source : Ministère de la jeunesse et des sports\")\n       mybw&lt;-2*sd(x,na.rm=T)/input$classes\n       lines(density(x,bw=mybw,na.rm=T),col=\"red\",lwd=2)\n    })\n    \n    output$mapPlot &lt;-renderPlot({\n      com&lt;-tab %&gt;% filter(sport==input$variable)\n  #    com&lt;-don %&gt;% filter(sport==\"Football\")\n      mapcom&lt;-merge(map,com,by.x=\"insee_com\",by.y=\"code_com\")\n    #  mapcom$pct[is.na(mapcom$pct)]&lt;-0\n      x&lt;-mapcom$pct\n      mybreaks&lt;-quantile(x,(0:input$classes)/input$classes,na.rm=T)\n      mf_map(mapcom, \n             var = \"pct\",\n             type = \"choro\",\n             breaks = mybreaks)\n    })\n    \n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\n\n\nMais nous pouvons encore améliorer plusieurs choses.\n\nL’habillage de la carte est insuffisant : il lui manque un titre, une échelle, une orientation, etc…\nL’histogramme et la carte ont des couleurs différentes alors qu’ils utilisent la même division en classes.\nLe choix des classes devrait être plus ouvert et ne pas se limiter aux classes d’effectifs égaux."
  },
  {
    "objectID": "32-PROJET-shiny.html#pgm005-classes",
    "href": "32-PROJET-shiny.html#pgm005-classes",
    "title": "Projet-Shiny",
    "section": "pgm005 : classes",
    "text": "pgm005 : classes\nLe package mapsf offre une fonction mf_get_breaks() qui propose plusieurs méthodes de division d’une variable en classes. Nous en retenons ici trois qui sont les plus courantes en cartographie :\n\namplitudes égales\neffectifs égaux\nJenks (minimisation de la variance intra-classe)\n\nSi l’on représente la variable “golf” avec des classes d’amplitudes égales, on pourra mieux mettre en valeur la concentration de ce sport dans quelques communes seulement. La carte précédente en quantiles (effectifs égaux) avait en effet tendance à masquer cette différence puisque chacune des classes regroupait le même nombre de communes.\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapsf)\ndon &lt;- readRDS(\"sport/licpop_idf_2018.RDS\") %&gt;% mutate(pop=as.numeric(pop))\n\n# selection de la zone d'étude et des sports\nsel &lt;- don %&gt;% filter(substr(code_com,1,2) %in% c(\"75\",\"92\",\"93\",\"94\")) %&gt;%\n  mutate(sport= case_when(code_fed==\"111\"~ \"Football\",\n                          code_fed==\"123\"~ \"Tennis\",\n                          code_fed==\"132\"~ \"Golf\",\n                          code_fed==\"119\"~ \"Natation\",\n                          code_fed==\"117\"~ \"Judo\",    \n                          code_fed==\"113\"~ \"Gymnastique\",\n                          code_fed==\"219\"~ \"Danse\",  \n                          code_fed==\"109\"~ \"Equitation\",\n                          code_fed==\"115\"~ \"Handball\", \n                          code_fed==\"133\"~ \"Rugby\",\n                          code_fed==\"101\"~ \"Athlétisme\", \n                          TRUE ~ \"Other\"))\n\n# Groupement par commune\nspo &lt;- sel %&gt;% group_by(code_com,sport) %&gt;%\n  summarise(spo=sum(nblic)) \ntot&lt;-sel %&gt;% group_by(code_com) %&gt;%\n  summarise(tot=sum(nblic)) \ntab&lt;-left_join(spo,tot) %&gt;% mutate(pct=100*spo/tot) %&gt;% as.data.frame()\n\n# Fonds de carte\nmap&lt;-readRDS(\"sport/map_com_idf.RDS\") \n\n\n# Définition UI et Server de l'application Shiny\nui &lt;- fluidPage(\n    # Titre de l'application\n  titlePanel(\"Les sports dans le Grand Paris en 2017-2018\"),\n    \n    # Définition du Widget - ici un slider en vue de construire un histogramme\n    sidebarLayout(\n        sidebarPanel(\n          selectInput(inputId = \"variable\",\n                      label = \"Choix de l'indicateur\",\n                      choices = c(\"Football\" = \"Football\",\n                                  \"Golf\" = \"Golf\",\n                                  \"Tennis\" = \"Tennis\",\n                                  \"Natation\" = \"Natation\",\n                                  \"Judo\"=\"Judo\",\n                                  \"Gymnastique\" = \"Gymnastique\",\n                                  \"Danse\" = \"Danse\",\n                                  \"Equitation\" = \"Equitation\",\n                                  \"Handball\" = \"Handball\",\n                                  \"Rugby\" = \"Rugby\",\n                                  \"Athlétisme\" = \"Athlétisme\"\n                      ),\n                      \n                      selected = \"Football\"\n          ),\n          \n            \n            sliderInput(inputId = \"classes\",\n                        label = \"Nombres de classes\",\n                        min = 1,\n                        max = 10,\n                        value = 5),\n            \n            selectInput(inputId = \"methode\",\n                        label = \"Type de classes\",\n                        choices = c(\"Effectifs égaux\" = \"quantile\",\n                                    \"Amplitudes égales\" = \"equal\",\n                                    \"Jenks\" = \"jenks\"),\n                        selected = \"quantile\"),\n            \n        ),\n        \n\n        \n        \n        # Graphe montré à l'utilisateur\n        mainPanel(\n          plotOutput(\"mapPlot\",height = \"400px\"),\n          plotOutput(\"histPlot\", height = \"300px\")\n        )\n    )\n)\n\nserver &lt;- function(input, \n                   output) {\n    output$histPlot &lt;- renderPlot({\n        \n       com&lt;-tab %&gt;% filter(sport==input$variable)\n       x&lt;-com$pct\n       mybreaks&lt;-mf_get_breaks(x, nbreaks= input$classes, breaks=input$methode)\n       hist(x, \n            breaks=mybreaks,\n            probability=TRUE,\n            col=\"lightyellow\",\n            xlab= \"% des licences\",\n            ylab = \"Densité de probabilité\",\n            main= paste(\"Les sports dans le Grand Paris : \", input$variable),\n            sub = \"Source : Ministère de la jeunesse et des sports\")\n       mybw&lt;-2*sd(x,na.rm=T)/input$classes\n       lines(density(x,bw=mybw,na.rm=T),col=\"red\",lwd=2)\n    })\n    \n    output$mapPlot &lt;-renderPlot({\n      com&lt;-tab %&gt;% filter(sport==input$variable)\n      mapcom&lt;-merge(map,com,by.x=\"insee_com\",by.y=\"code_com\")\n      x&lt;-mapcom$pct\n      mybreaks&lt;-mf_get_breaks(x, nbreaks= input$classes, breaks=input$methode)\n      mf_map(mapcom, \n             var = \"pct\",\n             type = \"choro\",\n             breaks = mybreaks)\n    })\n    \n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\n\n\nAvec ce nouveau choix, la carte des licenciés du golf apparaît remarquablement centré sur les communes et les arrondissements les plus riches de Paris (Neuilly, 16e arrondissement, …) et seules quelques communes de l’est parisien comme Saint-Maur-des-Fossés arrivent de justesse à sortir de la première classe qui regroupe les valeurs les plus faibles.\nLa question ici n’est pas de savoir s’il y a une “bonne” ou une “mauvaise” carte, mais simplement de laisser l’utilisateur choisir celle qui correspond le mieux à ce qu’il veut analyser ou mettre en valeur."
  },
  {
    "objectID": "32-PROJET-shiny.html#pgm006-couleurs",
    "href": "32-PROJET-shiny.html#pgm006-couleurs",
    "title": "Projet-Shiny",
    "section": "pgm006 : couleurs",
    "text": "pgm006 : couleurs\nJusqu’ici nous avons utilisé des palettes par défauts pour les cartes et une teinte unie pour l’histogramme. Mais puisque les classes sont les mêmes, pourquoi ne pas utiliser la même palette pour les deux figuress ? Et pouquoi ne pas offrir une plus grande liberté de choix des couleurs en allant par exemple choisir quelques unes des palettes d’un package comme RColorBrewerqui en offre un grand nombre.\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\n\nTout en gardant la variable “golf” on va utiliser cette fois-ci une participation selon la méthode de Jenks qui est la plus “scientifique” des trois proposées. Elle permet en effet de minimiser la variance interne des classes et maximiser leur variance externe. Elle s’apparente donc à un classification selon la méthode de Ward, mais basée sur un seul critère. On décide par ailleurs d’utiliser la palette “spectral” qui renforce l’opposition entre les communes riches (en bleu) et pauvres (en rouge). Cela donne évidemment une tonalité plutôt politique à une carte qui se prétendait scientifique…\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapsf)\nlibrary(RColorBrewer)\n\ndon &lt;- readRDS(\"sport/licpop_idf_2018.RDS\") %&gt;% mutate(pop=as.numeric(pop))\n\n# selection de la zone d'étude et des sports\nsel &lt;- don %&gt;% filter(substr(code_com,1,2) %in% c(\"75\",\"92\",\"93\",\"94\")) %&gt;%\n  mutate(sport= case_when(code_fed==\"111\"~ \"Football\",\n                          code_fed==\"123\"~ \"Tennis\",\n                          code_fed==\"132\"~ \"Golf\",\n                          code_fed==\"119\"~ \"Natation\",\n                          code_fed==\"117\"~ \"Judo\",    \n                          code_fed==\"113\"~ \"Gymnastique\",\n                          code_fed==\"219\"~ \"Danse\",  \n                          code_fed==\"109\"~ \"Equitation\",\n                          code_fed==\"115\"~ \"Handball\", \n                          code_fed==\"133\"~ \"Rugby\",\n                          code_fed==\"101\"~ \"Athlétisme\", \n                          TRUE ~ \"Other\"))\n\n# Groupement par commune\nspo &lt;- sel %&gt;% group_by(code_com,sport) %&gt;%\n  summarise(spo=sum(nblic)) \ntot&lt;-sel %&gt;% group_by(code_com) %&gt;%\n  summarise(tot=sum(nblic)) \ntab&lt;-left_join(spo,tot) %&gt;% mutate(pct=100*spo/tot) %&gt;% as.data.frame()\n\n# Fonds de carte\nmap&lt;-readRDS(\"sport/map_com_idf.RDS\") \n\n\n# Définition UI et Server de l'application Shiny\nui &lt;- fluidPage(\n    # Titre de l'application\n  titlePanel(\"Les sports dans le Grand Paris en 2017-2018\"),\n    \n    # Définition du Widget - ici un slider en vue de construire un histogramme\n    sidebarLayout(\n        sidebarPanel(\n          selectInput(inputId = \"variable\",\n                      label = \"Choix de l'indicateur\",\n                      choices = c(\"Football\" = \"Football\",\n                                  \"Golf\" = \"Golf\",\n                                  \"Tennis\" = \"Tennis\",\n                                  \"Natation\" = \"Natation\",\n                                  \"Judo\"=\"Judo\",\n                                  \"Gymnastique\" = \"Gymnastique\",\n                                  \"Danse\" = \"Danse\",\n                                  \"Equitation\" = \"Equitation\",\n                                  \"Handball\" = \"Handball\",\n                                  \"Rugby\" = \"Rugby\",\n                                  \"Athlétisme\" = \"Athlétisme\"\n                      ),\n                      \n                      selected = \"Football\"\n          ),\n            \n            sliderInput(inputId = \"classes\",\n                        label = \"Nombres de classes\",\n                        min = 1,\n                        max = 10,\n                        value = 5),\n            \n            selectInput(inputId = \"methode\",\n                        label = \"Type de classes\",\n                        choices = c(\"Effectifs égaux\" = \"quantile\",\n                                    \"Amplitudes égales\" = \"equal\",\n                                    \"Jenks\" = \"jenks\"),\n                        selected = \"quantile\"),\n            \n            selectInput(inputId = \"palette\",\n                        label = \"Couleurs\",\n                        choices = c(\"Oranges\" = \"Oranges\",\n                                    \"Bleus\" = \"Blues\",\n                                    \"Verts\" = \"Greens\",\n                                    \"Rouges\" = \"Reds\",\n                                    \"Gris\" = \"Greys\",\n                                    \"Spectral\"= \"Spectral\"),\n                        selected = \"Oranges\"),\n            \n            \n        ),\n        \n\n        \n        \n        # Graphe montré à l'utilisateur\n        mainPanel(\n          plotOutput(\"mapPlot\",height = \"400px\"),\n          plotOutput(\"histPlot\", height = \"300px\")\n        )\n    )\n)\n\nserver &lt;- function(input, \n                   output) {\n    output$histPlot &lt;- renderPlot({\n        \n       com&lt;-tab %&gt;% filter(sport==input$variable)\n       x&lt;-com$pct\n       mybreaks&lt;-mf_get_breaks(x, nbreaks= input$classes, breaks=input$methode)\n       mypalette&lt;-brewer.pal(name = input$palette,n = input$classes)\n       hist(x, \n            breaks=mybreaks,\n            probability=TRUE,\n            col=mypalette,\n            xlab= \"% des licences\",\n            ylab = \"Densité de probabilité\",\n            main= paste(\"Les sports dans le Grand Paris : \", input$variable),\n            sub = \"Source : Ministère de la jeunesse et des sports\")\n       mybw&lt;-2*sd(x,na.rm=T)/input$classes\n       lines(density(x,bw=mybw,na.rm=T),col=\"red\",lwd=2)\n    })\n    \n    output$mapPlot &lt;-renderPlot({\n      com&lt;-tab %&gt;% filter(sport==input$variable)\n      mapcom&lt;-merge(map,com,by.x=\"insee_com\",by.y=\"code_com\")\n      x&lt;-mapcom$pct\n      mybreaks&lt;-mf_get_breaks(x, nbreaks= input$classes, breaks=input$methode)\n      mypalette&lt;-brewer.pal(name = input$palette,n = input$classes)\n      mf_map(mapcom, \n             var = \"pct\",\n             type = \"choro\",\n             breaks = mybreaks,\n             pal=mypalette)\n    })\n    \n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\n\n\nLe résultat est nettement meilleur car le lecteur peut facilement passer désormais de la carte à l’histogramme. Et s’il trouve la palette “spectral” trop politique, il peut revenir à une analyse plus neutre et plus scientifique en prenant une simple variation de gris."
  },
  {
    "objectID": "32-PROJET-shiny.html#pgm007-où-sont-les-femmes",
    "href": "32-PROJET-shiny.html#pgm007-où-sont-les-femmes",
    "title": "Projet-Shiny",
    "section": "pgm007 : Où sont les femmes ?",
    "text": "pgm007 : Où sont les femmes ?\nIl reste encore pas mal de petits détails à améliorer (en pratique on n’a jamais fini …) pour aboutir à une application satisfaisante. Mais avant de passer au finition il faut s’interroger sur l’objet même de l’analyse et se demander par exemple s’il est réellement pertinent de mélanger hommes et femmes dans nos analyses.\nNous avons vu dans les analyses préliminaires que beaucoup de sport sont très marqués en faveur d’un genre ou l’autre. Il peut donc être pertinent de les analyser séparément plutôt que de les mélanger. Ce qui permettra également de comparer leurs distributions respectives pour un même sport.\nL’adaptation du code est très simple ici parce que la structure du tableau de données a été bien conçue (format long).\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapsf)\nlibrary(RColorBrewer)\n\ndon &lt;- readRDS(\"sport/licpop_idf_2018.RDS\") %&gt;% mutate(pop=as.numeric(pop))\n\n# selection de la zone d'étude et des sports\nsel &lt;- don %&gt;% filter(substr(code_com,1,2) %in% c(\"75\",\"92\",\"93\",\"94\")) %&gt;%\n  mutate(sport= case_when(code_fed==\"111\"~ \"Football\",\n                          code_fed==\"123\"~ \"Tennis\",\n                          code_fed==\"132\"~ \"Golf\",\n                          code_fed==\"119\"~ \"Natation\",\n                          code_fed==\"117\"~ \"Judo\",    \n                          code_fed==\"113\"~ \"Gymnastique\",\n                          code_fed==\"219\"~ \"Danse\",  \n                          code_fed==\"109\"~ \"Equitation\",\n                          code_fed==\"115\"~ \"Handball\", \n                          code_fed==\"133\"~ \"Rugby\",\n                          code_fed==\"101\"~ \"Athlétisme\", \n                          TRUE ~ \"Other\"))\n\n\n# Groupement par commune\nspo &lt;- sel %&gt;% group_by(code_com,sport,sexe) %&gt;%\n  summarise(spo=sum(nblic)) \ntot&lt;-sel %&gt;% group_by(code_com) %&gt;%\n  summarise(tot=sum(nblic)) \ntab&lt;-left_join(spo,tot) %&gt;% mutate(pct=100*spo/tot) %&gt;% as.data.frame()\n\n# Fonds de carte\nmap&lt;-readRDS(\"sport/map_com_idf.RDS\") \n\n\n# Définition UI et Server de l'application Shiny\nui &lt;- fluidPage(\n    # Titre de l'application\n  titlePanel(\"Les sports dans le Grand Paris en 2017-2018\"),\n    \n    # Définition du Widget - ici un slider en vue de construire un histogramme\n    sidebarLayout(\n        sidebarPanel(\n          selectInput(inputId = \"variable\",\n                      label = \"Choix de l'indicateur\",\n                      choices = c(\"Football\" = \"Football\",\n                                  \"Golf\" = \"Golf\",\n                                  \"Tennis\" = \"Tennis\",\n                                  \"Natation\" = \"Natation\",\n                                  \"Judo\"=\"Judo\",\n                                  \"Gymnastique\" = \"Gymnastique\",\n                                  \"Danse\" = \"Danse\",\n                                  \"Equitation\" = \"Equitation\",\n                                  \"Handball\" = \"Handball\",\n                                  \"Rugby\" = \"Rugby\",\n                                  \"Athlétisme\" = \"Athlétisme\"\n                      ),\n                      selected = \"Football\"\n          ),                 \n            \n            selectInput(inputId = \"Sexe\",\n                        label = \"Sexe\",\n                        choices = c(\"Homme\" = \"Homme\",\n                                    \"Femme\" = \"Femme\"),\n                        selected = \"Homme\"\n            ),\n            \n            \n            \n            sliderInput(inputId = \"classes\",\n                        label = \"Nombres de classes\",\n                        min = 1,\n                        max = 10,\n                        value = 5),\n            \n            selectInput(inputId = \"methode\",\n                        label = \"Type de classes\",\n                        choices = c(\"Effectifs égaux\" = \"quantile\",\n                                    \"Amplitudes égales\" = \"equal\",\n                                    \"Jenks\" = \"jenks\"),\n                        selected = \"quantile\"),\n            \n            selectInput(inputId = \"palette\",\n                        label = \"Couleurs\",\n                        choices = c(\"Oranges\" = \"Oranges\",\n                                    \"Bleus\" = \"Blues\",\n                                    \"Verts\" = \"Greens\",\n                                    \"Rouges\" = \"Reds\",\n                                    \"Gris\" = \"Greys\",\n                                    \"Spectral\"= \"Spectral\"),\n                        selected = \"Oranges\"),\n            \n            \n        ),\n        \n\n        \n        \n        # Graphe montré à l'utilisateur\n        mainPanel(\n          plotOutput(\"mapPlot\",height = \"400px\"),\n          plotOutput(\"histPlot\", height = \"300px\")\n        )\n    )\n)\n\nserver &lt;- function(input, \n                   output) {\n    output$histPlot &lt;- renderPlot({\n        \n       com&lt;-tab %&gt;% filter(sport==input$variable, sexe==input$Sexe)\n       x&lt;-com$pct\n       mybreaks&lt;-mf_get_breaks(x, nbreaks= input$classes, breaks=input$methode)\n       mypalette&lt;-brewer.pal(name = input$palette,n = input$classes)\n       hist(x, \n            breaks=mybreaks,\n            probability=TRUE,\n            col=mypalette,\n            xlab= \"% des licences\",\n            ylab = \"Densité de probabilité\",\n            main= paste(\"Les sports dans le Grand Paris : \", input$variable),\n            sub = \"Source : Ministère de la jeunesse et des sports\")\n       mybw&lt;-2*sd(x,na.rm=T)/input$classes\n       lines(density(x,bw=mybw,na.rm=T),col=\"red\",lwd=2)\n    })\n    \n    output$mapPlot &lt;-renderPlot({\n      com&lt;-tab %&gt;% filter(sport==input$variable, sexe==input$Sexe)\n      mapcom&lt;-merge(map,com,by.x=\"insee_com\",by.y=\"code_com\")\n      x&lt;-mapcom$pct\n      mybreaks&lt;-mf_get_breaks(x, nbreaks= input$classes, breaks=input$methode)\n      mypalette&lt;-brewer.pal(name = input$palette,n = input$classes)\n      mf_map(mapcom, \n             var = \"pct\",\n             type = \"choro\",\n             breaks = mybreaks,\n             pal=mypalette)\n    })\n    \n}\n\nshinyApp(ui = ui, server = server)\n\nOn prend comme exemple la distribution de la part du Handball par commune car c’est un sport où la France a obtenu de bons résultats aussi bien chez les hommes que chez les femmes. Pour lutter contre les stéréotypes, on choisit de cartographier les hommes dans une palette de teintes de rouges (incluant donc le rose …) et les femmes dans des teintes de bleus.\n\n\n\n\n\n\n\n\nIl ressort de la comparaison des deux cartes et des deux histogrammes que les hommes sont bien dispersés dans l’espace, même s’ils sont relativement plus présents à l’est et au sud. Quand aux femmes, leur distribution est beaucoup plus concentrée autour de quelques communes"
  },
  {
    "objectID": "32-PROJET-shiny.html#conclusion",
    "href": "32-PROJET-shiny.html#conclusion",
    "title": "Projet-Shiny",
    "section": "Conclusion",
    "text": "Conclusion\nQue faut-il retenir de cet exercice ?\n\nCommencer par des applications très simples : le point de départ d’une application shiny sera le plus souvent un programme d’exemple proposé par Rstudio.\nAvancer pas à pas : il vaut mieux améliorer un seu point à la fois afin de pouvoir repérer ses erreurs et revenir si besoin en arrière.\nAvoir un objectif général :  le plus important est de ne pas se disperser et de bein savoir ce que l’on veut faire (ici : un histogramme et une carte).\nUtiliser un petit tableau pour commencer :  inutile de tester l’application sur toutes les variables d’entrée de jeu. Commencer par une seule variable, puis deux ou trois avant de passer au tableau complet.\nAméliorer l’esthétique à la fin :  ce n’est q’une fois que toutes les fonctions marchent qu’on peut commencer à rentrer dans le détail de la décoration, des couleurs, …"
  },
  {
    "objectID": "23-CARTO-leaflet.html",
    "href": "23-CARTO-leaflet.html",
    "title": "Carto-leaflet",
    "section": "",
    "text": "library(knitr)\n## Global options\noptions(max.print=\"80\")\nopts_chunk$set(echo=TRUE,\n               cache=FALSE,\n               prompt=FALSE,\n               tidy=FALSE,\n               comment=NA,\n               message=FALSE,\n               warning=FALSE,\n               options(scipen=999))\nopts_knit$set(width=75)\n\n# Packages utilitaires\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(rmdformats)\n\n# Packages graphiques\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n#packages cartographiques \nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(leaflet)\nlibrary(htmlwidgets)\nlibrary(htmltools)\n\n# Appel d'API\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(geojsonsf)"
  },
  {
    "objectID": "23-CARTO-leaflet.html#premiers-pas",
    "href": "23-CARTO-leaflet.html#premiers-pas",
    "title": "Carto-leaflet",
    "section": "Premiers pas",
    "text": "Premiers pas\n\nOBJECTIFS : Ce cours propose de fournir les bases élémentaires du logiciel Leaflet. Il est très largement inspiré d’un article d’Elena Salette publié sur l’excellent site de formation ThinkR et intitulé Cartographie interactive : comment visualiser mes données spatiales de manière dynamique avec leaflet ?\n\n\nBUG WARNING : Il peut arriver que la transformation du fichier .Rmd en .html ne s’opère pas et que vous voyiez apparaître le message d’erreur suivant RMarkdown cannot knit: html_dependency not found. Ce message d’erreur persiste même après avoir corrigé le code… ce qui est très pénible. Après avoir cherché sur les forums de discussion, j’ai trouvé une première réponse sur stackoverflow qui consiste simplement à aller sur la flèche descendnate à droite du bouton knitr et effectuer un clear knitr cache avant de relancer le Knitr. Apparemment ça marche, sans que je sache bien pourquoi. Mais la solution la plus efficace semble être d’insérer une option cache=FALSE dans les options globales du fichier Markdown. Cela va sans doute un peu ralentir l’affichage des pages HTML,mais évite les problèmes. On pourra toujours rétablir cache=TRUE si nécessaire\n\nNotre premier objectif très limité sera de construire une carte interactive utilisant le fonds de carte OpenStreetMap que l’on pourra zoomer en avant ou en arrière. La carte comportera la localisation de la place de la gare à Sucy-en-Brie avec une “épingle” de localisation comportant une photographie de la gare et un petit texte de promotion de celle-ci.\n\nLancement avec leaflet()\nNous allons avoir besoin des packages suivants :\n\nleaflet puisque c’est l’objet même du cours !\ndplyr afin de pouvoir construire des programmes utilisant des pipes %&gt;%\nsf pour charger des fonds de carte de différents types (points, lignes polygones)\nhtmltools et htmlwidgets pour ajouter des popups interactifs sur notre carte\n\nPour vérifier que le package leaflet est bien installé, nous créons une première carte (vide !)\n\nmap &lt;- leaflet()\n\nmap\n\n\n\n\n\nEt il n’y a … RIEN ! si ce n’est un bouton de zoom\n\n\nRemplissage avec addTiles()\nOn ajoute sur ce fond de carte vide des “tuiles” cartographiques qui sont des images se modifiant selon l’échelle pour apporter plus ou moins de détails. Par défaut, le fonds de carte de référence est le fonds OpenStreetMap\n\nlibrary(leaflet)\n\nmap &lt;- leaflet() %&gt;%\n          addTiles()\n\nmap\n\n\n\n\n\nLa carte est désormais interactive et on peut effectuer des zooms ou se déplacer.\n\n\nCalage avec setView()\nNous allons ensuite choisir un point de référence, par exemple la place de la gare à Sucy-en-Brie. Pour trouver les coordonnées de latitude et longitude, la solution la plus simple est d’utiliser Google Maps puis de zoomer sur la zone d’étude et enfin d’effectuer un click droit avec la souris sur le point dont on cherche les coordonnées pour obtenir dans un popup les coordonnées recherchées :\n On peut alors procéder à une double opération de centrage de notre carte et de définition d’une échelle d’observation afin que la carte produite par leafletcouvre bien la zone qui nous intéresse. Cette double opération est réalisée à l’aide de la fonction setView() assortie des trois paramètre suivants :\n\nlng = pour la longitude\nlat = pour la latitude\nzoom = pour le degré d’aggrandissement de la carte de 1 pour le Monde entier à 20 pour une vision ulra locale\n\n\nmap &lt;- leaflet() %&gt;% \n          addTiles() %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 17)\n\nmap\n\n\n\n\n\nUne fois qu’on a vérifié le centrage avec un zoom fort (ici 17), on peut refaire la carte en utilisant un zoom plus faible, par exemple un zoom de 12 permettant de visualiser toute la commune de Sucy et les communes voisines.\n\nmap &lt;- leaflet() %&gt;% \n          addTiles() %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 12)\n\nmap\n\n\n\n\n\n\n\nPersonalisation avec addProviderTiles()\nLes tuiles OpenStreetMap qui servent de fonds de carte par défaut peuvent être remplacés par des tuiles personalisées fournies par des producteurs publics ou privés. On peut obtenir la liste des tuiles disponibles en tapant providers dans la console de R studio et les tester une par une. Mais il est souvent plus simple et plus rapide d’aller visualiser les tuiles disponibles sur ce site web où l’on peut centrer le monde sur sa zone d’étude et voir ce que donnent les différentes familles de tuiles.\nA titre d’exemple, les tuiles OpenTopoMap permettent de voir la carte topographique de type IGN en couleur :\n\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('OpenTopoMap') %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 12)\n\nmap\n\n\n\n\n\nLa couche Esri.WorldTopoMap fournit également une imagerie précise mais de couleurs plus neutre que les tuiles OpenTopoMap ou OpenStreetMap , ce qui sera intéressant si on superspose des marqueurs de couleur vive.\n\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 12)\nmap\n\n\n\n\n\n\n\nAffichage d’un point avec addMarkers()\nL’usage le plus fréquent de leafletconsiste à ajouter des éléments de localisation ponctuelle appelés markerset de rendre ces objets ponctuels interactifs avec l’ouverture de fenêtres popupslorsqu’on clique dessus avec la souris. On va donc voir pas à pas comment construire de telles cartes interactives en partant du cas le plus simple (marqueur unique) pour aller vers les cas plus complexes (ensemble de marqueurs de taille, couleur et formes différentes).\nNous allons commencer par indiquer l’emplacement de la place de la gare de Sucy-en-Brie sur notre carte précédente à l’aide de la fonction addMarkers() :\n\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77141, lng=2.50870, zoom = 12) %&gt;% \n            addMarkers(lat = 48.77141, lng=2.50870)\nmap\n\n\n\n\n\nOn constate que le marqueur donne bien la position choisi mais n’est pas interactif. Il faut ajouter plus de paramètres pour assurer l’interactivité.\n\n\nAjout d’un labelou d’un popup\nOn peut définir deux comportements d’un marker selon que la souris ne fait que passer dessus (label) ou selon que l’utilisateur effectue un click sur marker et déclenche l’ouverture d’une fenêtre (popup). Dans sa version la plus simple, l’interactivité consiste à ajouter une chaîne de caractère à ces deux paramètres.\n\nicone_gare &lt;-makeIcon(iconUrl = \"img/gare_sucy_coord_googlemap.png\")\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77141, lng=2.50870, zoom = 12) %&gt;% \n            addMarkers(lat = 48.77141, lng=2.50870,\n                      # En passant la souris\n                      label = \"GARE DE SUCY-BONNEUIL\", \n                      # En cliquant sur l'icone\n                       popup = \"La gare RER A de Sucy Bonneuil est bien reliée aux communes \n                                 environnantes par un réseau de bus partant dans toutes les directions\")\nmap\n\n\n\n\n\n\n\nAmélioration du popup\nMais on peut faire beaucoup mieux, notamment pour la fenêtre popupqui peut prendre la forme d’une mini-page web dont on fixe le contenu en html avec la fonction paste0() et les dimensions avec le sous-paramètre popupOptions().\n\n# Préparation de la fenêtre Popup\n    my_popup = paste0(\n      \"&lt;b&gt; LA GARE DE SUCY\",\n      \"&lt;/b&gt;&lt;br/&gt;&lt;img src=https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Gare_Sucy-en-Brie.jpg/1200px-Gare_Sucy-en-Brie.jpg width='200px'&gt;&lt;br/&gt;\",\n      \"La gare RER A de Sucy Bonneuil est bien reliée aux communes \n                                 environnantes par un réseau de bus partant dans toutes les directions.\")\n\n\n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77141, lng=2.50870, zoom = 12) %&gt;% \n            addMarkers(lat = 48.77141, lng=2.50870,\n                      # En passant la souris\n                      label = \"GARE DE SUCY-BONNEUIL\", \n                      # En cliquant sur l'icone\n                       popup = my_popup, \n                      # Quelques options de la popup\n                        popupOptions = \n                      list(maxHeight = 150, maxWidth = 200))\nmap\n\n\n\n\n\n\n\nProlongements\nEt voila, le tour est joué. Il faut maintenant réfléchir à la façon de construire une carte comportant un ensemble d’épingles similaires avec des couleurs ou des formes différentes, des messages différents, des photographies variées … Il ne sera alors évidemment pas possible d’ajouter une commande addMarkers() pour chaque épingle si la carte en comporte des centaines.\nSi vous avez bien compris ce cours, vous pourrez trouver des réponses en lisant de façon autonome le reste de l’article dont nous nous somme inspiré : Cartographie interactive : comment visualiser mes données spatiales de manière dynamique avec leaflet ?"
  },
  {
    "objectID": "23-CARTO-leaflet.html#cartographie-de-points",
    "href": "23-CARTO-leaflet.html#cartographie-de-points",
    "title": "Carto-leaflet",
    "section": "Cartographie de points",
    "text": "Cartographie de points\nNous allons prendre comme exemple un fichier contenant la localisation des tous les terrains de football de France en 2017.\n\ndon&lt;-st_read(\"data/foot/res_equipements_2017.shp\")\n\nReading layer `res_equipements_2017' from data source \n  `/Users/claudegrasland1/git/datamining2024/data/foot/res_equipements_2017.shp' \n  using driver `ESRI Shapefile'\nreplacing null geometries with empty geometries\nSimple feature collection with 36475 features and 86 fields (with 65 geometries empty)\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -63.09191 ymin: -23.8689 xmax: 168.1067 ymax: 51.07328\nGeodetic CRS:  WGS 84\n\n\n\nPréparation des données\nOn sélectionne les variables utiles et on ne retient que les terrains situés dans Paris + PC\n\nsel&lt;-don %&gt;% select(id = insnumeroin,\n                    com_code = cominsee,\n                    com_nom = comlib,\n                    ins = insnom,\n                    anc = equanneeser,\n                    sup = equsurfacee\n                    ) %&gt;%\n              mutate(anc=as.numeric(anc),\n                     sup=as.numeric(sup)) %&gt;%\n              filter(is.na(anc)==F,\n                     is.na(sup)==F,\n                     substr(com_code,1,2) %in% c(\"75\",\"92\",\"93\",\"94\"))\n\n\n\nsummary(sel)\n\n      id              com_code           com_nom              ins           \n Length:484         Length:484         Length:484         Length:484        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n      anc            sup                 geometry  \n Min.   :1886   Min.   :   96   POINT        :484  \n 1st Qu.:1970   1st Qu.: 5225   epsg:4326    :  0  \n Median :1982   Median : 6698   +proj=long...:  0  \n Mean   :1981   Mean   : 5984                      \n 3rd Qu.:1998   3rd Qu.: 7350                      \n Max.   :2016   Max.   :14000                      \n\n\n\n\nCartographie des localisations\nOn commence par créer une carte des localisations des installations sportives avec AddCircleMarkers()\n\n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.84, lng=2.33, zoom = 11) %&gt;%\n             addCircleMarkers(data=sel)\n\nmap\n\n\n\n\n\n\n\nRéglage de la taille des cercles\nOn règle la taille des cercles en fonction de la surface des installations\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n           setView(lat = 48.84, lng=2.33, zoom = 11) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,    # diamètre\n                              stroke=FALSE,         # pas de bordure           \n                              fillOpacity = 0.5)    # opacité \n            \n                              \n\nmap\n\n\n\n\n\n\n\nRéglage de la couleur des cercles\nOn fait varier la couleur des cercles en fonction due l’ancienneté des installations\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n\n# Choix des classes \n    mycut&lt;-c(1900, 1950, 1960,1970,1980,2000,2010,2020)\n    \n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('Spectral', \n                       reverse = T,\n                       sel$anc,\n                       bins=mycut)\n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n           setView(lat = 48.84, lng=2.33, zoom = 11) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,    # diamètre\n                              stroke=TRUE,          # bordure   \n                              weight=1  ,           # épaisseur de la bordure\n                              color= \"black\",      # couleur de la bordure\n                              opacity = 0.7  ,       # opacité de la bordure \n                              fillOpacity = 0.5,    # opacité \n                              fillColor = ~mypal(anc)\n                              )    %&gt;%\n              addLegend(data = sel,\n                      pal = mypal, \n                      title = \"Ancienneté\",\n                      values =~anc, \n                      position = 'topright') \n            \n                              \n\nmap\n\n\n\n\n\n\n\nAjout d’un popup d’information\nOn rajoute un popup pour afficher toutes les informations sur chaque terrain\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n\n# Choix des classes \n    mycut&lt;-c(1900, 1950, 1960,1970,1980,2000,2010,2020)\n    \n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('Spectral', \n                       reverse = T,\n                       sel$anc,\n                       bins=mycut)\n# Préparation des popups\n      mypopups &lt;- lapply(seq(nrow(sel)), function(i) {\n      paste0(  paste(\"Installation: \" ,sel$ins[i]), '&lt;br&gt;', \n               paste(\"Surface     : \", sel$sup[i]), '&lt;br&gt;',\n               paste(\"Ancienneté  : \" ,sel$anc[i]))\n            \n            })\n      mypopups&lt;-lapply(mypopups, htmltools::HTML)  \n      \n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n           setView(lat = 48.84, lng=2.33, zoom = 11) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,       # diamètre\n                              stroke=TRUE,             # bordure   \n                              weight=1  ,              # épaisseur de la bordure\n                              color= \"black\",          # couleur de la bordure\n                              opacity = 0.7  ,         # opacité de la bordure \n                              fillOpacity = 0.5,       # opacité du remplissage\n                              fillColor = ~mypal(anc), # couleur de remplissage\n                               popup = mypopups,       # Popup !\n                              )    %&gt;%\n              addLegend(data = sel,\n                      pal = mypal, \n                      title = \"Ancienneté\",\n                      values =~anc, \n                      position = 'topright') \n            \n                              \n\nmap\n\n\n\n\n\n\n\nChoix des tuiles\nOn fait varier les tuiles pour offrir la possibilité de visualiser la position des maisons sur un plan ou sur une photo aérienne.\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n\n# Choix des classes \n    mycut&lt;-c(1900, 1950, 1960,1970,1980,2000,2010,2020)\n    \n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('Spectral', \n                       reverse = T,\n                       sel$anc,\n                       bins=mycut)\n# Préparation des popups\n      mypopups &lt;- lapply(seq(nrow(sel)), function(i) {\n      paste0(  paste(\"Installation: \" ,sel$ins[i]), '&lt;br&gt;', \n               paste(\"Surface     : \", sel$sup[i]), '&lt;br&gt;',\n               paste(\"Ancienneté  : \" ,sel$anc[i]))\n            \n            })\n      mypopups&lt;-lapply(mypopups, htmltools::HTML)  \n      \n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n               # Tuiles\n               addTiles(group = \"OSM \") %&gt;%\n               addProviderTiles('Esri.WorldTopoMap', group = \"ESRI topo.\") %&gt;%\n               addProviderTiles('Esri.WorldImagery', group = \"ESRI photo.\") %&gt;%\n              # Contrôle des tuiles\n               addLayersControl( baseGroups = c(\"OSM\",\"ESRI topo.\",\"ESRI photo.\"),\n                                 position = \"bottomright\") %&gt;%\n           setView(lat = 48.84, lng=2.33, zoom = 11) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,       # diamètre\n                              stroke=TRUE,             # bordure   \n                              weight=1  ,              # épaisseur de la bordure\n                              color= \"black\",          # couleur de la bordure\n                              opacity = 0.7  ,         # opacité de la bordure \n                              fillOpacity = 0.5,       # opacité du remplissage\n                              fillColor = ~mypal(anc), # couleur de remplissage\n                               popup = mypopups,       # Popup !\n                              )    %&gt;%\n              addLegend(data = sel,\n                      pal = mypal, \n                      title = \"Ancienneté\",\n                      values =~anc, \n                      position = 'topright') \n            \n                              \n\nmap\n\n\n\n\n\n\n\nAjout d’une couche de polygones\nOn décide d’ajouter le polygone donnant le contour de la commune de Sucy-en-Brie ainsi que celui des quarties Iris.\n\ncom&lt;-readRDS(\"data/RP/map_com.RDS\") \n\ndep &lt;- readRDS(\"data/RP/map_dep.RDS\") \n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n\n# Choix des classes \n    mycut&lt;-c(1900, 1950, 1960,1970,1980,2000,2010,2020)\n    \n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('Spectral', \n                       reverse = T,\n                       sel$anc,\n                       bins=mycut)\n# Préparation des popups\n      mypopups &lt;- lapply(seq(nrow(sel)), function(i) {\n      paste0(  paste(\"Installation: \" ,sel$ins[i]), '&lt;br&gt;', \n               \n               paste(\"Surface     : \", sel$sup[i]), '&lt;br&gt;',\n               paste(\"Ancienneté  : \" ,sel$anc[i]))\n            \n            })\n      mypopups&lt;-lapply(mypopups, htmltools::HTML)  \n      \n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n               # Tuiles\n               addTiles(group = \"OSM \") %&gt;%\n               addProviderTiles('Esri.WorldTopoMap', group = \"ESRI topo.\") %&gt;%\n               addProviderTiles('Esri.WorldImagery', group = \"ESRI photo.\") %&gt;%\n              # Contrôle des tuiles\n               addLayersControl( baseGroups = c(\"OSM\",\"ESRI topo.\",\"ESRI photo.\"),\n                                 position = \"bottomright\") %&gt;%\n           setView(lat = 48.84, lng=2.33, zoom = 11) %&gt;%\n              addPolygons(data = com,\n                          fillOpacity = 0.1,\n                          color=\"red\",\n                          weight = 0.5) %&gt;%\n               addPolygons(data = dep,\n                          fillOpacity = 0,\n                          color=\"red\",\n                          weight = 2) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,       # diamètre\n                              stroke=TRUE,             # bordure   \n                              weight=1  ,              # épaisseur de la bordure\n                              color= \"black\",          # couleur de la bordure\n                              opacity = 0.7  ,         # opacité de la bordure \n                              fillOpacity = 0.5,       # opacité du remplissage\n                              fillColor = ~mypal(anc), # couleur de remplissage\n                               popup = mypopups,       # Popup !\n                              )    %&gt;%\n              addLegend(data = sel,\n                      pal = mypal, \n                      title = \"Ancienneté\",\n                      values =~anc, \n                      position = 'topright') \n            \n                              \n\nmap\n\n\n\n\n\n\n\nSauvegarde du résultat\non peut transformer le résultat en widget html pour réutilisation dans une page web\n\nsaveWidget(map, \"data/foot/map_foot.html\",selfcontained = T)"
  },
  {
    "objectID": "12-API-exo.html",
    "href": "12-API-exo.html",
    "title": "API-Exo",
    "section": "",
    "text": "Nous proposons une série d’exercices d’application du cours du chapitre précédent en allant des applications les plus simples au plux complexes. Les exercices portent tous sur la base de donnée des demandes de valeurs foncières géoloalisées que l’on peut trouver sur le site public.opendatasoft"
  },
  {
    "objectID": "12-API-exo.html#exercice-1-récupération-et-analyse-dun-tableau-unique",
    "href": "12-API-exo.html#exercice-1-récupération-et-analyse-dun-tableau-unique",
    "title": "API-Exo",
    "section": "Exercice 1 : Récupération et analyse d’un tableau unique",
    "text": "Exercice 1 : Récupération et analyse d’un tableau unique\n\nProblème\nEssayez de récupérer à l’aide d’une API les informations sur l’ensemble des ventes immobilières de maisons de la commune de Montcuq-en-Quercy-Blanc (code INSEE = 46201) au cours de l’année 2020. Vous devez ensuite\n\nAfficher les premières lignes du tableau des ventes de maisons à Moncuq en en 2020\nCalculer le nombre de ventes et leur prix moyen au m2\nRéaliser un histogramme du prix moyen de ces ventes sur lequel figureront le nombre de ventes et le prix moyen.\n\n\n\nSolution\nVous devez obtenir les résultats suivants :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nCommune\nCode\nSurf_hab\nSurf_ter\nPrix\nPrix_m2\n\n\n\n\n2020-01-06\nMontcuq-en-Quercy-Blanc\n46201\n280\n450\n270000\n964\n\n\n2020-01-31\nMontcuq-en-Quercy-Blanc\n46201\n60\n1258\n60000\n1000\n\n\n2020-02-07\nMontcuq-en-Quercy-Blanc\n46201\n27\n1275\n187000\n6926\n\n\n2020-02-07\nMontcuq-en-Quercy-Blanc\n46201\n79\n1275\n187000\n2367\n\n\n2020-02-20\nMontcuq-en-Quercy-Blanc\n46201\n40\nNA\n18000\n450\n\n\n2020-03-16\nMontcuq-en-Quercy-Blanc\n46201\n50\n800\n121000\n2420\n\n\n\n\n\n[1] \"Il ya eu 39 ventes au prix moyen de 1910 €/m2\""
  },
  {
    "objectID": "12-API-exo.html#exercice-2-tableau-de-bord-dune-commune",
    "href": "12-API-exo.html#exercice-2-tableau-de-bord-dune-commune",
    "title": "API-Exo",
    "section": "Exercice 2 : Tableau de bord d’une commune",
    "text": "Exercice 2 : Tableau de bord d’une commune\n\nProblème\nEssayez de récupérer à l’aide d’une API les informations sur l’ensemble des ventes immobilières de maisons ou d’appartement de la commune de Sucy-en-Brie (Code INSEE = 94071)\n\nSimplifiez le tableau pour ne garder que les variables suivantes\n\n\ndate : date de la transaction\ncode : code INSEE de la commune\nbien : type de bien (maison ou appartement)\nnom : nom de la commune\nprix : prix de vente total\nsurf : surface habitable\nprixm2 : prix au m2\n\n\nNettoyer le tableau en retirant les transactions dont le prix au m2 est supérieur à 10000€\nCréez un tableau montrant l’évolution par année des prix médian au m2 des maisons et des appartements.\nCréez un graphique montrant l’évolution mensuelle des prix au m2 des maisons et des appartements.\n\n\n\nSolution\nVous devez obtenir les résultats suivants :\n\n\n\n\n\ndate\ncode\nnom\nbien\nprix\nsurf\nprix_m2\n\n\n\n\n2014-01-10\n94071\nSucy-en-Brie\nAppartement\n212000\n62\n3419\n\n\n2014-01-16\n94071\nSucy-en-Brie\nMaison\n640000\n145\n4414\n\n\n2014-01-16\n94071\nSucy-en-Brie\nMaison\n640000\n145\n4414\n\n\n2014-01-17\n94071\nSucy-en-Brie\nAppartement\n115480\n45\n2566\n\n\n2014-01-21\n94071\nSucy-en-Brie\nMaison\n390000\n132\n2955\n\n\n2014-01-23\n94071\nSucy-en-Brie\nMaison\n690300\n140\n4931\n\n\n\n\n\n\nPrix médian de vente des maisons et appartement (en €/m2)\n\n\nAnnée\nVentes d’appartements\nVentes de maisons\n\n\n\n\n2014\n3200\n3666\n\n\n2015\n2889\n3541\n\n\n2016\n3069\n3636\n\n\n2017\n3249\n3783\n\n\n2018\n3455\n3753\n\n\n2019\n3537\n4097"
  },
  {
    "objectID": "12-API-exo.html#exercice-3-automatisation",
    "href": "12-API-exo.html#exercice-3-automatisation",
    "title": "API-Exo",
    "section": "Exercice 3 : Automatisation",
    "text": "Exercice 3 : Automatisation\nEcrivez le progamme de l’exercice 2 sous la forme d’une fonction prenant en entrée le code INSEE d’une commune quelconque."
  },
  {
    "objectID": "41-ANSPA-access.html",
    "href": "41-ANSPA-access.html",
    "title": "Accessibilité et Potentiel",
    "section": "",
    "text": "Cette séance va permettre :\n\nde consolider les apprentissages en matière de cartographie et d’analyse spatiale.\nd’aborder de nouvelles données sous l’angle des problèmes de localisation optimale, dans une perspective soit de service public (e.g. localisation optimale des écoles ou des crèches), soit de concurrence spatiale (localisation d’un commerce maximisant la clientète).\nde créer des fonctions-type de cartographie et d’analye spatiale pouvant être mobilisées ensuite dans vos applications shiny interactives.\n\n\n\n\nL’installation est a priori la même que dans les sessions précédentes.cOn reprend juste pour mémoire la liste, à l’intention de ceux qui n’auraient pas suivi la séance précédente :\n\nlibrary(knitr)\nlibrary(dplyr)\n\nlibrary(sf)\nlibrary(mapsf)\nlibrary(RColorBrewer)\nlibrary(leaflet)\n\nlibrary(ggplot2)\nlibrary(plotly)"
  },
  {
    "objectID": "41-ANSPA-access.html#introduction",
    "href": "41-ANSPA-access.html#introduction",
    "title": "Accessibilité et Potentiel",
    "section": "",
    "text": "Cette séance va permettre :\n\nde consolider les apprentissages en matière de cartographie et d’analyse spatiale.\nd’aborder de nouvelles données sous l’angle des problèmes de localisation optimale, dans une perspective soit de service public (e.g. localisation optimale des écoles ou des crèches), soit de concurrence spatiale (localisation d’un commerce maximisant la clientète).\nde créer des fonctions-type de cartographie et d’analye spatiale pouvant être mobilisées ensuite dans vos applications shiny interactives.\n\n\n\n\nL’installation est a priori la même que dans les sessions précédentes.cOn reprend juste pour mémoire la liste, à l’intention de ceux qui n’auraient pas suivi la séance précédente :\n\nlibrary(knitr)\nlibrary(dplyr)\n\nlibrary(sf)\nlibrary(mapsf)\nlibrary(RColorBrewer)\nlibrary(leaflet)\n\nlibrary(ggplot2)\nlibrary(plotly)"
  },
  {
    "objectID": "41-ANSPA-access.html#donnees",
    "href": "41-ANSPA-access.html#donnees",
    "title": "Accessibilité et Potentiel",
    "section": "DONNEES",
    "text": "DONNEES\nOn dispose de cinq jeux de données sur Paris et les départements de Petite Couronne qui ont été téléchargés sur le site de l’INSEE ou du ministère des sports et légèrement retouchés pour en faciliter l’utilisation.\n\nContour des communes d’Ile de France\nCe fichier fournit le contour des communes de Paris et petite Couronne. On commence par vérifier le système de projection :\n\nmapcom&lt;-readRDS(\"ParisPC/mapcom_parisPC.RDS\")\nst_crs(mapcom)\n\nCoordinate Reference System:\n  User input: 4326 \n  wkt:\nGEOGCS[\"WGS 84\",\n      DATUM[\"WGS_1984\",\n        SPHEROID[\"WGS 84\",6378137,298.257223563,\n          AUTHORITY[\"EPSG\",\"7030\"]],\n        AUTHORITY[\"EPSG\",\"6326\"]],\n      PRIMEM[\"Greenwich\",0,\n        AUTHORITY[\"EPSG\",\"8901\"]],\n      UNIT[\"degree\",0.0174532925199433,\n        AUTHORITY[\"EPSG\",\"9122\"]],\n      AXIS[\"Latitude\",NORTH],\n      AXIS[\"Longitude\",EAST],\n    AUTHORITY[\"EPSG\",\"4326\"]]\n\n\nLe système de projection EPSG = 4326 est celui qui convient pour leaflet. On peut visualiser l’ensemble des commune facilement :\n\nleaflet() %&gt;%  addTiles() %&gt;%\n              addPolygons(data=mapcom, # fonds de carte 4326\n                          weight = 1,  # épaisseur des traits\n                          col = \"red\", # couleur\n                          label = ~nom_com, # réaction souris\n                          opacity = 0.3)  # opacité du remplissage\n\n\n\n\n\n\n\nRevenus, pauvreté et niveau de vie en 2015 - Données carroyées\nCes données issues du “Dispositif Fichier localisé social et fiscal” (Filosofi) ont été créée pour des besoins de services public :\n\nL’Insee fournit des informations socio-économiques sur près de 30 millions de ménages. Il diffuse ces informations à différentes échelles dont la plus petite est celle d’un carreau de 200 mètres de côté.\n\n\nCes statistiques locales permettent d’observer finement la situation socio-économique de la population de zones géographiques très ciblées. Elles représentent une source d’information précieuse pour aller au-devant des besoins des habitants et des acteurs économiques et accompagner la mise en œuvre de politiques publiques.\n\nSource : INSEE\nExaminons à titre d’exemple les carreaux correspondant majoritairement au territoire de la commune de Sucy-en-Brie (code = 94071)\n\ngridpop&lt;-readRDS(\"ParisPC/gridpop_parisPC.RDS\")\n\n\n\nleaflet() %&gt;%  addTiles() %&gt;%\n                addPolygons(data=mapcom, \n                          weight = 1,\n                          col = \"blue\",\n                          fillOpacity = 0.1) %&gt;%\n  \n              addPolygons(data=gridpop, \n                          weight = 1,\n                          col = \"red\", \n                          opacity = 0.3) \n\n\n\n\n\nComme on peut le voir, les carreaux ne sont présent que dans les zones peuplées et ne recouvrent pas les zones inhabitées.\nLe fichier propose un grand nombre de variables dont on trouvera la description dans le document explicatif dictionnaire des variables accessible sur le site de l’INSEE\n\nkable(head(st_drop_geometry(gridpop))[,1:10])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninsee_com\nI_pauv\nInd\nMen\nMen_pauv\nMen_1ind\nMen_5ind\nMen_prop\nMen_fmp\nInd_snv\n\n\n\n\n75119\n0\n2818.5\n990\n280\n340\n164\n21\n159\n44265483\n\n\n75111\n0\n1543.5\n926\n128\n564\n20\n378\n57\n48209885\n\n\n75119\n0\n1338.0\n508\n131\n185\n71\n124\n54\n24681173\n\n\n75119\n0\n1235.5\n633\n76\n319\n33\n352\n32\n41531046\n\n\n75120\n0\n685.0\n349\n134\n201\n22\n46\n28\n12379153\n\n\n75113\n0\n1728.0\n751\n115\n311\n63\n177\n106\n43383686\n\n\n\n\n\nPour des raisons de confidentialités, les données ne peuvent toutefois être divulguées lorsqu’il y a moins de 10 à 20 ménages dans un carreau de la grille. Dans ce cas, les données sont “modifiées” en effectuant une sorte de moyenne avec les carreaux les plus proches.\n\n\nBase des équipements sportifs\nCette base de données du ministère de l’équipement et des sports est accessible par ce lien. Elle fournit la position précise des équipements sportifs en indiquant leur type, leur ancienneté, leur accessibilité aux handicapés, etc. Nous avons réalisé une extraction pour les départements de Paris et petite couronne en ne retenant que quelques indicateurs.\n\nequ&lt;-readRDS(\"ParisPC/equip_ParisPC.RDS\") \nkable(head(equ))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninsee_com\ntyp_code\ntyp_nom\ntyp_fam\ndat_ser\nprop\nlon\nlat\ngeometry\n\n\n\n\n75119\n1205\nPractice\nParcours de golf\n2009\nCommune\n2.38027\n48.88630\nPOINT (2.38027 48.8863)\n\n\n75119\n802\nSalle de musculation/cardiotraining\nEquipement d’activités de forme et de santé\nNA\nEtablissement privé commercial\n2.38049\n48.89280\nPOINT (2.38049 48.8928)\n\n\n75119\n2105\nSalle de danse\nSalle ou terrain spécialisé\n1997\nEtablissement privé commercial\n2.37923\n48.89400\nPOINT (2.37923 48.894)\n\n\n75119\n801\nSalle de cours collectifs\nEquipement d’activités de forme et de santé\n2007\nPrivé non commercial\n2.37056\n48.87941\nPOINT (2.37056 48.87941)\n\n\n75119\n104\nFosse à plongeon\nBassin de natation\n1972\nCommune\n2.38911\n48.88210\nPOINT (2.38911 48.8821)\n\n\n75119\n1701\nMultisports/City-stades\nMultisports/City-stades\n2005\nCommune\n2.38669\n48.87640\nPOINT (2.38669 48.8764)\n\n\n\n\n\nOn peut voir que le fichier comporte 109 équipements, certains étant rares et d’autres fréquents.\n\ntab&lt;-equ %&gt;% st_drop_geometry() %&gt;%\n                count(typ_code,typ_nom) %&gt;%\n                arrange(-n)\nkable(head(tab,25))\n\n\n\n\ntyp_code\ntyp_nom\nn\n\n\n\n\n501\nCourt de tennis\n1991\n\n\n1901\nSalle multisports (gymnase)\n1339\n\n\n1701\nMultisports/City-stades\n1063\n\n\n802\nSalle de musculation/cardiotraining\n821\n\n\n2802\nTerrain de football\n680\n\n\n2105\nSalle de danse\n584\n\n\n1801\nDojo / Salle d’arts martiaux\n478\n\n\n2201\nSalles polyvalentes / des fêtes / non spécialisées\n462\n\n\n801\nSalle de cours collectifs\n415\n\n\n202\nTerrain de pétanque\n374\n\n\n2901\nTerrain de basket-ball\n364\n\n\n1004\nPiste d’athlétisme isolée\n219\n\n\n102\nBassin sportif de natation\n212\n\n\n2701\nStructure Artificielle d’Escalade\n196\n\n\n2106\nSalle de gymnastique sportive\n175\n\n\n1001\nStade d’athlétisme\n148\n\n\n2111\nSalle de tennis de table\n148\n\n\n103\nBassin ludique de natation\n146\n\n\n2117\nSalle ou terrain de squash\n142\n\n\n1105\nMur de tennis\n122\n\n\n2903\nTerrain de handball\n119\n\n\n1802\nSalle de boxe\n114\n\n\n1401\nPas de tir à l’arc\n112\n\n\n2803\nTerrain de rugby\n109\n\n\n1003\nAire de saut\n96\n\n\n\n\n\nExaminons à titre d’exemple la localisation des terrains de football (code 2802) autour de la commeune de Sucy-en-Brie (code 94071)\n\nmyequ&lt;-equ %&gt;% filter(typ_code %in% c(\"2803\"))\nleaflet() %&gt;% addProviderTiles('Esri.WorldTopoMap') %&gt;%\n  \n                addPolygons(data=mapcom, \n                          weight = 1,\n                          col = \"blue\",\n                          fillOpacity = 0.1) %&gt;%\n  \n              addCircleMarkers(data=myequ,\n                               radius = 3,\n                               stroke = T,\n                               weight = 2,\n                               color=\"red\",\n                               fillColor =  \"yellow\")\n\n\n\n\n\nExercice : Faites une carte de la distribution de votre équipement."
  },
  {
    "objectID": "41-ANSPA-access.html#accessibilite",
    "href": "41-ANSPA-access.html#accessibilite",
    "title": "Accessibilité et Potentiel",
    "section": "ACCESSIBILITE",
    "text": "ACCESSIBILITE\nNous allons calculer l’accessibilité de la population de Sucy-en-Brie aux terrains de football localisés à l’intérieur de ses frontières.\n\nPréparation des données\nOn extrait les contours de la commune choisie et sa population sur grille puis on projette les deux cartes dans la projection Lambert (crs=2154) afin de pouvoir mesurer les distances à vol d’oiseau en km. On calcule le centre des grilles pour positionner les populations.\n\nmymap &lt;- mapcom %&gt;% filter(insee_com==\"94071\") %&gt;% \n                        st_transform(2154)\n\nmypop &lt;- gridpop %&gt;% filter(insee_com== \"94071\") %&gt;%\n                     select(w = \"Ind\") %&gt;%\n                     st_transform(2154)\n\nOn extrait ensuite les équipements qui nous intéressent en ne retenant dans un premier temps que ceux qui sont présents dans la commune :\n\nmyequ &lt;- equ %&gt;% filter(typ_code==2802,\n                        insee_com == \"94071\") %&gt;%\n                  mutate(w=1) %&gt;%\n                  select(w) %&gt;%\n                  st_transform(2154)\n\nOn vérifie à l’aide d’une carte que tout se superpose bien :\n\n# carte de base de type polygone\nmf_map(mymap, type=\"base\", \n       col=\"lightyellow\")\n\n# Carte de stock\nmf_map(mypop, type=\"prop\",\n       var=\"w\",\n       inches=0.05,           # réglage de la taille dez symboles\n       symbol = \"square\",     # forme des symboles\n       col=\"red\",              \n       leg_pos = \"topright\",       # position de la légende\n       leg_title = \"Population\")    # Titre de la légende\n\n\n# Carte de base de type point\nmf_map(myequ, type=\"base\",\n       pch=20,\n       col=\"black\",\n       leg_pos = \"topleft\",\n       leg_title = \"Equipement\",\n       add=T)                    # Superposition sur les cartes précédentes\n\n# Titre, cadre, échelle, source ...\nmf_layout(title = \"Population et ressources\",\n          scale = T, \n          frame=T,\n          arrow=F,\n          credits = \"Source : INSEE et Min. Sports, 2024\"\n          )\n\n\n\n\n\n\nCalcul de la distance Population x Ressource\nLe calcul va être effectué par la fonction st_distance() du package sf. Elle ne fonctionne que si le fonds de carte a été projetée, ce que nous avons fait avant. On la transforme en numérique puis en matrice et on calcule pour chaque point de population sa distance minimum à l’équipement choisi en mètres\n\nD &lt;-st_distance(mypop, myequ, by_element = F) \nclass(D)&lt;-\"matrix\"\nD[1:3,1:5]\n\n         [,1]     [,2]     [,3]     [,4]     [,5]\n[1,] 3855.405 3971.156 1465.316 4122.109 4060.326\n[2,] 1787.188 1936.501 1319.309 2055.465 1989.679\n[3,] 2163.856 2321.926 1346.151 2430.599 2363.762\n\n\n\n\nCalcul de la distance minimum\nOn calcule pour chaque point de la grille population sa distance minimale à l’équipement et on effectue la moyenne pondérée :\n\nmypop$Dmin &lt;- apply(D,1,min)\nDmintot &lt;- sum(mypop$Dmin*mypop$w)/sum(mypop$w)\nDmintot\n\n[1] 837.692\n\n\nOn constate que les habitants de la commune sont en moyenne à 837.6 mètres de l’équipement le plus proche.\n\n\nCourbe d’accessibilité minimale de la population\nUne solution plus générale consiste à calculer une courbe de fréquence cumulée indiquant combien d’habitants sont situés à moins d’une certaine distance de l’équipement.\n\ntabfreq&lt;-data.frame(dis= mypop$Dmin, pop = mypop$w) %&gt;% \n              arrange(dis) %&gt;%\n              mutate(cumpop=cumsum(pop)) %&gt;%\n              mutate(cumfreq=100*cumpop/sum(pop))\nhead(tabfreq)\n\n       dis   pop cumpop   cumfreq\n1  0.00000   3.0    3.0 0.0112049\n2  0.00000  21.0   24.0 0.0896392\n3  0.00000 118.0  142.0 0.5303653\n4  0.00000   3.0  145.0 0.5415702\n5 59.90465 443.5  588.5 2.1980279\n6 71.12526 181.0  769.5 2.8740569\n\n\nOn voit ainsi par exemple que 769 habitants sont situés à moins de 178 mètres de l’équipement ce qui représente 2.87% de la population de la commune. On trace le résultat avec ggplot2 :\n\np&lt;-ggplot(tabfreq) + aes(x=dis, y=cumfreq) +\n                     geom_line() +\n                     scale_x_continuous(name = \"Distance minimale à l'équipement\") +\n                     scale_y_continuous(name = \"% de la population\") +\n                     ggtitle(\"Courbe d'accessibilité minimale\")\nggplotly(p)\n\n\n\n\n\nOn peut alors voir en promenant le curseur sur la courbe quel % de la poplation se trouve à moins d’une certaine distance de l’équipement le plus proche et répondre aux questions telles que :\n\nQ1 : quel % de la population est située à moins de 500 m ? environ 26%\nQ2 : quel % de la population est située à plus de 1500 m ? environ 4%\nQ3 : A quelle distance se trouvent les 10% les plus favorisés ? moins de 258 m\nQ4 : A quelle distance se trouvent les 10% les moins favorisés ? plus de 1371m\nQ5 : quelle est la distance médiane à l’équipement le plus proche ? 900 m\n\n\n\nCartographie\nOn peut faire une carte représentant la localisation et l’effectif des populations favorisés et défavorisés. On va utiliser pour cela des carrés dont la surface sera proportionnlle à la population et la couleur à l’accessibilité minimale à l’équipement le plus proche. On utilisera comme seuil cartographique de référence la distance moyenne et ses valeurs divisées par deux ou multipliées par deux.\n\nmf_map(mymap, type=\"base\", \n       col=\"lightyellow\")\n\n\nmybreaks&lt;-c(min(mypop$Dmin), Dmintot/2, Dmintot, Dmintot*2, max(mypop$Dmin))\nmypal&lt;-rev(brewer.pal(4,\"RdYlBu\"))\n\nmf_map(mypop, type=\"prop_choro\",\n       var=c(\"w\", \"Dmin\"),\n       inches=0.05,\n       pal=mypal,\n       breaks=mybreaks,\n       symbol = \"square\",\n       leg_pos = c(\"topleft\",\"topright\"),\n       leg_title = c(\"Population\", \"Distance minimale (en m)\"),\n       leg_val_rnd = c(0,0)\n        )\n\nmf_map(myequ, type=\"base\",\n       pch=20,\n       col=\"black\",\n       leg_pos = \"topleft\",\n       leg_title = \"Equipement\",\n       add=T)\nmf_layout(title = \"Accessibilité de la population à la ressource\",\n          scale = T, \n          frame=T,\n          arrow=F,\n          credits = \"Source : INSEE et Min. Sports, 2024\"\n          )\n\n\n\n\n\n\nExercice : refaire les calculs précédents pour tout le Grand Paris\n\n## Chargement des fichiers\nmymap &lt;- mapcom %&gt;%  st_transform(2154)\n\nmypop &lt;- gridpop %&gt;%  select(w = \"Ind\") %&gt;%\n                     st_transform(2154)\n\nmyequ &lt;- equ %&gt;% filter(typ_code==2802) %&gt;%\n                  mutate(w=1) %&gt;%\n                  select(w) %&gt;%\n                  st_transform(2154)\n\n## Calcul de la matrice de distance\nD &lt;-st_distance(mypop, myequ, by_element = F) \nclass(D)&lt;-\"matrix\"\nD[1:3,1:5]\n\n         [,1]      [,2]     [,3]     [,4]     [,5]\n[1,] 5253.313  352.0405 4367.758 6420.792 6979.968\n[2,] 3212.081 3890.0556 2882.108 3799.088 3930.807\n[3,] 5580.766  906.8593 4756.769 6655.044 7102.999\n\n## Calcul de la distance minimale moyenne\nmypop$Dmin &lt;- apply(D,1,min)\nDmintot &lt;- sum(mypop$Dmin*mypop$w)/sum(mypop$w)\nDmintot\n\n[1] 750.3469\n\n## Tableau de distance cumulée\ntabfreq&lt;-data.frame(dis= mypop$Dmin, pop = mypop$w) %&gt;% \n              arrange(dis) %&gt;%\n              mutate(cumpop=cumsum(pop)) %&gt;%\n              mutate(cumfreq=100*cumpop/sum(pop))\nhead(tabfreq)\n\n  dis   pop cumpop     cumfreq\n1   0 243.0  243.0 0.003653544\n2   0 140.0  383.0 0.005758467\n3   0   5.0  388.0 0.005833643\n4   0 563.5  951.5 0.014305957\n5   0  94.0 1045.5 0.015719262\n6   0   7.5 1053.0 0.015832026\n\n## Graphique d'accessibilité\np&lt;-ggplot(tabfreq) + aes(x=dis, y=cumfreq) +\n                     geom_line() +\n                     scale_x_continuous(name = \"Distance minimale à l'équipement\") +\n                     scale_y_continuous(name = \"% de la population\") +\n                     ggtitle(\"Courbe d'accessibilité minimale\")\nggplotly(p)\n\n\n\n\n## Carte d'accessibilité\n\nmf_map(mymap, type=\"base\", \n       col=\"lightyellow\")\n\n\nmybreaks&lt;-c(min(mypop$Dmin), Dmintot/2, Dmintot, Dmintot*2, max(mypop$Dmin))\nmypal&lt;-rev(brewer.pal(4,\"RdYlBu\"))\n\nmf_map(mypop, type=\"prop_choro\",\n       var=c(\"w\", \"Dmin\"),\n       inches=0.05,\n       pal=mypal,\n       border = NA,\n       breaks=mybreaks,\n       symbol = \"square\",\n       leg_pos = c(\"topleft\",\"topright\"),\n       leg_title = c(\"Population\", \"Distance minimale (en m)\"),\n       leg_val_rnd = c(0,0)\n        )\n\nmf_map(myequ, type=\"base\",\n       pch=20,\n       cex=0.2,\n       col=\"black\",\n       leg_pos = \"topleft\",\n       leg_title = \"Equipement\",\n       add=T)\nmf_layout(title = \"Accessibilité de la population aux terrain de football le plus proche \",\n          scale = T, \n          frame=T,\n          arrow=F,\n          credits = \"Source : INSEE et Min. Sports, 2024\"\n          )"
  },
  {
    "objectID": "41-ANSPA-access.html#potentiel",
    "href": "41-ANSPA-access.html#potentiel",
    "title": "Accessibilité et Potentiel",
    "section": "POTENTIEL",
    "text": "POTENTIEL\nOn repart de la matrice des distances mais on va calculer cette fois-ci le nombre d’équipement situés à moins d’une certaine distance du lieu d’habitat. On va utiliser cette fois-ci les centres de commune comme point de référence :\n\nPréparation des données\n\nmycom &lt;- mapcom %&gt;% st_transform(2154)\nmyequ &lt;- equ %&gt;% filter(typ_code==2802) %&gt;%\n                  st_transform(2154)\n\n\n\nDistance\n\nmatdis &lt;-st_distance(mycom,myequ)\nmatdis&lt;-as.matrix(matdis)\nclass(matdis)&lt;-\"matrix\"\nrow.names(matdis)&lt;-mycom$insee_com\nmatdis[1:5,1:7]\n\n           [,1]      [,2]      [,3]      [,4]      [,5]      [,6]      [,7]\n75119  2923.439     0.000  1984.378  4149.837  4732.112  6842.183  6240.701\n75106  5101.953  5582.947  5044.986  5181.630  4750.000  8941.392  8257.951\n93071 11199.722 10019.160 10589.325 12318.792 13406.187 11929.699 11836.841\n94056 19504.036 25241.280 20382.510 18446.918 18215.258 15436.621 16011.799\n94041  3376.855  8172.080  4180.139  2185.553  1107.208  3733.509  3302.157\n\n\n\n\nCalcul du nombre d’équipement à moins de 1000 m\nOn transforme la matrice en 0 ou 1 selon la distance\n\nmat2000 &lt;- matdis&lt;1000\nmycom$pot2000&lt;-apply(mat2000,1,sum)\n\n\n\nCartographie du résultat\n\nmf_map(mycom, type = \"choro\",\n       var=\"pot2000\",\n       breaks=c(0,5,10,15,20,25,30,max(mycom$pot2000)),\n       leg_pos = \"topright\",\n       leg_title = \"nb. equipt &lt; 1000 m\",\n       leg_val_rnd = 0)\n\nmf_map(myequ, type=\"base\",\n       pch=20,\n       cex=0.4,\n       col=\"red\",\n\n       add=TRUE)\n\nmf_layout(title= \"Potentiel d'équipement\",\n          frame=T,\n          credits = \"Source : INSEE & Min. des Sports\")"
  },
  {
    "objectID": "41-ANSPA-access.html#prolongements",
    "href": "41-ANSPA-access.html#prolongements",
    "title": "Accessibilité et Potentiel",
    "section": "PROLONGEMENTS",
    "text": "PROLONGEMENTS\nNous avons été très rapide sur la notion de potentiel. Les personnes intéressées pour en savoir plus pourront lire en premier la vignette du Package R potential qui résume de façon rapide les principes du calcul de potentiel et décrivent les fonctions à mettre en oeuvre sous R pour réaliser une carte de potentiel.\nPour une compréhension plus approfondie du concept, on pourra se reporter aux articles de Grasland, 1990 ou de Grasland & al., 1993 qui ont profondément renouveler les méthodes de calcul du potentiel par rapport à la formulation initiale de J.Q. Stewart, 1947 qui était inspirée des lois de la gravitation universelle."
  },
  {
    "objectID": "21-CARTO-ParisPC.html",
    "href": "21-CARTO-ParisPC.html",
    "title": "Jointures",
    "section": "",
    "text": "On charge les packages suivants\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks jsonlite::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n## Data.table (pour sa fonction d'importation fread)\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n## Cartographie thématique\nlibrary(mapsf)\n\n\n\n\nOn constitue un fichier des individus localisés dans les communes de Paris et Petite Couronne au RP de 2019 en reprenant le programme décrit dans le Cours n°1 de Camille Signoretto.\nLe programme ci-dessous comporte la mention “eval=FALSE” car il ne dout être executé qu’une seule fois.\n\n## Récupération des fichiers INSEE zippé\n## On utilise pour cela un dossier \"tmp\" \ndownload.file(url=\"https://www.insee.fr/fr/statistiques/fichier/6544333/RP2019_INDCVIZA_csv.zip\",\n              destfile = \"tmp/RP2019_INDCVIZA_csv.zip\")\nunzip(\"tmp/RP2019_INDCVIZA_csv.zip\", exdir = \"tmp\")\n\n## Lecture du fichier individu avec fread\nlibrary(data.table)\nRP &lt;- fread(\"tmp/FD_INDCVIZA_2019.csv\", stringsAsFactors=TRUE)\nRP &lt;- as.data.frame(RP)\n## Selection Paris PC \nRP &lt;- RP %&gt;% filter(DEPT %in% c(75, 92, 93, 94))\nsaveRDS(RP, \"data/RP/RP_final.RDS\")\n\n## Lecture du fichier de métadonnées\nmeta &lt;- read.csv(file = 'tmp/Varmod_INDCVI_2019.csv',\n                 sep = \";\",\n                 encoding = \"UTF-8\",\n                 stringsAsFactors = TRUE)\n\n## Sauvegarde des deux fichiers\nsaveRDS(meta, \"data/RP/meta.RDS\")\n\n## nettoyage du dossier  tmp\nunlink(\"tmp/*\")\n\n\n\n\nOn va maintenant acquérir le fichier des unités géographiques les plus petites (IRIS) pour la zone Paris + Petite Couronne. On se servira de ce fonds de carte des IRIS pour générer ensuite ceux des unités géographiques de niveau supérieur : communes, territoires, départements …\nComme les IRIS changent au cours du temps, il faut choisir le bon “millésime” pour que la correspondance soit possible avec les données individuelles du recensement. On utilise un lien de téléchargement depuis la base des iris millésimé accessible sur public.opendatasoft\nComme précédemment, ce programme est à executer une seule fois d’où la mention eval=FALSE dans l’en-tête du chunk.\n\n## Lien de téléchargement IDF 2019 au forma geojson\nmyurl &lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/georef-france-iris-millesime/exports/geojson?lang=fr&refine=year%3A%222019%22&refine=reg_name%3A%22%C3%8Ele-de-France%22&facet=facet(name%3D%22reg_name%22%2C%20disjunctive%3Dtrue)&timezone=Europe%2FBerlin\"\n\n## téléchargement et conversion au format sf\ngeo&lt;-geojson_sf(myurl)\ngeo&lt;-geo %&gt;% select(iris_type,\n                    iris_code, \n                    iris_name,\n                    com_code= com_arm_code,\n                    com_name = com_arm_name,\n                    dep_code,\n                    dep_name,\n                    geometry)\n\n## Nettoyage des chaînes de caractère\nclean_char &lt;- function(x) {\n  y&lt;-gsub('\\\\[\\\"','',x)\n  y&lt;-gsub('\\\"\\\\]','',y)\n  return(y)\n}\ngeo &lt;- geo %&gt;% mutate(iris_code = clean_char(iris_code),\n                      iris_name = clean_char(iris_name),\n                      com_code = clean_char(com_code),\n                      com_name = clean_char(com_name),\n                      dep_code = clean_char(dep_code),\n                      dep_name = clean_char(dep_name),\n                      )\n\n\n\n## Selection Paris PC\ngeo&lt;-geo %&gt;% filter(dep_code %in% c(\"75\",\"92\",\"93\",\"94\"))\n#plot(geo[\"iris_type\"])\n\n## Sauvegarde\n\nsaveRDS(geo,\"data/RP/map_iris.RDS\" )\n\n\n## Carto rapide\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nplot(map_iris[\"dep_code\"], main = \"IRIS\")\n\n\n\n\n\n\n\nOn agrège par le nom et le code de la commune et on conserve le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_com &lt;- map_iris %&gt;% group_by(com_code, com_name) %&gt;% \n                  summarise(dep_code = max(dep_code),\n                            dep_name = max(dep_name))\nplot(map_com[\"dep_code\"], main = \"Communes\")\n\n\n\nsaveRDS(map_com, \"DATA/RP/map_com.RDS\")\n\n\n\n\nOn agrège simplement par le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_dep &lt;- map_iris %&gt;% group_by(dep_code, dep_name) %&gt;% \n                  summarise()\nplot(map_dep[\"dep_code\"], main = \"Départements\")\n\n\n\nsaveRDS(map_dep, \"DATA/RP/map_dep.RDS\")\n\n\n\n\nNous allons maintenant examiner comment agréger les données individuelles de l’INSEE par iris, commune ou département et effectuer une jointure avec les fonds de cartes que nous avons préparé. On va s’appuyer pour cela sur le cours de datamining n°2 de Camille Signoretto.\nOn commence par recharger la fonction somme()que nous avions créé :\n\nsomme &lt;- function(data, var_gpe, nom_var){\n  som &lt;- data %&gt;% \n    group_by({{var_gpe}}) %&gt;% \n    count({{nom_var}}, wt=IPONDI) %&gt;% \n    mutate(n=round(n)) %&gt;% \n    pivot_wider(names_from = {{nom_var}}, values_from = n)\n  \n  return(som)\n}\n\nNous l’utilisons pour créer un tableau des individus par CSP simplifiées en 5 catégories et par IRIS :\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\"))\n\n# Agrégation par IRIS  \niris_csp &lt;- somme(data = indiv,\n                 var_gpe = IRIS,\n                 nom_var = TACT5)\n\n\n\n\nOn procède à la jointure des deux fichiers iris en utilisant le code des iris.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_iris_csp&lt;- left_join(map_iris, iris_csp,by = c(\"iris_code\"=\"IRIS\"))\nsaveRDS(map_iris_csp, \"data/RP/map_iris_CSP.RDS\")\n\nOn examine quels IRIS ne sont pas renseignés en croisant cette information avec le type d’IRIS.\n\nmap_iris_csp$missing&lt;-case_when(is.na(map_iris_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_iris_csp[\"missing\"], main = \"IRIS sans données\")\n\n\n\ntab&lt;-table(map_iris_csp$missing,map_iris_csp$iris_type)\naddmargins(tab)\n\n          \n           commune iris d'activité iris d'habitat iris divers  Sum\n  Manquant       7              44              5          40   96\n  OK             0              74           2572           7 2653\n  Sum            7             118           2577          47 2749\n\n\nOn constate qu’il manque des données pour 96 IRIS sur 2749. Il s’agit dans la plupart des cas d’iris correspondant à des zones industrielles ou des forêts dont le nombre d’habitant est trop faible pour que les données soient mises à disposition au niveau individuel. Cela concerne également 7 communes de petites tailles et 5 iris d’habitat.\n\n\n\nOn reprend les programmes précédents par commune\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\")) \n\n# Extraction du code communal \nindiv&lt;- indiv %&gt;%   mutate(com_code = substr(IRIS,1,5))\n\n# Agrégation par IRIS  \ncom_csp &lt;- somme(data = indiv,\n                 var_gpe = com_code,\n                 nom_var = TACT5)\n\n# Chargement du fonds de carte communal\nmap_com &lt;- readRDS(\"data/RP/map_com.RDS\")\n\n# Jointure\nmap_com_csp &lt;- left_join(map_com, com_csp)\n\n# Sauvegarde\nsaveRDS(map_com_csp, \"data/RP/map_com_csp.RDS\")\n\n# Analyse des valeurs manquantes\nmap_com_csp$missing&lt;-case_when(is.na(map_com_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_com_csp[\"missing\"], main= \"Communes sans données\")\n\n\n\n\nOn retrouve les 7 communes manquantes pour lesquelles l’INSEE ne fournit pas les données dans le fichier détail des individus."
  },
  {
    "objectID": "21-CARTO-ParisPC.html#preparation-du-travail",
    "href": "21-CARTO-ParisPC.html#preparation-du-travail",
    "title": "Jointures",
    "section": "",
    "text": "On charge les packages suivants\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks jsonlite::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n## Data.table (pour sa fonction d'importation fread)\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n## Cartographie thématique\nlibrary(mapsf)\n\n\n\n\nOn constitue un fichier des individus localisés dans les communes de Paris et Petite Couronne au RP de 2019 en reprenant le programme décrit dans le Cours n°1 de Camille Signoretto.\nLe programme ci-dessous comporte la mention “eval=FALSE” car il ne dout être executé qu’une seule fois.\n\n## Récupération des fichiers INSEE zippé\n## On utilise pour cela un dossier \"tmp\" \ndownload.file(url=\"https://www.insee.fr/fr/statistiques/fichier/6544333/RP2019_INDCVIZA_csv.zip\",\n              destfile = \"tmp/RP2019_INDCVIZA_csv.zip\")\nunzip(\"tmp/RP2019_INDCVIZA_csv.zip\", exdir = \"tmp\")\n\n## Lecture du fichier individu avec fread\nlibrary(data.table)\nRP &lt;- fread(\"tmp/FD_INDCVIZA_2019.csv\", stringsAsFactors=TRUE)\nRP &lt;- as.data.frame(RP)\n## Selection Paris PC \nRP &lt;- RP %&gt;% filter(DEPT %in% c(75, 92, 93, 94))\nsaveRDS(RP, \"data/RP/RP_final.RDS\")\n\n## Lecture du fichier de métadonnées\nmeta &lt;- read.csv(file = 'tmp/Varmod_INDCVI_2019.csv',\n                 sep = \";\",\n                 encoding = \"UTF-8\",\n                 stringsAsFactors = TRUE)\n\n## Sauvegarde des deux fichiers\nsaveRDS(meta, \"data/RP/meta.RDS\")\n\n## nettoyage du dossier  tmp\nunlink(\"tmp/*\")\n\n\n\n\nOn va maintenant acquérir le fichier des unités géographiques les plus petites (IRIS) pour la zone Paris + Petite Couronne. On se servira de ce fonds de carte des IRIS pour générer ensuite ceux des unités géographiques de niveau supérieur : communes, territoires, départements …\nComme les IRIS changent au cours du temps, il faut choisir le bon “millésime” pour que la correspondance soit possible avec les données individuelles du recensement. On utilise un lien de téléchargement depuis la base des iris millésimé accessible sur public.opendatasoft\nComme précédemment, ce programme est à executer une seule fois d’où la mention eval=FALSE dans l’en-tête du chunk.\n\n## Lien de téléchargement IDF 2019 au forma geojson\nmyurl &lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/georef-france-iris-millesime/exports/geojson?lang=fr&refine=year%3A%222019%22&refine=reg_name%3A%22%C3%8Ele-de-France%22&facet=facet(name%3D%22reg_name%22%2C%20disjunctive%3Dtrue)&timezone=Europe%2FBerlin\"\n\n## téléchargement et conversion au format sf\ngeo&lt;-geojson_sf(myurl)\ngeo&lt;-geo %&gt;% select(iris_type,\n                    iris_code, \n                    iris_name,\n                    com_code= com_arm_code,\n                    com_name = com_arm_name,\n                    dep_code,\n                    dep_name,\n                    geometry)\n\n## Nettoyage des chaînes de caractère\nclean_char &lt;- function(x) {\n  y&lt;-gsub('\\\\[\\\"','',x)\n  y&lt;-gsub('\\\"\\\\]','',y)\n  return(y)\n}\ngeo &lt;- geo %&gt;% mutate(iris_code = clean_char(iris_code),\n                      iris_name = clean_char(iris_name),\n                      com_code = clean_char(com_code),\n                      com_name = clean_char(com_name),\n                      dep_code = clean_char(dep_code),\n                      dep_name = clean_char(dep_name),\n                      )\n\n\n\n## Selection Paris PC\ngeo&lt;-geo %&gt;% filter(dep_code %in% c(\"75\",\"92\",\"93\",\"94\"))\n#plot(geo[\"iris_type\"])\n\n## Sauvegarde\n\nsaveRDS(geo,\"data/RP/map_iris.RDS\" )\n\n\n## Carto rapide\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nplot(map_iris[\"dep_code\"], main = \"IRIS\")\n\n\n\n\n\n\n\nOn agrège par le nom et le code de la commune et on conserve le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_com &lt;- map_iris %&gt;% group_by(com_code, com_name) %&gt;% \n                  summarise(dep_code = max(dep_code),\n                            dep_name = max(dep_name))\nplot(map_com[\"dep_code\"], main = \"Communes\")\n\n\n\nsaveRDS(map_com, \"DATA/RP/map_com.RDS\")\n\n\n\n\nOn agrège simplement par le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_dep &lt;- map_iris %&gt;% group_by(dep_code, dep_name) %&gt;% \n                  summarise()\nplot(map_dep[\"dep_code\"], main = \"Départements\")\n\n\n\nsaveRDS(map_dep, \"DATA/RP/map_dep.RDS\")\n\n\n\n\nNous allons maintenant examiner comment agréger les données individuelles de l’INSEE par iris, commune ou département et effectuer une jointure avec les fonds de cartes que nous avons préparé. On va s’appuyer pour cela sur le cours de datamining n°2 de Camille Signoretto.\nOn commence par recharger la fonction somme()que nous avions créé :\n\nsomme &lt;- function(data, var_gpe, nom_var){\n  som &lt;- data %&gt;% \n    group_by({{var_gpe}}) %&gt;% \n    count({{nom_var}}, wt=IPONDI) %&gt;% \n    mutate(n=round(n)) %&gt;% \n    pivot_wider(names_from = {{nom_var}}, values_from = n)\n  \n  return(som)\n}\n\nNous l’utilisons pour créer un tableau des individus par CSP simplifiées en 5 catégories et par IRIS :\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\"))\n\n# Agrégation par IRIS  \niris_csp &lt;- somme(data = indiv,\n                 var_gpe = IRIS,\n                 nom_var = TACT5)\n\n\n\n\nOn procède à la jointure des deux fichiers iris en utilisant le code des iris.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_iris_csp&lt;- left_join(map_iris, iris_csp,by = c(\"iris_code\"=\"IRIS\"))\nsaveRDS(map_iris_csp, \"data/RP/map_iris_CSP.RDS\")\n\nOn examine quels IRIS ne sont pas renseignés en croisant cette information avec le type d’IRIS.\n\nmap_iris_csp$missing&lt;-case_when(is.na(map_iris_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_iris_csp[\"missing\"], main = \"IRIS sans données\")\n\n\n\ntab&lt;-table(map_iris_csp$missing,map_iris_csp$iris_type)\naddmargins(tab)\n\n          \n           commune iris d'activité iris d'habitat iris divers  Sum\n  Manquant       7              44              5          40   96\n  OK             0              74           2572           7 2653\n  Sum            7             118           2577          47 2749\n\n\nOn constate qu’il manque des données pour 96 IRIS sur 2749. Il s’agit dans la plupart des cas d’iris correspondant à des zones industrielles ou des forêts dont le nombre d’habitant est trop faible pour que les données soient mises à disposition au niveau individuel. Cela concerne également 7 communes de petites tailles et 5 iris d’habitat.\n\n\n\nOn reprend les programmes précédents par commune\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\")) \n\n# Extraction du code communal \nindiv&lt;- indiv %&gt;%   mutate(com_code = substr(IRIS,1,5))\n\n# Agrégation par IRIS  \ncom_csp &lt;- somme(data = indiv,\n                 var_gpe = com_code,\n                 nom_var = TACT5)\n\n# Chargement du fonds de carte communal\nmap_com &lt;- readRDS(\"data/RP/map_com.RDS\")\n\n# Jointure\nmap_com_csp &lt;- left_join(map_com, com_csp)\n\n# Sauvegarde\nsaveRDS(map_com_csp, \"data/RP/map_com_csp.RDS\")\n\n# Analyse des valeurs manquantes\nmap_com_csp$missing&lt;-case_when(is.na(map_com_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_com_csp[\"missing\"], main= \"Communes sans données\")\n\n\n\n\nOn retrouve les 7 communes manquantes pour lesquelles l’INSEE ne fournit pas les données dans le fichier détail des individus."
  },
  {
    "objectID": "31-PROJET-data.html",
    "href": "31-PROJET-data.html",
    "title": "Projet-Données",
    "section": "",
    "text": "library(knitr)\n## Global options\noptions(max.print=\"80\")\nopts_chunk$set(echo=TRUE,\n               cache=FALSE,\n               prompt=FALSE,\n               tidy=FALSE,\n               comment=NA,\n               message=FALSE,\n               warning=FALSE,\n               options(scipen=999))\nopts_knit$set(width=75)\n\n# Packages utilitaires\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n#library(rmdformats)\n\n# Packages graphiques\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n#packages cartographiques \nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n#library(leaflet)\n#library(htmlwidgets)\n#library(htmltools)\n\n# Appel d'API\n#library(httr)\n#library(jsonlite)\nlibrary(geojsonsf)\nL’objectif de ce chapitre est de charger une base de données originale, de la mettre en forme, de la nettoyer et de préparer une série de fonctions permettant de l’exploiter en vue de la création d’une application shiny."
  },
  {
    "objectID": "31-PROJET-data.html#présentation",
    "href": "31-PROJET-data.html#présentation",
    "title": "Projet-Données",
    "section": "Présentation",
    "text": "Présentation\nLa base qui nous intéresse est un invetaire des licenciés sportifs par commune, âge, sexe de 2011 à 2023 établie par le ministère des sports et accessible à l’aide de ce lien\nLa base est décrite ainsi :\nLe recensement annuel des licences auprès des fédérations sportives agréées par le ministère en charge des sports permet de mesurer le niveau et l’évolution dans le temps de la pratique sportive encadrée. Ces statistiques fournissent un éclairage pour les politiques publiques de développement du sport, tant au niveau national que territorial. Il s’agit d’un recensement au lieu d’habitation de la personne et non au lieu de pratique.Les données issues du recensement sont dans un second temps géocodées par l’Insee pour métropole+DROM (hors Mayotte), afin de pouvoir communiquer ces fichiers au niveau communal. Les données ne sont pas disponibles pour l’ensemble des fédérations. Un certain nombre d’entre elles ne disposaient pas de données totalement géolocalisables à la commune permettant une exploitation exhaustive. Les données géocodées ont donc été traitées afin de pouvoir communiquer une estimation du nombre de licences par commune et par fédération. Les données de millésime N correspondent à la saison N-1/N ou à l’année civile N selon le fonctionnement des fédérations (ex : lic-data-2021 est une répartition des licences de la saison 2020/2021 ou de l’année 2021).\nContrairement à la base des équipements sportifs que nous avons commencé à analyser dans le chapitre de cours consacré à leaflet, cette base de données ne fournit pas la position individuelle des personnes qui pratiquent un sport mais seulement leur effectif par commune. Elle a toutefois été complétée par une extraction de la base du recensement qui a été vue dans les cours précédents afin de connaître le nombre de personne par âge et par sexe dans les communes. On pourra ainsi disposer d’un dénominateur permettant de calculer le pourcentage de personnes d’un âge ou d’un sexe donné qui disposent d’une licence dans tel ou tel sport.\nIl faut toutefois préciser d’emblée quelques limites de cette base :\n\nLa base fournit le nombre de licenciés d’une fédération sportive et non pas le nombre de personnes qui pratiquent un sport. Elle ne correspond donc pas aux personnes qui pratiquent un sport pour deux raisons : (1) certains licenciés sont des arbitres ou des entraineurs qui ne pratiquent pas directement le sport et (2) beaucoup de personnes pratiquent un sport sans avoir de licence. Il y a donc un biais à estimer.\nLa population de référence fournie par le recensement est également une estimation puisqu’en France le recensement s’opère par sondage sur période de 5 ans. Le recensement de 2017 est en réalité une moyenne de la population 2015-2019.\nLa pratique de certains sport dépend de la disponibilité d’équipements spécifiques qui ne sont pas partout disponible. Une faible pratique du football à Paris n’aura ainsi rien d’étonnant puisque cette commune dispose de peu de terrains. Nous reviendrons sur cette question dans le prochain chapitre."
  },
  {
    "objectID": "31-PROJET-data.html#données",
    "href": "31-PROJET-data.html#données",
    "title": "Projet-Données",
    "section": "Données",
    "text": "Données\nOn choisit de travailler sur la base de données 2018 et on rappatrie deux fichiers correspondant respectivement aux clubs et aux licenciés. On sélectionne l’ensemble de la région Ile de France. On procédera ultérieurement à l’extraction des communes du Grand Paris mais on souhaite connaître les valeurs globale de l’ensemble de la région.\n\nFichier des licenciés\n\nlic&lt;-read.csv2(\"https://www.data.gouv.fr/fr/datasets/r/f3970a7b-df0e-4c3e-9f36-c93da58f4a3e\", \n               fileEncoding = \"Latin1\") %&gt;%\n     filter(region==\"Île-de-France\")\nsaveRDS(lic,\"data/sport/lic_2018_idf.RDS\")\n\n\nlic &lt;- readRDS(\"data/sport/lic_2018_idf.RDS\")\nglimpse(lic)\n\nRows: 56,834\nColumns: 68\n$ code_commune    &lt;chr&gt; \"75101\", \"75101\", \"75101\", \"75101\", \"75101\", \"75101\", …\n$ libelle         &lt;chr&gt; \"Paris 1er Arrondissement\", \"Paris 1er Arrondissement\"…\n$ region          &lt;chr&gt; \"Île-de-France\", \"Île-de-France\", \"Île-de-France\", \"Îl…\n$ fed_2018        &lt;int&gt; 101, 102, 103, 106, 108, 109, 110, 111, 112, 113, 114,…\n$ nom_fed         &lt;chr&gt; \"FF d'athlétisme\", \"FF d'aviron\", \"FF de badminton\", \"…\n$ l_2018          &lt;int&gt; 28, 99, 23, 28, 4, 109, 46, 106, 18, 86, 2, 26, 3, 138…\n$ l_0_4_2018      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 4, 0, 0, 0, 0, …\n$ l_5_9_2018      &lt;int&gt; 0, 0, 0, 0, 0, 24, 9, 6, 7, 17, 0, 0, 0, 72, 0, 7, 1, …\n$ l_10_14_2018    &lt;int&gt; 8, 7, 2, 3, 1, 32, 13, 29, 2, 26, 0, 5, 0, 31, 0, 9, 2…\n$ l_15_19_2018    &lt;int&gt; 1, 32, 5, 5, 1, 9, 5, 17, 3, 7, 0, 3, 2, 12, 0, 6, 4, …\n$ l_20_29_2018    &lt;int&gt; 5, 13, 4, 4, 2, 14, 3, 23, 2, 7, 2, 12, 1, 7, 1, 3, 0,…\n$ l_30_44_2018    &lt;int&gt; 6, 15, 11, 9, 0, 15, 4, 24, 1, 6, 0, 5, 0, 5, 0, 7, 1,…\n$ l_45_59_2018    &lt;int&gt; 5, 25, 1, 5, 0, 11, 7, 6, 2, 11, 0, 1, 0, 6, 0, 2, 5, …\n$ l_60_74_2018    &lt;int&gt; 1, 7, 0, 2, 0, 3, 5, 1, 0, 9, 0, 0, 0, 0, 0, 2, 1, 0, …\n$ l_75_2018       &lt;int&gt; 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, …\n$ l_f_2018        &lt;int&gt; 9, 38, 5, 8, 0, 78, 19, 6, 16, 54, 0, 10, 1, 34, 1, 12…\n$ l_0_4_f_2018    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ l_5_9_f_2018    &lt;int&gt; 0, 0, 0, 0, 0, 22, 1, 0, 7, 13, 0, 0, 0, 17, 0, 2, 1, …\n$ l_10_14_f_2018  &lt;int&gt; 2, 2, 0, 0, 0, 23, 6, 0, 1, 11, 0, 2, 0, 7, 0, 3, 1, 0…\n$ l_15_19_f_2018  &lt;int&gt; 0, 8, 1, 2, 0, 9, 2, 1, 3, 6, 0, 1, 0, 3, 0, 5, 1, 2, …\n$ l_20_29_f_2018  &lt;int&gt; 2, 6, 2, 0, 0, 10, 0, 3, 2, 5, 0, 4, 1, 3, 1, 0, 0, 1,…\n$ l_30_44_f_2018  &lt;int&gt; 3, 6, 1, 4, 0, 9, 2, 2, 1, 3, 0, 3, 0, 1, 0, 1, 1, 0, …\n$ l_45_59_f_2018  &lt;int&gt; 1, 13, 1, 2, 0, 4, 4, 0, 2, 8, 0, 0, 0, 3, 0, 1, 1, 1,…\n$ l_60_74_f_2018  &lt;int&gt; 1, 3, 0, 0, 0, 1, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ l_75_f_2018     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ l_h_2018        &lt;int&gt; 19, 61, 18, 20, 4, 31, 27, 100, 2, 32, 2, 16, 2, 104, …\n$ l_0_4_h_2018    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 0, 0, …\n$ l_5_9_h_2018    &lt;int&gt; 0, 0, 0, 0, 0, 2, 8, 6, 0, 4, 0, 0, 0, 55, 0, 5, 0, 2,…\n$ l_10_14_h_2018  &lt;int&gt; 6, 5, 2, 3, 1, 9, 7, 29, 1, 15, 0, 3, 0, 24, 0, 6, 1, …\n$ l_15_19_h_2018  &lt;int&gt; 1, 24, 4, 3, 1, 0, 3, 16, 0, 1, 0, 2, 2, 9, 0, 1, 3, 5…\n$ l_20_29_h_2018  &lt;int&gt; 3, 7, 2, 4, 2, 4, 3, 20, 0, 2, 2, 8, 0, 4, 0, 3, 0, 0,…\n$ l_30_44_h_2018  &lt;int&gt; 3, 9, 10, 5, 0, 6, 2, 22, 0, 3, 0, 2, 0, 4, 0, 6, 0, 0…\n$ l_45_59_h_2018  &lt;int&gt; 4, 12, 0, 3, 0, 7, 3, 6, 0, 3, 0, 1, 0, 3, 0, 1, 4, 2,…\n$ l_60_74_h_2018  &lt;int&gt; 0, 4, 0, 2, 0, 2, 1, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, …\n$ l_75_h_2018     &lt;int&gt; 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, …\n$ l_qp_2018       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0,…\n$ l_qp_f_2018     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0,…\n$ l_qp_h_2018     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0,…\n$ pop_2017        &lt;int&gt; 16258, 16258, 16258, 16258, 16258, 16258, 16258, 16258…\n$ pop_0_4_2017    &lt;int&gt; 629, 629, 629, 629, 629, 629, 629, 629, 629, 629, 629,…\n$ pop_5_9_2017    &lt;int&gt; 596, 596, 596, 596, 596, 596, 596, 596, 596, 596, 596,…\n$ pop_10_14_2017  &lt;int&gt; 686, 686, 686, 686, 686, 686, 686, 686, 686, 686, 686,…\n$ pop_15_19_2017  &lt;int&gt; 683, 683, 683, 683, 683, 683, 683, 683, 683, 683, 683,…\n$ pop_20_29_2017  &lt;int&gt; 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, …\n$ pop_30_44_2017  &lt;int&gt; 3717, 3717, 3717, 3717, 3717, 3717, 3717, 3717, 3717, …\n$ pop_45_59_2017  &lt;int&gt; 3303, 3303, 3303, 3303, 3303, 3303, 3303, 3303, 3303, …\n$ pop_60_74_2017  &lt;int&gt; 2424, 2424, 2424, 2424, 2424, 2424, 2424, 2424, 2424, …\n$ pop_75_2017     &lt;int&gt; 1321, 1321, 1321, 1321, 1321, 1321, 1321, 1321, 1321, …\n$ popf_2017       &lt;int&gt; 7899, 7899, 7899, 7899, 7899, 7899, 7899, 7899, 7899, …\n$ popf_0_4_2017   &lt;chr&gt; \"283\", \"283\", \"283\", \"283\", \"283\", \"283\", \"283\", \"283\"…\n$ popf_5_9_2017   &lt;chr&gt; \"306\", \"306\", \"306\", \"306\", \"306\", \"306\", \"306\", \"306\"…\n$ popf_10_14_2017 &lt;chr&gt; \"327\", \"327\", \"327\", \"327\", \"327\", \"327\", \"327\", \"327\"…\n$ popf_15_19_2017 &lt;chr&gt; \"356\", \"356\", \"356\", \"356\", \"356\", \"356\", \"356\", \"356\"…\n$ popf_20_29_2017 &lt;chr&gt; \"1 444\", \"1 444\", \"1 444\", \"1 444\", \"1 444\", \"1 444\", …\n$ popf_30_44_2017 &lt;chr&gt; \"1 659\", \"1 659\", \"1 659\", \"1 659\", \"1 659\", \"1 659\", …\n$ popf_45_59_2017 &lt;chr&gt; \"1 545\", \"1 545\", \"1 545\", \"1 545\", \"1 545\", \"1 545\", …\n$ popf_60_74_2017 &lt;chr&gt; \"1 227\", \"1 227\", \"1 227\", \"1 227\", \"1 227\", \"1 227\", …\n$ popf_75_2017    &lt;chr&gt; \"752\", \"752\", \"752\", \"752\", \"752\", \"752\", \"752\", \"752\"…\n$ poph_2017       &lt;int&gt; 8359, 8359, 8359, 8359, 8359, 8359, 8359, 8359, 8359, …\n$ poph_0_4_2017   &lt;chr&gt; \"346\", \"346\", \"346\", \"346\", \"346\", \"346\", \"346\", \"346\"…\n$ poph_5_9_2017   &lt;chr&gt; \"290\", \"290\", \"290\", \"290\", \"290\", \"290\", \"290\", \"290\"…\n$ poph_10_14_2017 &lt;chr&gt; \"359\", \"359\", \"359\", \"359\", \"359\", \"359\", \"359\", \"359\"…\n$ poph_15_19_2017 &lt;chr&gt; \"327\", \"327\", \"327\", \"327\", \"327\", \"327\", \"327\", \"327\"…\n$ poph_20_29_2017 &lt;chr&gt; \"1 455\", \"1 455\", \"1 455\", \"1 455\", \"1 455\", \"1 455\", …\n$ poph_30_44_2017 &lt;chr&gt; \"2 058\", \"2 058\", \"2 058\", \"2 058\", \"2 058\", \"2 058\", …\n$ poph_45_59_2017 &lt;chr&gt; \"1 758\", \"1 758\", \"1 758\", \"1 758\", \"1 758\", \"1 758\", …\n$ poph_60_74_2017 &lt;chr&gt; \"1 197\", \"1 197\", \"1 197\", \"1 197\", \"1 197\", \"1 197\", …\n$ poph_75_2017    &lt;chr&gt; \"569\", \"569\", \"569\", \"569\", \"569\", \"569\", \"569\", \"569\"…\n\n\n\n\nFichier des clubs\nLe nom des variables correspondant aux communes et régions est différent du fichier précédent. Il n’y a pas d’erreur cette fois-ci sur le code\n\nclu&lt;-read.csv2(\"https://www.data.gouv.fr/fr/datasets/r/9348012d-9baa-451b-89e1-55817837c521\", \n               fileEncoding = \"Latin1\") %&gt;%\n     filter(Region==\"Île-de-France\")\nsaveRDS(clu,\"data/sport/clu_2018_idf.RDS\")\n\n\nclu &lt;- readRDS(\"data/sport/clu_2018_idf.RDS\")\nglimpse(clu)\n\nRows: 11,484\nColumns: 8\n$ Code_commune             &lt;chr&gt; \"75101\", \"75101\", \"75101\", \"75101\", \"75101\", …\n$ commune                  &lt;chr&gt; \"Paris 1er Arrondissement\", \"Paris 1er Arrond…\n$ Region                   &lt;chr&gt; \"Île-de-France\", \"Île-de-France\", \"Île-de-Fra…\n$ code_federation          &lt;int&gt; 102, 106, 111, 117, 121, 122, 123, 127, 132, …\n$ nom_federation           &lt;chr&gt; \"FF d'aviron\", \"FF de boxe\", \"FF de football\"…\n$ clubs_sportifs_2018      &lt;int&gt; 0, 1, 4, 1, 1, 0, 3, 0, 1, 0, 1, 1, 1, 1, 0, …\n$ etablissements_prof_2018 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ total_clubs_2018         &lt;int&gt; 0, 1, 4, 1, 1, 0, 3, 1, 1, 0, 1, 1, 1, 1, 0, …\n\n\n\n\nFonds de carte\nOn ajoute un fonds de carte des communes d’Ile de France (au cas où l’on n’en dispose pas déjà). On choisit ici le fonds de carte Geofla 2015 de l’IGN qui présente l’avantage de fournir Paris découpé en arrondissements.\n\nmap&lt;-geojson_sf(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/geoflar-communes-2015/exports/geojson?lang=fr&refine=nom_reg%3A%22ILE-DE-FRANCE%22&timezone=Europe%2FBerlin\")\nsaveRDS(map,\"data/sport/map_com_idf.RDS\")\n\n\nmap&lt;-readRDS(\"data/sport/map_com_idf.RDS\")\npar(mar=c(0,0,0,0))\nplot(map['code_dept'], main=\"Ile de France\")\n\n\n\n\n\n\nJointure\nOn procède à une vérification rapide des codes communaux en effectuant une jointure\n\ndon&lt;-lic %&gt;% group_by(insee_com=code_commune) %&gt;% summarise(pop=sum(pop_2017))\nmapdon&lt;-left_join(map,don)\nmapdon$missing&lt;-is.na(mapdon$pop)\nplot(mapdon['missing'])\n\n\n\n\nIl existe quatre communes manquantes ce qui est lié à des fusions intervenues entre 2015 et 2018. Dans la mesure où elles se situent en dehors de la zone d’étude, on ne va pas s’en inquiéter et garder le fonds de carte actuel."
  },
  {
    "objectID": "31-PROJET-data.html#wrangling",
    "href": "31-PROJET-data.html#wrangling",
    "title": "Projet-Données",
    "section": "Wrangling",
    "text": "Wrangling\nNous allons complètement réorganiser le tableau des licenciés afin de faciliter son utilisation ultérieure\n\nlicenciés - femme\n\nlic_fem &lt;- lic %&gt;% select(code_com=code_commune,\n                       nom_com = libelle,\n                       code_fed = fed_2018,\n                       nom_fed ,\n                       age0004 = l_0_4_f_2018,\n                       age0509 = l_5_9_f_2018,\n                       age1014 = l_10_14_f_2018,\n                       age1519 = l_15_19_f_2018,\n                       age2029 = l_20_29_f_2018,                       \n                       age3044 = l_30_44_f_2018,\n                       age4559 = l_45_59_f_2018,    \n                       age6074 = l_60_74_f_2018,\n                       age7599 = l_75_f_2018)  %&gt;%\n  pivot_longer(cols = 5:13) %&gt;%\n  rename(nblic=value, age=name) %&gt;%\n  mutate(sexe = \"Femme\", age=substr(age,4,7))\n\n\n\nlicenciés - hommes\n\nlic_hom &lt;- lic %&gt;% select(code_com=code_commune,\n                       nom_com = libelle,\n                       code_fed = fed_2018,\n                       nom_fed ,\n                       age0004 = l_0_4_h_2018,\n                       age0509 = l_5_9_h_2018,\n                       age1014 = l_10_14_h_2018,\n                       age1519 = l_15_19_h_2018,\n                       age2029 = l_20_29_h_2018,                       \n                       age3044 = l_30_44_h_2018,\n                       age4559 = l_45_59_h_2018,    \n                       age6074 = l_60_74_h_2018,\n                       age7599 = l_75_h_2018)  %&gt;%\n  pivot_longer(cols = 5:13) %&gt;%\n  rename(nblic=value, age=name) %&gt;%\n  mutate(sexe = \"Homme\",  age=substr(age,4,7))\n\n\n\npopulation - femme\n\npop_fem &lt;- lic %&gt;% select(code_com=code_commune,\n                       nom_com = libelle,\n                       code_fed = fed_2018,\n                       nom_fed ,\n                       age0004 = popf_0_4_2017,\n                       age0509 = popf_5_9_2017,\n                       age1014 = popf_10_14_2017,\n                       age1519 = popf_15_19_2017,\n                       age2029 = popf_20_29_2017,                       \n                       age3044 = popf_30_44_2017,\n                       age4559 = popf_45_59_2017,    \n                       age6074 = popf_60_74_2017,\n                       age7599 = popf_75_2017)  %&gt;%\n  pivot_longer(cols = 5:13) %&gt;%\n  rename(pop=value, age=name) %&gt;%\n  mutate(sexe = \"Femme\", age=substr(age,4,7))\n\n\n\npopulation - hommes\n\npop_hom &lt;- lic %&gt;% select(code_com=code_commune,\n                       nom_com = libelle,\n                       code_fed = fed_2018,\n                       nom_fed ,\n                       age0004 = poph_0_4_2017,\n                       age0509 = poph_5_9_2017,\n                       age1014 = poph_10_14_2017,\n                       age1519 = poph_15_19_2017,\n                       age2029 = poph_20_29_2017,                       \n                       age3044 = poph_30_44_2017,\n                       age4559 = poph_45_59_2017,    \n                       age6074 = poph_60_74_2017,\n                       age7599 = poph_75_2017)  %&gt;%\n  pivot_longer(cols = 5:13) %&gt;%\n  rename(pop=value, age=name) %&gt;%\n  mutate(sexe = \"Homme\",  age=substr(age,4,7))\n\n\n\nassemblage\n\nlictot&lt;-rbind(lic_fem, lic_hom)\npoptot&lt;-rbind(pop_fem, pop_hom) %&gt;% mutate(agemoy=(as.numeric(substr(age,1,2))+as.numeric(substr(age,3,4)))/2)\nlicpop&lt;-left_join(lictot,poptot) %&gt;% select(1:4,7,5,9,6,8)\n\n# Corrige un problème d'espace dans les milliers !\nlicpop$pop&lt;-as.numeric(gsub(\" \",\"\",licpop$pop))\n\nsaveRDS(licpop,\"data/sport/licpop_idf_2018.RDS\")\n\n\nlicpop &lt;-readRDS(\"data/sport/licpop_idf_2018.RDS\")\n\nglimpse(licpop)\n\nRows: 1,023,012\nColumns: 9\n$ code_com &lt;chr&gt; \"75101\", \"75101\", \"75101\", \"75101\", \"75101\", \"75101\", \"75101\"…\n$ nom_com  &lt;chr&gt; \"Paris 1er Arrondissement\", \"Paris 1er Arrondissement\", \"Pari…\n$ code_fed &lt;int&gt; 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 1…\n$ nom_fed  &lt;chr&gt; \"FF d'athlétisme\", \"FF d'athlétisme\", \"FF d'athlétisme\", \"FF …\n$ sexe     &lt;chr&gt; \"Femme\", \"Femme\", \"Femme\", \"Femme\", \"Femme\", \"Femme\", \"Femme\"…\n$ age      &lt;chr&gt; \"0004\", \"0509\", \"1014\", \"1519\", \"2029\", \"3044\", \"4559\", \"6074…\n$ agemoy   &lt;dbl&gt; 2.0, 7.0, 12.0, 17.0, 24.5, 37.0, 52.0, 67.0, 87.0, 2.0, 7.0,…\n$ nblic    &lt;int&gt; 0, 0, 2, 0, 2, 3, 1, 1, 0, 0, 0, 2, 8, 6, 6, 13, 3, 0, 0, 0, …\n$ pop      &lt;dbl&gt; 283, 306, 327, 356, 1444, 1659, 1545, 1227, 752, 283, 306, 32…\n\nkable(head(licpop,18))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncode_com\nnom_com\ncode_fed\nnom_fed\nsexe\nage\nagemoy\nnblic\npop\n\n\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n0004\n2.0\n0\n283\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n0509\n7.0\n0\n306\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n1014\n12.0\n2\n327\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n1519\n17.0\n0\n356\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n2029\n24.5\n2\n1444\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n3044\n37.0\n3\n1659\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n4559\n52.0\n1\n1545\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n6074\n67.0\n1\n1227\n\n\n75101\nParis 1er Arrondissement\n101\nFF d’athlétisme\nFemme\n7599\n87.0\n0\n752\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n0004\n2.0\n0\n283\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n0509\n7.0\n0\n306\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n1014\n12.0\n2\n327\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n1519\n17.0\n8\n356\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n2029\n24.5\n6\n1444\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n3044\n37.0\n6\n1659\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n4559\n52.0\n13\n1545\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n6074\n67.0\n3\n1227\n\n\n75101\nParis 1er Arrondissement\n102\nFF d’aviron\nFemme\n7599\n87.0\n0\n752\n\n\n\n\n\n\nN.B. On remarque que la population apparaît plusieurs fois et qu’il ne faut donc pas effectuer de sommes sur tout le tableau.\nN.B.2 on pourrait gagner de la place en retirant les lignes ou le nombre de licencié est égal à zéro et en stockant à part les populations par âge."
  },
  {
    "objectID": "31-PROJET-data.html#exploration",
    "href": "31-PROJET-data.html#exploration",
    "title": "Projet-Données",
    "section": "Exploration",
    "text": "Exploration\nPemières analyses du tableau … afin de choisir le sport que l’on souhaite étudier par la suite. A vous de retrouver les programmes\n\nTop20\n\n\n\n\n\n\n\n\n\nnom_fed\nnb\n\n\n\n\nFF de football\n267700\n\n\nFF de tennis\n223858\n\n\nUnion nationale du sport scolaire (UNSS)\n188123\n\n\nUnion sportive de l’enseignement du premier degré\n118350\n\n\nFF de golf\n108503\n\n\nFF de judo-jujitsu et disciplines associées\n107679\n\n\nF sportive et gymnique du travail (FSGT)\n96451\n\n\nFF d’équitation\n93590\n\n\nFF de Handball\n72577\n\n\nFF d’éducation physique et de gymnastique volontaire\n69167\n\n\nFF de natation\n68533\n\n\nFF de basketball\n67876\n\n\nFF de karaté et disciplines associées\n61035\n\n\nFF de gymnastique\n58136\n\n\nFF d’athlétisme\n51776\n\n\nFF de voile\n44615\n\n\nUnion française des uvres laïques d’éducation physique (UFOLEP)\n39455\n\n\nFF de badminton\n36168\n\n\nFF de rugby\n35684\n\n\nFF de tennis de table\n33759\n\n\n\n\n\n\n\nMasculin/Feminin\n\n\n\nSports les plus Féminins\n\n\n\n\n\n\n\n\n\nnom_fed\nFemme\nHomme\nTotal\nIndice\n\n\n\n\nFF d’éducation physique et de gymnastique volontaire\n62893\n6274\n69167\n-0.82\n\n\nFF des sports de glace\n6308\n881\n7189\n-0.75\n\n\nFF de danse\n11749\n2088\n13837\n-0.70\n\n\nFF d’équitation\n77052\n16538\n93590\n-0.65\n\n\nFF de gymnastique\n47790\n10346\n58136\n-0.64\n\n\nFF sport pour tous\n13821\n3058\n16879\n-0.64\n\n\nFF de la retraite sportive\n6568\n2638\n9206\n-0.43\n\n\nFF de la randonnée pédestre\n20600\n10775\n31375\n-0.31\n\n\nUnion française des uvres laïques d’éducation physique (UFOLEP)\n25457\n13998\n39455\n-0.29\n\n\nUnion nationale sportive Léo Lagrange\n1094\n613\n1707\n-0.28\n\n\n\n\n\n\nSports les plus Masculins\n\n\nnom_fed\nFemme\nHomme\nTotal\nIndice\n\n\n\n\nFF d’aéromodélisme\n78\n3156\n3234\n0.95\n\n\nFF des pêches sportives\n20\n549\n569\n0.93\n\n\nFF de planeur ultra léger motorisé\n50\n1207\n1257\n0.92\n\n\nFF de ball-trap et de tir à balle\n107\n2040\n2147\n0.90\n\n\nFF de motocyclisme\n236\n3827\n4063\n0.88\n\n\nFF de football\n17349\n250351\n267700\n0.87\n\n\nFF des sports de billard\n139\n1985\n2124\n0.87\n\n\nFF d’aéronautique\n665\n7977\n8642\n0.85\n\n\nFF du sport automobile\n209\n2449\n2658\n0.84\n\n\nFF de pelote basque\n59\n580\n639\n0.82\n\n\n\n\n\n\nSports les plus Neutres\n\n\n\n\n\n\n\n\n\nnom_fed\nFemme\nHomme\nTotal\nIndice\n\n\n\n\nFF de volley-ball\n8498\n10660\n19158\n0.11\n\n\nFF d’athlétisme\n23533\n28243\n51776\n0.09\n\n\nFF de sauvetage et secourisme\n2610\n3041\n5651\n0.08\n\n\nF sportive et gymnique du travail (FSGT)\n46513\n49938\n96451\n0.04\n\n\nUnion sportive de l’enseignement du premier degré\n58003\n60347\n118350\n0.02\n\n\nFF de roller et skateboard\n5272\n4857\n10129\n-0.04\n\n\nFF de natation\n36438\n32095\n68533\n-0.06\n\n\nF sportive et culturelle de France\n18096\n14341\n32437\n-0.12\n\n\n\n\n\n\n\nJeunes/Vieux\n\n\n\nSports de jeunes\n\n\nnom_fed\nnb\nagemoy\n\n\n\n\nUnion sportive de l’enseignement du premier degré\n118350\n10.2\n\n\nFF de gymnastique\n58136\n13.9\n\n\nUnion nationale du sport scolaire (UNSS)\n188123\n14.0\n\n\nFF de judo-jujitsu et disciplines associées\n107679\n15.2\n\n\nFF de rugby à XIII\n438\n16.2\n\n\nFF des sports de glace\n7189\n16.4\n\n\nFF de taekwondo et disciplines associées\n15447\n18.5\n\n\nFF de basketball\n67876\n18.8\n\n\nFF d’escrime\n17053\n19.9\n\n\nFF de Handball\n72577\n20.0\n\n\n\n\n\n\nSports de vieux\n\n\n\n\n\n\n\nnom_fed\nnb\nagemoy\n\n\n\n\nFF de la retraite sportive\n9206\n71.5\n\n\nFF de la randonnée pédestre\n31375\n65.4\n\n\nFF du sport boules\n1488\n59.1\n\n\nFF des sports de billard\n2124\n58.9\n\n\nFF d’éducation physique et de gymnastique volontaire\n69167\n57.9\n\n\nFF de pétanque et jeu provençal\n22837\n56.5\n\n\nFF de planeur ultra léger motorisé\n1257\n54.8\n\n\nFédération française des Arts Energétiques et Martiaux Chinois (ancien WUSHU)\n5766\n54.1\n\n\nFF de bowling et de sports de quilles\n1414\n53.8\n\n\nFF de cyclotourisme\n12057\n53.3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Mining 2024",
    "section": "",
    "text": "Ce document est la quatrième édition d’un cours de Data Mining dispensé aux étudiants de deuxième année de l’ option Data Mining du master MECI conjointement avec Camille Signoretto.\nIl est basé sur :\n\nR.Version()[[\"version.string\"]]\n\n[1] \"R version 4.3.1 (2023-06-16)\"\n\n\nCe document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse :\n\nhttps://claudegrasland.github.io/datamining2024/.\n\nPour toute suggestion ou correction, il est possible de me contacter par mail"
  },
  {
    "objectID": "index.html#à-propos-de-ce-document",
    "href": "index.html#à-propos-de-ce-document",
    "title": "Data Mining 2024",
    "section": "",
    "text": "Ce document est la quatrième édition d’un cours de Data Mining dispensé aux étudiants de deuxième année de l’ option Data Mining du master MECI conjointement avec Camille Signoretto.\nIl est basé sur :\n\nR.Version()[[\"version.string\"]]\n\n[1] \"R version 4.3.1 (2023-06-16)\"\n\n\nCe document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse :\n\nhttps://claudegrasland.github.io/datamining2024/.\n\nPour toute suggestion ou correction, il est possible de me contacter par mail"
  },
  {
    "objectID": "index.html#prérequis",
    "href": "index.html#prérequis",
    "title": "Data Mining 2024",
    "section": "Prérequis",
    "text": "Prérequis\nLe seul prérequis pour suivre ce document est d’avoir installé R et RStudio sur votre ordinateur. Il s’agit de deux logiciels libres, gratuits, téléchargeables en ligne et fonctionnant sous PC, Mac et Linux.\nPour installer R, il suffit de se rendre sur une des pages suivantes 1 :\n\nInstaller R sous Windows\nInstaller R sous Mac\n\nPour installer RStudio, rendez-vous sur la page suivante et téléchargez la version adaptée à votre système :\n\nhttps://www.rstudio.com/products/rstudio/download/#download"
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "Data Mining 2024",
    "section": "Remerciements",
    "text": "Remerciements\nCe document a bénéficié de la relecture et des suggestions … des étudiants qui en ont été les cobayes des premières versions."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Data Mining 2024",
    "section": "Licence",
    "text": "Licence\nCe document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.\n\n\n\nLicence Creative Commons"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Data Mining 2024",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSous Linux, utilisez votre gestionnaire de packages habituel.↩︎"
  },
  {
    "objectID": "13-API-CARTO.html",
    "href": "13-API-CARTO.html",
    "title": "Acquisition",
    "section": "",
    "text": "Le but de ce chapitre est d’approfondir les méthodes de recueil de données lorsque celles-ci comportent une information géographique sur la localisation des objets étudiés. Nous allons donc charger non plus seulement des tableaux statistiques mais aussi de l’information géographique décrivant la localisation de poins, lignes ou polygones. Cela implique deux nouveautés :\nNous verrons en détail l’utilisation des données géographiques dans les chapitres ultérieurs et on se bornera ici à analyser comment recueillir cette information."
  },
  {
    "objectID": "13-API-CARTO.html#preparation-du-travail",
    "href": "13-API-CARTO.html#preparation-du-travail",
    "title": "Acquisition",
    "section": "PREPARATION DU TRAVAIL",
    "text": "PREPARATION DU TRAVAIL\n\nPackages\nOn charge les packages habituels\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(httr)\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(dplyr, warn.conflicts = T, quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\n\n\nOrganisation du projet\nOn crée un dossier resul à l’intérieur duquel on va imporer les données statistiques (sous-dossier stats) et des données géométriques (sous-dossier geom). On ajoute un dossier sf où on placera les ficheirs au format spatial features de R.\n\n\nObjectif Grand Paris\nOn se donne comme ojectif d’acquérir des données géométriques décrivant les communes et les iris du Grand Paris qui regroupe quatre départements 75, 92, 93, 94 et quelques communes isolées de la grande couronne dont les codes sont : “95018”,“91027”,“91479”,“91432”,“91589”,“91326”,“91687”.\nNous devons arriver à produire quatre fonds de carte :\n\npar IRIS\npar communes\npar territoires\npar département\n\nIl faudra faire en sorte que les résultats se superposent …"
  },
  {
    "objectID": "13-API-CARTO.html#importation-de-fichiers-sig",
    "href": "13-API-CARTO.html#importation-de-fichiers-sig",
    "title": "Acquisition",
    "section": "Importation de fichiers SIG",
    "text": "Importation de fichiers SIG\nBeaucoup de données géographiques ont été conçues pour l’utilisation de systèmes d’information géographiques tels que ArcGIS ou QGIS. Historiquement ces données sont le plus souvent enregistrées et échangées dans le format shapefile qui se compose de trois ou quatre fichiers pour chaque fonds de carte :\n\ncarte.shp : fichier contenant la géométrie (contour des unités)\ncarte.shx : index des unités géométriques\ncarte.prj : fichier contenant la projection de la carte\ncarte.dbf : fichier de données attributaires (statistiques)\n\nNous allons prendre à titre d’exemple l’acquisition d’un fichier des communes d’Ile de France disponible sur le site data.gouv.fr à cette adresse\nNous commeçons par télécharger le fichier avec la fonction download.file() et on stocke le résultat dans notre dossier “geom”.\nNous avons téléchargé un fichier au format .zip que l’on va décompresser.\nOn voit bien apparaître les quatre fichiers qui définissent un shapefile et on pourrait les utiliser avec des logiciels tels que ArcGis, Qgis ou Magrit.\n\nImportantion de shapefile -&gt; R\nNous allons maintenant importer le fonds de carte dans R à l’aide du package sf (spatial features) en utilisant la fonction st_read() :\n\nmap&lt;-st_read(\"resul/geom/idf_com/communes-dile-de-france-au-01-janvier.shp\")\n\nReading layer `communes-dile-de-france-au-01-janvier' from data source \n  `/Users/claudegrasland1/git/datamining2024/resul/geom/idf_com/communes-dile-de-france-au-01-janvier.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1287 features and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 1.44728 ymin: 48.12054 xmax: 3.555687 ymax: 49.23719\nGeodetic CRS:  WGS 84\n\n\nOn vérifie la classe de l’objet :\n\nclass(map)\n\n[1] \"sf\"         \"data.frame\"\n\n\nOn voit qu’il s’agit à la fois d’un data.frame et d’un objet de type sf. Regardons plus en détail avec str()\n\nstr(map)\n\nClasses 'sf' and 'data.frame':  1287 obs. of  10 variables:\n $ objectid  : num  12 14 56 57 59 73 78 86 90 94 ...\n $ shape_leng: num  16585 17790 14908 6894 10681 ...\n $ insee     : num  77472 91315 78472 77038 78672 ...\n $ nomcom    : chr  \"La Trétoire\" \"Itteville\" \"Orsonville\" \"Boissettes\" ...\n $ numdep    : num  77 91 78 77 78 95 95 95 92 77 ...\n $ fusioinsee: chr  NA NA NA NA ...\n $ nomcomto  : chr  \"Trétoire (la)\" \"Itteville\" \"Orsonville\" \"Boissettes\" ...\n $ st_areasha: num  9488102 12122472 9504776 1603038 5117345 ...\n $ st_lengths: num  16585 17790 14908 6894 10681 ...\n $ geometry  :sfc_POLYGON of length 1287; first list element: List of 1\n  ..$ : num [1:17, 1:2] 3.26 3.26 3.24 3.24 3.23 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:9] \"objectid\" \"shape_leng\" \"insee\" \"nomcom\" ...\n\n\nPar rapport à un dataframe classique on trouve une nouvelle colonne appelée “geometry” ainsi que différents attributs tels que la projection. Nous trouvons donc en un seul fichier l’ensemble des informations normalement présents dans les quatre fichiers qui composaient le shappefile.\n\n\nVisualisation de la geometrie\nPour visualiser rapidement le fonds de carte, il suffit de taper la fonction rbase plot appliquée à la colonne geometry du fichier sf :\n\nplot(map$geometry)\n\n\n\n\n\n\nExtraction du data.frame sans les données géométriques\nSi l’on veut juste travailler sur les données statistiques du tableau, on peut retirer la géométrie du fichier pour revenir à un pur objet de type data.frame à l’aide de la fonction sf st_drop_geometry() :\n\ndon&lt;-st_drop_geometry(map)\nclass(don)\n\n[1] \"data.frame\"\n\nhead(don)\n\n  objectid shape_leng insee               nomcom numdep fusioinsee\n1       12  16584.790 77472          La Trétoire     77       &lt;NA&gt;\n2       14  17789.557 91315            Itteville     91       &lt;NA&gt;\n3       56  14908.000 78472           Orsonville     78       &lt;NA&gt;\n4       57   6894.431 77038           Boissettes     77       &lt;NA&gt;\n5       59  10681.145 78672  Villennes-sur-Seine     78       &lt;NA&gt;\n6       73  18855.711 95541 Saint-Clair-sur-Epte     95       &lt;NA&gt;\n              nomcomto st_areasha st_lengths\n1        Trétoire (la)    9488102  16584.790\n2            Itteville   12122472  17789.557\n3           Orsonville    9504776  14908.000\n4           Boissettes    1603038   6894.431\n5  Villennes-sur-Seine    5117345  10681.145\n6 Saint-Clair-sur-Epte   12431151  18855.711\n\n\nOn constate que parmi les colonnes il existe à la fois une variable relative au département et une autre au code INSEE des communes. On peut donc procéder à une sélection sur ces deux critères afin d’aboutir à un fonds de carte du grand Paris.\n\n\nExtraction des communes du grand Paris\nOn utilise la condition “ou” pour filter à la fois sur les départements et les communes.\n\nGP_com &lt;- map %&gt;% filter(numdep %in% c(75, 92, 93, 94) |  \n                           insee %in% c(95018,91027,91479,91432,91589,91326,91687))\nplot(GP_com$geometry)\n\n\n\n\n\n\nCartographie rapide du résultat\nOn utilise une petite astuce pour visualiser les départements. On commence par créer une variable de type factor et on applique un plot spécial sur cette variable.\n\nGP_com$Dep&lt;-as.factor(GP_com$numdep)\nplot(GP_com[\"Dep\"])\n\n\n\n\n\n\nSauvegarde du fichier sf\nOn enregistre le fichier dans le format interne de R afin de ne pas avoir à répliquer toutes les étapes précédentes à l’aide de la fonction saveRDS(). On en profite pour nettoyer le dossier en supprimant les fichiers dont on n'a plus  besoin à l'aide de la fonctionfile.remove()pour un fichier unique ouunlink()`` pour un groupe de fichiers\n\nfile.remove(\"resul/geom/idf_com.zip\")\n\n[1] FALSE\n\n#unlink(\"resul/geom/communes*\")\nsaveRDS(GP_com,\"resul/geom/GP_com.RDS\")\n\n\n\nExportation au format Geojson\nSi l’on doit travailler avec des programmeurs qui utilisent Python, le plus simple est de réaliser une exportation au format geojson à l’aide de la fonction st_write() du package sf. On rajoute l’option delete_dsn=T pour écraser une éventuelle version antérieure.\n\nst_write(GP_com, \"resul/geom/GP_com.geojson\",delete_dsn = T)\n\nDeleting source `resul/geom/GP_com.geojson' using driver `GeoJSON'\nWriting layer `GP_com' to data source \n  `resul/geom/GP_com.geojson' using driver `GeoJSON'\nWriting 150 features with 10 fields and geometry type Polygon."
  },
  {
    "objectID": "13-API-CARTO.html#importation-via-une-api",
    "href": "13-API-CARTO.html#importation-via-une-api",
    "title": "Acquisition",
    "section": "Importation via une API",
    "text": "Importation via une API\nUne solution beaucoup plus rapide consiste à importer des données géographiques en faisant appel à une API. Celles-ci renvoient en général des fichiers au format Geojson qu’il sera facile de convertir ensuite au format sf.\nA titre d’exemple, nous allons utiliser le site Opendatasoft pour importer des données concernant l’indice de défavorisation sociale à l’échelle des IRIS dans la commune de Fontenay-sous-Bois\n\n\n\nIndice de déprivation sociale\n\n\n\nIdentification du lien de téléchargement\nOn procède à une sélection des IRIS de la région Ile-de-France puis on copie le lien permettant de récupérer les données au format shapefile\n\n\n\nlien de télécargement\n\n\n\n\nRécupération du fichier au format sf\n\nmyurl &lt;- \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/indice-de-defavorisation-sociale-fdep-par-iris/exports/geojson?lang=fr&refine=c_nom_com%3A%22FONTENAY-SOUS-BOIS%22&timezone=Europe%2FBerlin\"\nmap &lt;- st_read(myurl)\n\nReading layer `OGRGeoJSON' from data source \n  `https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/indice-de-defavorisation-sociale-fdep-par-iris/exports/geojson?lang=fr&refine=c_nom_com%3A%22FONTENAY-SOUS-BOIS%22&timezone=Europe%2FBerlin' \n  using driver `GeoJSON'\nSimple feature collection with 21 features and 14 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2.447158 ymin: 48.8391 xmax: 2.500071 ymax: 48.86146\nGeodetic CRS:  WGS 84\n\n\n\n\nVisualisation du fonds de carte\n\nplot(map$geometry)\n\n\n\n\n\n\nCartographie rapide d’indicateurs\n\nplot(map[\"t1_rev_med\"], main=\"Revenu médian\")\n\n\n\n\n\nplot(map[\"t1_txbac09\"], main=\"Diplômes du supérieur\")\n\n\n\n\n\nplot(map[\"t1_txchom0\"], main=\"Taux de chômage\")\n\n\n\n\n\nplot(map[\"t1_txouvr0\"], main=\"Part des ouvriers\")\n\n\n\n\n\n\nExercice\n\nConstruire un indicateur synthétique combinant les quatre variables\nCartographier cet indicateur\nConstruire une fonction applicable à une commune quelconque."
  }
]