[
  {
    "objectID": "13-API-CARTO.html",
    "href": "13-API-CARTO.html",
    "title": "Acquisition",
    "section": "",
    "text": "Le but de ce chapitre est d’approfondir les méthodes de recueil de données lorsque celles-ci comportent une information géographique sur la localisation des objets étudiés. Nous allons donc charger non plus seulement des tableaux statistiques mais aussi de l’information géographique décrivant la localisation de poins, lignes ou polygones. Cela implique deux nouveautés :\nNous verrons en détail l’utilisation des données géographiques dans les chapitres ultérieurs et on se bornera ici à analyser comment recueillir cette information."
  },
  {
    "objectID": "13-API-CARTO.html#preparation-du-travail",
    "href": "13-API-CARTO.html#preparation-du-travail",
    "title": "Acquisition",
    "section": "PREPARATION DU TRAVAIL",
    "text": "PREPARATION DU TRAVAIL\n\nPackages\nOn charge les packages habituels\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(httr)\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(dplyr, warn.conflicts = T, quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\n\n\nOrganisation du projet\nOn crée un dossier resul à l’intérieur duquel on va imporer les données statistiques (sous-dossier stats) et des données géométriques (sous-dossier geom). On ajoute un dossier sf où on placera les ficheirs au format spatial features de R.\n\n\nObjectif Grand Paris\nOn se donne comme ojectif d’acquérir des données géométriques décrivant les communes et les iris du Grand Paris qui regroupe quatre départements 75, 92, 93, 94 et quelques communes isolées de la grande couronne dont les codes sont : “95018”,“91027”,“91479”,“91432”,“91589”,“91326”,“91687”.\nNous devons arriver à produire quatre fonds de carte :\n\npar IRIS\npar communes\npar territoires\npar département\n\nIl faudra faire en sorte que les résultats se superposent …"
  },
  {
    "objectID": "13-API-CARTO.html#importation-de-fichiers-sig",
    "href": "13-API-CARTO.html#importation-de-fichiers-sig",
    "title": "Acquisition",
    "section": "Importation de fichiers SIG",
    "text": "Importation de fichiers SIG\nBeaucoup de données géographiques ont été conçues pour l’utilisation de systèmes d’information géographiques tels que ArcGIS ou QGIS. Historiquement ces données sont le plus souvent enregistrées et échangées dans le format shapefile qui se compose de trois ou quatre fichiers pour chaque fonds de carte :\n\ncarte.shp : fichier contenant la géométrie (contour des unités)\ncarte.shx : index des unités géométriques\ncarte.prj : fichier contenant la projection de la carte\ncarte.dbf : fichier de données attributaires (statistiques)\n\nNous allons prendre à titre d’exemple l’acquisition d’un fichier des communes d’Ile de France disponible sur le site data.gouv.fr à cette adresse\nNous commeçons par télécharger le fichier avec la fonction download.file() et on stocke le résultat dans notre dossier “geom”.\n\nmyurl &lt;- \"https://www.data.gouv.fr/fr/datasets/r/5cd27d86-4859-40dc-b029-a215219eedf9\"\ndownload.file(url = myurl, destfile = \"resul/geom/idf_com.zip\")\nlist.files(\"resul/geom\")\n\n[1] \"GP_com.geojson\" \"GP_com.RDS\"     \"idf_com.zip\"   \n\n\nNous avons téléchargé un fichier au format .zip que l’on va décompresse à l’aide de la fonction unzip()\n\nzipF&lt;- \"resul/geom/idf_com.zip\"\noutDir&lt;-\"resul/geom/\"\nunzip(zipF,exdir=outDir)\nlist.files(\"resul/geom\")\n\n[1] \"communes-dile-de-france-au-01-janvier.dbf\"\n[2] \"communes-dile-de-france-au-01-janvier.prj\"\n[3] \"communes-dile-de-france-au-01-janvier.shp\"\n[4] \"communes-dile-de-france-au-01-janvier.shx\"\n[5] \"GP_com.geojson\"                           \n[6] \"GP_com.RDS\"                               \n[7] \"idf_com.zip\"                              \n\n\nOn voit bien apparaître les quatre fichiers qui définissent un shapefile et on pourrait les utiliser avec des logiciels tels que ArcGis, Qgis ou Magrit.\n\nImportantion de shapefile -&gt; R\nNous allons maintenant importer le fonds de carte dans R à l’aide du package sf (spatial features) en utilisant la fonction st_read() :\n\nmap&lt;-st_read(\"resul/geom/communes-dile-de-france-au-01-janvier.shp\")\n\nReading layer `communes-dile-de-france-au-01-janvier' from data source \n  `/Users/claudegrasland1/git/datamining2024/resul/geom/communes-dile-de-france-au-01-janvier.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1287 features and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 1.44728 ymin: 48.12054 xmax: 3.555687 ymax: 49.23719\nGeodetic CRS:  WGS 84\n\n\nOn vérifie la classe de l’objet :\n\nclass(map)\n\n[1] \"sf\"         \"data.frame\"\n\n\nOn voit qu’il s’agit à la fois d’un data.frame et d’un objet de type sf. Regardons plus en détail avec str()\n\nstr(map)\n\nClasses 'sf' and 'data.frame':  1287 obs. of  10 variables:\n $ objectid  : num  12 14 56 57 59 73 78 86 90 94 ...\n $ shape_leng: num  16585 17790 14908 6894 10681 ...\n $ insee     : num  77472 91315 78472 77038 78672 ...\n $ nomcom    : chr  \"La Trétoire\" \"Itteville\" \"Orsonville\" \"Boissettes\" ...\n $ numdep    : num  77 91 78 77 78 95 95 95 92 77 ...\n $ fusioinsee: chr  NA NA NA NA ...\n $ nomcomto  : chr  \"Trétoire (la)\" \"Itteville\" \"Orsonville\" \"Boissettes\" ...\n $ st_areasha: num  9488102 12122472 9504776 1603038 5117345 ...\n $ st_lengths: num  16585 17790 14908 6894 10681 ...\n $ geometry  :sfc_POLYGON of length 1287; first list element: List of 1\n  ..$ : num [1:17, 1:2] 3.26 3.26 3.24 3.24 3.23 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:9] \"objectid\" \"shape_leng\" \"insee\" \"nomcom\" ...\n\n\nPar rapport à un dataframe classique on trouve une nouvelle colonne appelée “geometry” ainsi que différents attributs tels que la projection. Nous trouvons donc en un seul fichier l’ensemble des informations normalement présents dans les quatre fichiers qui composaient le shappefile.\n\n\nVisualisation de la geometrie\nPour visualiser rapidement le fonds de carte, il suffit de taper la fonction rbase plot appliquée à la colonne geometry du fichier sf :\n\nplot(map$geometry)\n\n\n\n\n\n\nExtraction du data.frame sans les données géométriques\nSi l’on veut juste travailler sur les données statistiques du tableau, on peut retirer la géométrie du fichier pour revenir à un pur objet de type data.frame à l’aide de la fonction sf st_drop_geometry() :\n\ndon&lt;-st_drop_geometry(map)\nclass(don)\n\n[1] \"data.frame\"\n\nhead(don)\n\n  objectid shape_leng insee               nomcom numdep fusioinsee\n1       12  16584.790 77472          La Trétoire     77       &lt;NA&gt;\n2       14  17789.557 91315            Itteville     91       &lt;NA&gt;\n3       56  14908.000 78472           Orsonville     78       &lt;NA&gt;\n4       57   6894.431 77038           Boissettes     77       &lt;NA&gt;\n5       59  10681.145 78672  Villennes-sur-Seine     78       &lt;NA&gt;\n6       73  18855.711 95541 Saint-Clair-sur-Epte     95       &lt;NA&gt;\n              nomcomto st_areasha st_lengths\n1        Trétoire (la)    9488102  16584.790\n2            Itteville   12122472  17789.557\n3           Orsonville    9504776  14908.000\n4           Boissettes    1603038   6894.431\n5  Villennes-sur-Seine    5117345  10681.145\n6 Saint-Clair-sur-Epte   12431151  18855.711\n\n\nOn constate que parmi les colonnes il existe à la fois une variable relative au département et une autre au code INSEE des communes. On peut donc procéder à une sélection sur ces deux critères afin d’aboutir à un fonds de carte du grand Paris.\n\n\nExtraction des communes du grand Paris\nOn utilise la condition “ou” pour filter à la fois sur les départements et les communes.\n\nGP_com &lt;- map %&gt;% filter(numdep %in% c(75, 92, 93, 94) |  \n                           insee %in% c(95018,91027,91479,91432,91589,91326,91687))\nplot(GP_com$geometry)\n\n\n\n\n\n\nCartographie rapide du résultat\nOn utilise une petite astuce pour visualiser les départements. On commence par créer une variable de type factor et on applique un plot spécial sur cette variable.\n\nGP_com$Dep&lt;-as.factor(GP_com$numdep)\nplot(GP_com[\"Dep\"])\n\n\n\n\n\n\nSauvegarde du fichier sf\nOn enregistre le fichier dans le format interne de R afin de ne pas avoir à répliquer toutes les étapes précédentes à l’aide de la fonction saveRDS(). On en profite pour nettoyer le dossier en supprimant les fichiers dont on n'a plus  besoin à l'aide de la fonctionfile.remove()pour un fichier unique ouunlink()`` pour un groupe de fichiers\n\nfile.remove(\"resul/geom/idf_com.zip\")\n\n[1] TRUE\n\nunlink(\"resul/geom/communes*\")\nsaveRDS(GP_com,\"resul/geom/GP_com.RDS\")\n\n\n\nExportation au format Geojson\nSi l’on doit travailler avec des programmeurs qui utilisent Python, le plus simple est de réaliser une exportation au format geojson à l’aide de la fonction st_write() du package sf. On rajoute l’option delete_dsn=T pour écraser une éventuelle version antérieure.\n\nst_write(GP_com, \"resul/geom/GP_com.geojson\",delete_dsn = T)\n\nDeleting source `resul/geom/GP_com.geojson' using driver `GeoJSON'\nWriting layer `GP_com' to data source \n  `resul/geom/GP_com.geojson' using driver `GeoJSON'\nWriting 150 features with 10 fields and geometry type Polygon."
  },
  {
    "objectID": "13-API-CARTO.html#importation-via-une-api",
    "href": "13-API-CARTO.html#importation-via-une-api",
    "title": "Acquisition",
    "section": "Importation via une API",
    "text": "Importation via une API\nUne solution beaucoup plus rapide consiste à importer des données géographiques en faisant appel à une API. Celles-ci renvoient en général des fichiers au format Geojson qu’il sera facile de convertir ensuite au format sf.\nA titre d’exemple, nous allons utiliser le site Opendatasoft pour importer des données concernant l’indice de défavorisation sociale à l’échelle des IRIS dans la commune de Fontenay-sous-Bois\n\n\n\nIndice de déprivation sociale\n\n\n\nIdentification du lien de téléchargement\nOn procède à une sélection des IRIS de la région Ile-de-France puis on copie le lien permettant de récupérer les données au format shapefile\n\n\n\nlien de télécargement\n\n\n\n\nRécupération du fichier au format sf\n\nmyurl &lt;- \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/indice-de-defavorisation-sociale-fdep-par-iris/exports/geojson?lang=fr&refine=c_nom_com%3A%22FONTENAY-SOUS-BOIS%22&timezone=Europe%2FBerlin\"\nmap &lt;- st_read(myurl)\n\nReading layer `OGRGeoJSON' from data source \n  `https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/indice-de-defavorisation-sociale-fdep-par-iris/exports/geojson?lang=fr&refine=c_nom_com%3A%22FONTENAY-SOUS-BOIS%22&timezone=Europe%2FBerlin' \n  using driver `GeoJSON'\nSimple feature collection with 21 features and 14 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2.447158 ymin: 48.8391 xmax: 2.500071 ymax: 48.86146\nGeodetic CRS:  WGS 84\n\n\n\n\nVisualisation du fonds de carte\n\nplot(map$geometry)\n\n\n\n\n\n\nCartographie rapide d’indicateurs\n\nplot(map[\"t1_rev_med\"], main=\"Revenu médian\")\n\n\n\n\n\nplot(map[\"t1_txbac09\"], main=\"Diplômes du supérieur\")\n\n\n\n\n\nplot(map[\"t1_txchom0\"], main=\"Taux de chômage\")\n\n\n\n\n\nplot(map[\"t1_txouvr0\"], main=\"Part des ouvriers\")\n\n\n\n\n\n\nExercice\n\nConstruire un indicateur synthétique combinant les quatre variables\nCartographier cet indicateur\nConstruire une fonction applicable à une commune quelconque."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Mining 2024",
    "section": "",
    "text": "Ce document est la quatrième édition d’un cours de Data Mining dispensé aux étudiants de deuxième année de l’ option Data Mining du master MECI conjointement avec Camille Signoretto.\nIl est basé sur :\n\nR.Version()[[\"version.string\"]]\n\n[1] \"R version 4.3.1 (2023-06-16)\"\n\n\nCe document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse :\n\nhttps://claudegrasland.github.io/datamining2024/.\n\nPour toute suggestion ou correction, il est possible de me contacter par mail"
  },
  {
    "objectID": "index.html#à-propos-de-ce-document",
    "href": "index.html#à-propos-de-ce-document",
    "title": "Data Mining 2024",
    "section": "",
    "text": "Ce document est la quatrième édition d’un cours de Data Mining dispensé aux étudiants de deuxième année de l’ option Data Mining du master MECI conjointement avec Camille Signoretto.\nIl est basé sur :\n\nR.Version()[[\"version.string\"]]\n\n[1] \"R version 4.3.1 (2023-06-16)\"\n\n\nCe document est régulièrement corrigé et mis à jour. La version de référence est disponible en ligne à l’adresse :\n\nhttps://claudegrasland.github.io/datamining2024/.\n\nPour toute suggestion ou correction, il est possible de me contacter par mail"
  },
  {
    "objectID": "index.html#prérequis",
    "href": "index.html#prérequis",
    "title": "Data Mining 2024",
    "section": "Prérequis",
    "text": "Prérequis\nLe seul prérequis pour suivre ce document est d’avoir installé R et RStudio sur votre ordinateur. Il s’agit de deux logiciels libres, gratuits, téléchargeables en ligne et fonctionnant sous PC, Mac et Linux.\nPour installer R, il suffit de se rendre sur une des pages suivantes 1 :\n\nInstaller R sous Windows\nInstaller R sous Mac\n\nPour installer RStudio, rendez-vous sur la page suivante et téléchargez la version adaptée à votre système :\n\nhttps://www.rstudio.com/products/rstudio/download/#download"
  },
  {
    "objectID": "index.html#remerciements",
    "href": "index.html#remerciements",
    "title": "Data Mining 2024",
    "section": "Remerciements",
    "text": "Remerciements\nCe document a bénéficié de la relecture et des suggestions … des étudiants qui en ont été les cobayes des premières versions."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "Data Mining 2024",
    "section": "Licence",
    "text": "Licence\nCe document est mis à disposition selon les termes de la Licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International.\n\n\n\nLicence Creative Commons"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Data Mining 2024",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSous Linux, utilisez votre gestionnaire de packages habituel.↩︎"
  },
  {
    "objectID": "Exo_seance2.html",
    "href": "Exo_seance2.html",
    "title": "Exo séance n°2",
    "section": "",
    "text": "On charge les packages habituels\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(httr)\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(dplyr, warn.conflicts = T, quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE"
  },
  {
    "objectID": "Exo_seance2.html#preparation-du-travail",
    "href": "Exo_seance2.html#preparation-du-travail",
    "title": "Exo séance n°2",
    "section": "",
    "text": "On charge les packages habituels\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(httr)\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(dplyr, warn.conflicts = T, quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE"
  },
  {
    "objectID": "Exo_seance2.html#exo-seance-n2",
    "href": "Exo_seance2.html#exo-seance-n2",
    "title": "Exo séance n°2",
    "section": "EXO SEANCE n°2",
    "text": "EXO SEANCE n°2\nUne solution beaucoup plus rapide consiste à importer des données géographiques en faisant appel à une API. Celles-ci renvoient en général des fichiers au format Geojson qu’il sera facile de convertir ensuite au format sf.\nA titre d’exemple, nous allons utiliser le site Opendatasoft pour importer des données concernant l’indice de défavorisation sociale à l’échelle des IRIS dans la commune de Fontenay-sous-Bois\n\nRécupération du fichier au format sf\n\nmyurl &lt;- \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/indice-de-defavorisation-sociale-fdep-par-iris/exports/geojson?lang=fr&refine=c_nom_com%3A%22FONTENAY-SOUS-BOIS%22&timezone=Europe%2FBerlin\"\nmap &lt;- st_read(myurl)\n\nReading layer `OGRGeoJSON' from data source \n  `https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/indice-de-defavorisation-sociale-fdep-par-iris/exports/geojson?lang=fr&refine=c_nom_com%3A%22FONTENAY-SOUS-BOIS%22&timezone=Europe%2FBerlin' \n  using driver `GeoJSON'\nSimple feature collection with 21 features and 14 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2.447158 ymin: 48.8391 xmax: 2.500071 ymax: 48.86146\nGeodetic CRS:  WGS 84\n\n\n\n\nVisualisation du fonds de carte\n\nplot(map$geometry)\n\n\n\n\n\n\nCartographie rapide d’indicateurs\n\nplot(map[\"t1_rev_med\"], main=\"Revenu médian\")\n\n\n\n\n\nplot(map[\"t1_txbac09\"], main=\"Diplômes du supérieur\")\n\n\n\n\n\nplot(map[\"t1_txchom0\"], main=\"Taux de chômage\")\n\n\n\n\n\nplot(map[\"t1_txouvr0\"], main=\"Part des ouvriers\")\n\n\n\n\n\n\nExercice\n\nConstruire un indicateur synthétique combinant les quatre variables\nCartographier cet indicateur\nConstruire une fonction applicable à une commune quelconque."
  },
  {
    "objectID": "21-CARTO-ParisPC.html",
    "href": "21-CARTO-ParisPC.html",
    "title": "Jointures",
    "section": "",
    "text": "On charge les packages suivants\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks jsonlite::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n## Data.table (pour sa fonction d'importation fread)\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n## Cartographie thématique\nlibrary(mapsf)\n\n\n\n\nOn constitue un fichier des individus localisés dans les communes de Paris et Petite Couronne au RP de 2019 en reprenant le programme décrit dans le Cours n°1 de Camille Signoretto.\nLe programme ci-dessous comporte la mention “eval=FALSE” car il ne dout être executé qu’une seule fois.\n\n## Récupération des fichiers INSEE zippé\n## On utilise pour cela un dossier \"tmp\" \ndownload.file(url=\"https://www.insee.fr/fr/statistiques/fichier/6544333/RP2019_INDCVIZA_csv.zip\",\n              destfile = \"tmp/RP2019_INDCVIZA_csv.zip\")\nunzip(\"tmp/RP2019_INDCVIZA_csv.zip\", exdir = \"tmp\")\n\n## Lecture du fichier individu avec fread\nlibrary(data.table)\nRP &lt;- fread(\"tmp/FD_INDCVIZA_2019.csv\", stringsAsFactors=TRUE)\nRP &lt;- as.data.frame(RP)\n## Selection Paris PC \nRP &lt;- RP %&gt;% filter(DEPT %in% c(75, 92, 93, 94))\nsaveRDS(RP, \"data/RP/RP_final.RDS\")\n\n## Lecture du fichier de métadonnées\nmeta &lt;- read.csv(file = 'tmp/Varmod_INDCVI_2019.csv',\n                 sep = \";\",\n                 encoding = \"UTF-8\",\n                 stringsAsFactors = TRUE)\n\n## Sauvegarde des deux fichiers\nsaveRDS(meta, \"data/RP/meta.RDS\")\n\n## nettoyage du dossier  tmp\nunlink(\"tmp/*\")\n\n\n\n\nOn va maintenant acquérir le fichier des unités géographiques les plus petites (IRIS) pour la zone Paris + Petite Couronne. On se servira de ce fonds de carte des IRIS pour générer ensuite ceux des unités géographiques de niveau supérieur : communes, territoires, départements …\nComme les IRIS changent au cours du temps, il faut choisir le bon “millésime” pour que la correspondance soit possible avec les données individuelles du recensement. On utilise un lien de téléchargement depuis la base des iris millésimé accessible sur public.opendatasoft\nComme précédemment, ce programme est à executer une seule fois d’où la mention eval=FALSE dans l’en-tête du chunk.\n\n## Lien de téléchargement IDF 2019 au forma geojson\nmyurl &lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/georef-france-iris-millesime/exports/geojson?lang=fr&refine=year%3A%222019%22&refine=reg_name%3A%22%C3%8Ele-de-France%22&facet=facet(name%3D%22reg_name%22%2C%20disjunctive%3Dtrue)&timezone=Europe%2FBerlin\"\n\n## téléchargement et conversion au format sf\ngeo&lt;-geojson_sf(myurl)\ngeo&lt;-geo %&gt;% select(iris_type,\n                    iris_code, \n                    iris_name,\n                    com_code= com_arm_code,\n                    com_name = com_arm_name,\n                    dep_code,\n                    dep_name,\n                    geometry)\n\n## Nettoyage des chaînes de caractère\nclean_char &lt;- function(x) {\n  y&lt;-gsub('\\\\[\\\"','',x)\n  y&lt;-gsub('\\\"\\\\]','',y)\n  return(y)\n}\ngeo &lt;- geo %&gt;% mutate(iris_code = clean_char(iris_code),\n                      iris_name = clean_char(iris_name),\n                      com_code = clean_char(com_code),\n                      com_name = clean_char(com_name),\n                      dep_code = clean_char(dep_code),\n                      dep_name = clean_char(dep_name),\n                      )\n\n\n\n## Selection Paris PC\ngeo&lt;-geo %&gt;% filter(dep_code %in% c(\"75\",\"92\",\"93\",\"94\"))\n#plot(geo[\"iris_type\"])\n\n## Sauvegarde\n\nsaveRDS(geo,\"data/RP/map_iris.RDS\" )\n\n\n## Carto rapide\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nplot(map_iris[\"dep_code\"], main = \"IRIS\")\n\n\n\n\n\n\n\nOn agrège par le nom et le code de la commune et on conserve le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_com &lt;- map_iris %&gt;% group_by(com_code, com_name) %&gt;% \n                  summarise(dep_code = max(dep_code),\n                            dep_name = max(dep_name))\nplot(map_com[\"dep_code\"], main = \"Communes\")\n\n\n\nsaveRDS(map_com, \"DATA/RP/map_com.RDS\")\n\n\n\n\nOn agrège simplement par le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_dep &lt;- map_iris %&gt;% group_by(dep_code, dep_name) %&gt;% \n                  summarise()\nplot(map_dep[\"dep_code\"], main = \"Départements\")\n\n\n\nsaveRDS(map_dep, \"DATA/RP/map_dep.RDS\")\n\n\n\n\nNous allons maintenant examiner comment agréger les données individuelles de l’INSEE par iris, commune ou département et effectuer une jointure avec les fonds de cartes que nous avons préparé. On va s’appuyer pour cela sur le cours de datamining n°2 de Camille Signoretto.\nOn commence par recharger la fonction somme()que nous avions créé :\n\nsomme &lt;- function(data, var_gpe, nom_var){\n  som &lt;- data %&gt;% \n    group_by({{var_gpe}}) %&gt;% \n    count({{nom_var}}, wt=IPONDI) %&gt;% \n    mutate(n=round(n)) %&gt;% \n    pivot_wider(names_from = {{nom_var}}, values_from = n)\n  \n  return(som)\n}\n\nNous l’utilisons pour créer un tableau des individus par CSP simplifiées en 5 catégories et par IRIS :\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\"))\n\n# Agrégation par IRIS  \niris_csp &lt;- somme(data = indiv,\n                 var_gpe = IRIS,\n                 nom_var = TACT5)\n\n\n\n\nOn procède à la jointure des deux fichiers iris en utilisant le code des iris.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_iris_csp&lt;- left_join(map_iris, iris_csp,by = c(\"iris_code\"=\"IRIS\"))\nsaveRDS(map_iris_csp, \"data/RP/map_iris_CSP.RDS\")\n\nOn examine quels IRIS ne sont pas renseignés en croisant cette information avec le type d’IRIS.\n\nmap_iris_csp$missing&lt;-case_when(is.na(map_iris_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_iris_csp[\"missing\"], main = \"IRIS sans données\")\n\n\n\ntab&lt;-table(map_iris_csp$missing,map_iris_csp$iris_type)\naddmargins(tab)\n\n          \n           commune iris d'activité iris d'habitat iris divers  Sum\n  Manquant       7              44              5          40   96\n  OK             0              74           2572           7 2653\n  Sum            7             118           2577          47 2749\n\n\nOn constate qu’il manque des données pour 96 IRIS sur 2749. Il s’agit dans la plupart des cas d’iris correspondant à des zones industrielles ou des forêts dont le nombre d’habitant est trop faible pour que les données soient mises à disposition au niveau individuel. Cela concerne également 7 communes de petites tailles et 5 iris d’habitat.\n\n\n\nOn reprend les programmes précédents par commune\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\")) \n\n# Extraction du code communal \nindiv&lt;- indiv %&gt;%   mutate(com_code = substr(IRIS,1,5))\n\n# Agrégation par IRIS  \ncom_csp &lt;- somme(data = indiv,\n                 var_gpe = com_code,\n                 nom_var = TACT5)\n\n# Chargement du fonds de carte communal\nmap_com &lt;- readRDS(\"data/RP/map_com.RDS\")\n\n# Jointure\nmap_com_csp &lt;- left_join(map_com, com_csp)\n\n# Sauvegarde\nsaveRDS(map_com_csp, \"data/RP/map_com_csp.RDS\")\n\n# Analyse des valeurs manquantes\nmap_com_csp$missing&lt;-case_when(is.na(map_com_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_com_csp[\"missing\"], main= \"Communes sans données\")\n\n\n\n\nOn retrouve les 7 communes manquantes pour lesquelles l’INSEE ne fournit pas les données dans le fichier détail des individus."
  },
  {
    "objectID": "21-CARTO-ParisPC.html#preparation-du-travail",
    "href": "21-CARTO-ParisPC.html#preparation-du-travail",
    "title": "Jointures",
    "section": "",
    "text": "On charge les packages suivants\n\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks jsonlite::flatten()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n## Data.table (pour sa fonction d'importation fread)\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n## Information géographique\nlibrary(geojsonsf)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n## Cartographie thématique\nlibrary(mapsf)\n\n\n\n\nOn constitue un fichier des individus localisés dans les communes de Paris et Petite Couronne au RP de 2019 en reprenant le programme décrit dans le Cours n°1 de Camille Signoretto.\nLe programme ci-dessous comporte la mention “eval=FALSE” car il ne dout être executé qu’une seule fois.\n\n## Récupération des fichiers INSEE zippé\n## On utilise pour cela un dossier \"tmp\" \ndownload.file(url=\"https://www.insee.fr/fr/statistiques/fichier/6544333/RP2019_INDCVIZA_csv.zip\",\n              destfile = \"tmp/RP2019_INDCVIZA_csv.zip\")\nunzip(\"tmp/RP2019_INDCVIZA_csv.zip\", exdir = \"tmp\")\n\n## Lecture du fichier individu avec fread\nlibrary(data.table)\nRP &lt;- fread(\"tmp/FD_INDCVIZA_2019.csv\", stringsAsFactors=TRUE)\nRP &lt;- as.data.frame(RP)\n## Selection Paris PC \nRP &lt;- RP %&gt;% filter(DEPT %in% c(75, 92, 93, 94))\nsaveRDS(RP, \"data/RP/RP_final.RDS\")\n\n## Lecture du fichier de métadonnées\nmeta &lt;- read.csv(file = 'tmp/Varmod_INDCVI_2019.csv',\n                 sep = \";\",\n                 encoding = \"UTF-8\",\n                 stringsAsFactors = TRUE)\n\n## Sauvegarde des deux fichiers\nsaveRDS(meta, \"data/RP/meta.RDS\")\n\n## nettoyage du dossier  tmp\nunlink(\"tmp/*\")\n\n\n\n\nOn va maintenant acquérir le fichier des unités géographiques les plus petites (IRIS) pour la zone Paris + Petite Couronne. On se servira de ce fonds de carte des IRIS pour générer ensuite ceux des unités géographiques de niveau supérieur : communes, territoires, départements …\nComme les IRIS changent au cours du temps, il faut choisir le bon “millésime” pour que la correspondance soit possible avec les données individuelles du recensement. On utilise un lien de téléchargement depuis la base des iris millésimé accessible sur public.opendatasoft\nComme précédemment, ce programme est à executer une seule fois d’où la mention eval=FALSE dans l’en-tête du chunk.\n\n## Lien de téléchargement IDF 2019 au forma geojson\nmyurl &lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/georef-france-iris-millesime/exports/geojson?lang=fr&refine=year%3A%222019%22&refine=reg_name%3A%22%C3%8Ele-de-France%22&facet=facet(name%3D%22reg_name%22%2C%20disjunctive%3Dtrue)&timezone=Europe%2FBerlin\"\n\n## téléchargement et conversion au format sf\ngeo&lt;-geojson_sf(myurl)\ngeo&lt;-geo %&gt;% select(iris_type,\n                    iris_code, \n                    iris_name,\n                    com_code= com_arm_code,\n                    com_name = com_arm_name,\n                    dep_code,\n                    dep_name,\n                    geometry)\n\n## Nettoyage des chaînes de caractère\nclean_char &lt;- function(x) {\n  y&lt;-gsub('\\\\[\\\"','',x)\n  y&lt;-gsub('\\\"\\\\]','',y)\n  return(y)\n}\ngeo &lt;- geo %&gt;% mutate(iris_code = clean_char(iris_code),\n                      iris_name = clean_char(iris_name),\n                      com_code = clean_char(com_code),\n                      com_name = clean_char(com_name),\n                      dep_code = clean_char(dep_code),\n                      dep_name = clean_char(dep_name),\n                      )\n\n\n\n## Selection Paris PC\ngeo&lt;-geo %&gt;% filter(dep_code %in% c(\"75\",\"92\",\"93\",\"94\"))\n#plot(geo[\"iris_type\"])\n\n## Sauvegarde\n\nsaveRDS(geo,\"data/RP/map_iris.RDS\" )\n\n\n## Carto rapide\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nplot(map_iris[\"dep_code\"], main = \"IRIS\")\n\n\n\n\n\n\n\nOn agrège par le nom et le code de la commune et on conserve le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_com &lt;- map_iris %&gt;% group_by(com_code, com_name) %&gt;% \n                  summarise(dep_code = max(dep_code),\n                            dep_name = max(dep_name))\nplot(map_com[\"dep_code\"], main = \"Communes\")\n\n\n\nsaveRDS(map_com, \"DATA/RP/map_com.RDS\")\n\n\n\n\nOn agrège simplement par le nom et le code du département.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_dep &lt;- map_iris %&gt;% group_by(dep_code, dep_name) %&gt;% \n                  summarise()\nplot(map_dep[\"dep_code\"], main = \"Départements\")\n\n\n\nsaveRDS(map_dep, \"DATA/RP/map_dep.RDS\")\n\n\n\n\nNous allons maintenant examiner comment agréger les données individuelles de l’INSEE par iris, commune ou département et effectuer une jointure avec les fonds de cartes que nous avons préparé. On va s’appuyer pour cela sur le cours de datamining n°2 de Camille Signoretto.\nOn commence par recharger la fonction somme()que nous avions créé :\n\nsomme &lt;- function(data, var_gpe, nom_var){\n  som &lt;- data %&gt;% \n    group_by({{var_gpe}}) %&gt;% \n    count({{nom_var}}, wt=IPONDI) %&gt;% \n    mutate(n=round(n)) %&gt;% \n    pivot_wider(names_from = {{nom_var}}, values_from = n)\n  \n  return(som)\n}\n\nNous l’utilisons pour créer un tableau des individus par CSP simplifiées en 5 catégories et par IRIS :\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\"))\n\n# Agrégation par IRIS  \niris_csp &lt;- somme(data = indiv,\n                 var_gpe = IRIS,\n                 nom_var = TACT5)\n\n\n\n\nOn procède à la jointure des deux fichiers iris en utilisant le code des iris.\n\nmap_iris &lt;- readRDS(\"data/RP/map_iris.RDS\")\nmap_iris_csp&lt;- left_join(map_iris, iris_csp,by = c(\"iris_code\"=\"IRIS\"))\nsaveRDS(map_iris_csp, \"data/RP/map_iris_CSP.RDS\")\n\nOn examine quels IRIS ne sont pas renseignés en croisant cette information avec le type d’IRIS.\n\nmap_iris_csp$missing&lt;-case_when(is.na(map_iris_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_iris_csp[\"missing\"], main = \"IRIS sans données\")\n\n\n\ntab&lt;-table(map_iris_csp$missing,map_iris_csp$iris_type)\naddmargins(tab)\n\n          \n           commune iris d'activité iris d'habitat iris divers  Sum\n  Manquant       7              44              5          40   96\n  OK             0              74           2572           7 2653\n  Sum            7             118           2577          47 2749\n\n\nOn constate qu’il manque des données pour 96 IRIS sur 2749. Il s’agit dans la plupart des cas d’iris correspondant à des zones industrielles ou des forêts dont le nombre d’habitant est trop faible pour que les données soient mises à disposition au niveau individuel. Cela concerne également 7 communes de petites tailles et 5 iris d’habitat.\n\n\n\nOn reprend les programmes précédents par commune\n\n# Chargement du tableau\nindiv &lt;- readRDS(\"data/RP/RP_final.RDS\")\n\n# Création de CSP simplifiées\nindiv &lt;- indiv %&gt;% \n  mutate(TACT5=case_when(TACT == \"11\" ~ \"EMP\",\n                             TACT == \"12\" ~ \"CHO\",\n                             TACT == \"22\" ~ \"ETU\",\n                             TACT == \"21\" ~ \"RET\",\n                             TRUE ~ \"DIV\")) \n\n# Extraction du code communal \nindiv&lt;- indiv %&gt;%   mutate(com_code = substr(IRIS,1,5))\n\n# Agrégation par IRIS  \ncom_csp &lt;- somme(data = indiv,\n                 var_gpe = com_code,\n                 nom_var = TACT5)\n\n# Chargement du fonds de carte communal\nmap_com &lt;- readRDS(\"data/RP/map_com.RDS\")\n\n# Jointure\nmap_com_csp &lt;- left_join(map_com, com_csp)\n\n# Sauvegarde\nsaveRDS(map_com_csp, \"data/RP/map_com_csp.RDS\")\n\n# Analyse des valeurs manquantes\nmap_com_csp$missing&lt;-case_when(is.na(map_com_csp$CHO)  ~ \"Manquant\",\n                                TRUE ~ \"OK\"\n                               )\nplot(map_com_csp[\"missing\"], main= \"Communes sans données\")\n\n\n\n\nOn retrouve les 7 communes manquantes pour lesquelles l’INSEE ne fournit pas les données dans le fichier détail des individus."
  },
  {
    "objectID": "12-API-exo.html",
    "href": "12-API-exo.html",
    "title": "API-Exo",
    "section": "",
    "text": "Nous proposons une série d’exercices d’application du cours du chapitre précédent en allant des applications les plus simples au plux complexes. Les exercices portent tous sur la base de donnée des demandes de valeurs foncières géoloalisées que l’on peut trouver sur le site public.opendatasoft"
  },
  {
    "objectID": "12-API-exo.html#exercice-1-récupération-et-analyse-dun-tableau-unique",
    "href": "12-API-exo.html#exercice-1-récupération-et-analyse-dun-tableau-unique",
    "title": "API-Exo",
    "section": "Exercice 1 : Récupération et analyse d’un tableau unique",
    "text": "Exercice 1 : Récupération et analyse d’un tableau unique\n\nProblème\nEssayez de récupérer à l’aide d’une API les informations sur l’ensemble des ventes immobilières de maisons de la commune de Montcuq-en-Quercy-Blanc (code INSEE = 46201) au cours de l’année 2020. Vous devez ensuite\n\nAfficher les premières lignes du tableau des ventes de maisons à Moncuq en en 2020\nCalculer le nombre de ventes et leur prix moyen au m2\nRéaliser un histogramme du prix moyen de ces ventes sur lequel figureront le nombre de ventes et le prix moyen.\n\n\n\nSolution\nVous devez obtenir les résultats suivants :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nCommune\nCode\nSurf_hab\nSurf_ter\nPrix\nPrix_m2\n\n\n\n\n2020-01-06\nMontcuq-en-Quercy-Blanc\n46201\n280\n450\n270000\n964\n\n\n2020-01-31\nMontcuq-en-Quercy-Blanc\n46201\n60\n1258\n60000\n1000\n\n\n2020-02-07\nMontcuq-en-Quercy-Blanc\n46201\n27\n1275\n187000\n6926\n\n\n2020-02-07\nMontcuq-en-Quercy-Blanc\n46201\n79\n1275\n187000\n2367\n\n\n2020-02-20\nMontcuq-en-Quercy-Blanc\n46201\n40\nNA\n18000\n450\n\n\n2020-03-16\nMontcuq-en-Quercy-Blanc\n46201\n50\n800\n121000\n2420\n\n\n\n\n\n[1] \"Il ya eu 39 ventes au prix moyen de 1910 €/m2\""
  },
  {
    "objectID": "12-API-exo.html#exercice-2-tableau-de-bord-dune-commune",
    "href": "12-API-exo.html#exercice-2-tableau-de-bord-dune-commune",
    "title": "API-Exo",
    "section": "Exercice 2 : Tableau de bord d’une commune",
    "text": "Exercice 2 : Tableau de bord d’une commune\n\nProblème\nEssayez de récupérer à l’aide d’une API les informations sur l’ensemble des ventes immobilières de maisons ou d’appartement de la commune de Sucy-en-Brie (Code INSEE = 94071)\n\nSimplifiez le tableau pour ne garder que les variables suivantes\n\n\ndate : date de la transaction\ncode : code INSEE de la commune\nbien : type de bien (maison ou appartement)\nnom : nom de la commune\nprix : prix de vente total\nsurf : surface habitable\nprixm2 : prix au m2\n\n\nNettoyer le tableau en retirant les transactions dont le prix au m2 est supérieur à 10000€\nCréez un tableau montrant l’évolution par année des prix médian au m2 des maisons et des appartements.\nCréez un graphique montrant l’évolution mensuelle des prix au m2 des maisons et des appartements.\n\n\n\nSolution\nVous devez obtenir les résultats suivants :\n\n\n\n\n\ndate\ncode\nnom\nbien\nprix\nsurf\nprix_m2\n\n\n\n\n2014-01-10\n94071\nSucy-en-Brie\nAppartement\n212000\n62\n3419\n\n\n2014-01-16\n94071\nSucy-en-Brie\nMaison\n640000\n145\n4414\n\n\n2014-01-16\n94071\nSucy-en-Brie\nMaison\n640000\n145\n4414\n\n\n2014-01-17\n94071\nSucy-en-Brie\nAppartement\n115480\n45\n2566\n\n\n2014-01-21\n94071\nSucy-en-Brie\nMaison\n390000\n132\n2955\n\n\n2014-01-23\n94071\nSucy-en-Brie\nMaison\n690300\n140\n4931\n\n\n\n\n\n\nPrix médian de vente des maisons et appartement (en €/m2)\n\n\nAnnée\nVentes d’appartements\nVentes de maisons\n\n\n\n\n2014\n3200\n3666\n\n\n2015\n2889\n3541\n\n\n2016\n3069\n3636\n\n\n2017\n3249\n3783\n\n\n2018\n3455\n3753\n\n\n2019\n3537\n4097"
  },
  {
    "objectID": "12-API-exo.html#exercice-3-automatisation",
    "href": "12-API-exo.html#exercice-3-automatisation",
    "title": "API-Exo",
    "section": "Exercice 3 : Automatisation",
    "text": "Exercice 3 : Automatisation\nEcrivez le progamme de l’exercice 2 sous la forme d’une fonction prenant en entrée le code INSEE d’une commune quelconque."
  },
  {
    "objectID": "23-CARTO-leaflet.html",
    "href": "23-CARTO-leaflet.html",
    "title": "Carto-leaflet",
    "section": "",
    "text": "library(knitr)\n## Global options\noptions(max.print=\"80\")\nopts_chunk$set(echo=TRUE,\n               cache=FALSE,\n               prompt=FALSE,\n               tidy=FALSE,\n               comment=NA,\n               message=FALSE,\n               warning=FALSE,\n               options(scipen=999))\nopts_knit$set(width=75)\n\n# Packages utilitaires\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(rmdformats)\n\n# Packages graphiques\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n#packages cartographiques \nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(leaflet)\nlibrary(htmlwidgets)\nlibrary(htmltools)\n\n# Appel d'API\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(geojsonsf)"
  },
  {
    "objectID": "23-CARTO-leaflet.html#premiers-pas",
    "href": "23-CARTO-leaflet.html#premiers-pas",
    "title": "Carto-leaflet",
    "section": "Premiers pas",
    "text": "Premiers pas\n\nOBJECTIFS : Ce cours propose de fournir les bases élémentaires du logiciel Leaflet. Il est très largement inspiré d’un article d’Elena Salette publié sur l’excellent site de formation ThinkR et intitulé Cartographie interactive : comment visualiser mes données spatiales de manière dynamique avec leaflet ?\n\n\nBUG WARNING : Il peut arriver que la transformation du fichier .Rmd en .html ne s’opère pas et que vous voyiez apparaître le message d’erreur suivant RMarkdown cannot knit: html_dependency not found. Ce message d’erreur persiste même après avoir corrigé le code… ce qui est très pénible. Après avoir cherché sur les forums de discussion, j’ai trouvé une première réponse sur stackoverflow qui consiste simplement à aller sur la flèche descendnate à droite du bouton knitr et effectuer un clear knitr cache avant de relancer le Knitr. Apparemment ça marche, sans que je sache bien pourquoi. Mais la solution la plus efficace semble être d’insérer une option cache=FALSE dans les options globales du fichier Markdown. Cela va sans doute un peu ralentir l’affichage des pages HTML,mais évite les problèmes. On pourra toujours rétablir cache=TRUE si nécessaire\n\nNotre premier objectif très limité sera de construire une carte interactive utilisant le fonds de carte OpenStreetMap que l’on pourra zoomer en avant ou en arrière. La carte comportera la localisation de la place de la gare à Sucy-en-Brie avec une “épingle” de localisation comportant une photographie de la gare et un petit texte de promotion de celle-ci.\n\nLancement avec leaflet()\nNous allons avoir besoin des packages suivants :\n\nleaflet puisque c’est l’objet même du cours !\ndplyr afin de pouvoir construire des programmes utilisant des pipes %&gt;%\nsf pour charger des fonds de carte de différents types (points, lignes polygones)\nhtmltools et htmlwidgets pour ajouter des popups interactifs sur notre carte\n\nPour vérifier que le package leaflet est bien installé, nous créons une première carte (vide !)\n\nmap &lt;- leaflet()\n\nmap\n\n\n\n\n\nEt il n’y a … RIEN ! si ce n’est un bouton de zoom\n\n\nRemplissage avec addTiles()\nOn ajoute sur ce fond de carte vide des “tuiles” cartographiques qui sont des images se modifiant selon l’échelle pour apporter plus ou moins de détails. Par défaut, le fonds de carte de référence est le fonds OpenStreetMap\n\nlibrary(leaflet)\n\nmap &lt;- leaflet() %&gt;%\n          addTiles()\n\nmap\n\n\n\n\n\nLa carte est désormais interactive et on peut effectuer des zooms ou se déplacer.\n\n\nCalage avec setView()\nNous allons ensuite choisir un point de référence, par exemple la place de la gare à Sucy-en-Brie. Pour trouver les coordonnées de latitude et longitude, la solution la plus simple est d’utiliser Google Maps puis de zoomer sur la zone d’étude et enfin d’effectuer un click droit avec la souris sur le point dont on cherche les coordonnées pour obtenir dans un popup les coordonnées recherchées :\n On peut alors procéder à une double opération de centrage de notre carte et de définition d’une échelle d’observation afin que la carte produite par leafletcouvre bien la zone qui nous intéresse. Cette double opération est réalisée à l’aide de la fonction setView() assortie des trois paramètre suivants :\n\nlng = pour la longitude\nlat = pour la latitude\nzoom = pour le degré d’aggrandissement de la carte de 1 pour le Monde entier à 20 pour une vision ulra locale\n\n\nmap &lt;- leaflet() %&gt;% \n          addTiles() %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 17)\n\nmap\n\n\n\n\n\nUne fois qu’on a vérifié le centrage avec un zoom fort (ici 17), on peut refaire la carte en utilisant un zoom plus faible, par exemple un zoom de 12 permettant de visualiser toute la commune de Sucy et les communes voisines.\n\nmap &lt;- leaflet() %&gt;% \n          addTiles() %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 12)\n\nmap\n\n\n\n\n\n\n\nPersonalisation avec addProviderTiles()\nLes tuiles OpenStreetMap qui servent de fonds de carte par défaut peuvent être remplacés par des tuiles personalisées fournies par des producteurs publics ou privés. On peut obtenir la liste des tuiles disponibles en tapant providers dans la console de R studio et les tester une par une. Mais il est souvent plus simple et plus rapide d’aller visualiser les tuiles disponibles sur ce site web où l’on peut centrer le monde sur sa zone d’étude et voir ce que donnent les différentes familles de tuiles.\nA titre d’exemple, les tuiles OpenTopoMap permettent de voir la carte topographique de type IGN en couleur :\n\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('OpenTopoMap') %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 12)\n\nmap\n\n\n\n\n\nLa couche Esri.WorldTopoMap fournit également une imagerie précise mais de couleurs plus neutre que les tuiles OpenTopoMap ou OpenStreetMap , ce qui sera intéressant si on superspose des marqueurs de couleur vive.\n\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n          setView(lat = 48.77141, lng=2.50870, zoom = 12)\nmap\n\n\n\n\n\n\n\nAffichage d’un point avec addMarkers()\nL’usage le plus fréquent de leafletconsiste à ajouter des éléments de localisation ponctuelle appelés markerset de rendre ces objets ponctuels interactifs avec l’ouverture de fenêtres popupslorsqu’on clique dessus avec la souris. On va donc voir pas à pas comment construire de telles cartes interactives en partant du cas le plus simple (marqueur unique) pour aller vers les cas plus complexes (ensemble de marqueurs de taille, couleur et formes différentes).\nNous allons commencer par indiquer l’emplacement de la place de la gare de Sucy-en-Brie sur notre carte précédente à l’aide de la fonction addMarkers() :\n\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77141, lng=2.50870, zoom = 12) %&gt;% \n            addMarkers(lat = 48.77141, lng=2.50870)\nmap\n\n\n\n\n\nOn constate que le marqueur donne bien la position choisi mais n’est pas interactif. Il faut ajouter plus de paramètres pour assurer l’interactivité.\n\n\nAjout d’un labelou d’un popup\nOn peut définir deux comportements d’un marker selon que la souris ne fait que passer dessus (label) ou selon que l’utilisateur effectue un click sur marker et déclenche l’ouverture d’une fenêtre (popup). Dans sa version la plus simple, l’interactivité consiste à ajouter une chaîne de caractère à ces deux paramètres.\n\nicone_gare &lt;-makeIcon(iconUrl = \"img/gare_sucy_coord_googlemap.png\")\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77141, lng=2.50870, zoom = 12) %&gt;% \n            addMarkers(lat = 48.77141, lng=2.50870,\n                      # En passant la souris\n                      label = \"GARE DE SUCY-BONNEUIL\", \n                      # En cliquant sur l'icone\n                       popup = \"La gare RER A de Sucy Bonneuil est bien reliée aux communes \n                                 environnantes par un réseau de bus partant dans toutes les directions\")\nmap\n\n\n\n\n\n\n\nAmélioration du popup\nMais on peut faire beaucoup mieux, notamment pour la fenêtre popupqui peut prendre la forme d’une mini-page web dont on fixe le contenu en html avec la fonction paste0() et les dimensions avec le sous-paramètre popupOptions().\n\n# Préparation de la fenêtre Popup\n    my_popup = paste0(\n      \"&lt;b&gt; LA GARE DE SUCY\",\n      \"&lt;/b&gt;&lt;br/&gt;&lt;img src=https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Gare_Sucy-en-Brie.jpg/1200px-Gare_Sucy-en-Brie.jpg width='200px'&gt;&lt;br/&gt;\",\n      \"La gare RER A de Sucy Bonneuil est bien reliée aux communes \n                                 environnantes par un réseau de bus partant dans toutes les directions.\")\n\n\n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77141, lng=2.50870, zoom = 12) %&gt;% \n            addMarkers(lat = 48.77141, lng=2.50870,\n                      # En passant la souris\n                      label = \"GARE DE SUCY-BONNEUIL\", \n                      # En cliquant sur l'icone\n                       popup = my_popup, \n                      # Quelques options de la popup\n                        popupOptions = \n                      list(maxHeight = 150, maxWidth = 200))\nmap\n\n\n\n\n\n\n\nProlongements\nEt voila, le tour est joué. Il faut maintenant réfléchir à la façon de construire une carte comportant un ensemble d’épingles similaires avec des couleurs ou des formes différentes, des messages différents, des photographies variées … Il ne sera alors évidemment pas possible d’ajouter une commande addMarkers() pour chaque épingle si la carte en comporte des centaines.\nSi vous avez bien compris ce cours, vous pourrez trouver des réponses en lisant de façon autonome le reste de l’article dont nous nous somme inspiré : Cartographie interactive : comment visualiser mes données spatiales de manière dynamique avec leaflet ?"
  },
  {
    "objectID": "23-CARTO-leaflet.html#cartographie-de-points",
    "href": "23-CARTO-leaflet.html#cartographie-de-points",
    "title": "Carto-leaflet",
    "section": "Cartographie de points",
    "text": "Cartographie de points\nNous allons prendre comme exemple la base des équipements sportifs qui sera utilisée par la suite pour le projet de fin de semestre. Cette base peut être obtenue à travers deux API différentes :\n\nBase permanente des équipements sportifs et de loisirs : il s’agit d’une base qui est mise à jour en temps réel et est donc très utile lorsque l’on veut actualiser sa source régulièrement : https://equipements.sports.gouv.fr/explore/dataset/data-es/table/\nBase des équipements sportifs et de loisirs en 2017 : il s’agit d’une photographie de la situation en 2017 qui ne fait plus l’objet de maintenance. Elle est accessible par le site public.opendasoft qui a déjà été vue dans le premier cours https://public.opendatasoft.com/explore/dataset/res_equipements_2017/information/?disjunctive.caracteristiques&sort=equdatecreation\n\n\nPréparation des données\nOn télécharge à titre d’exemple la base des équipements sportifs et de loisirs de la commune de Sucy-en-Brie en 2017 à l’aide du site public.opendasoft. On utilise le format d’importation geojson et on crée un objet de type spatial features. On ne sélectionne que quelques caractéristiques des équipements\n\nmyurl &lt;- \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/res_equipements_2017/exports/geojson?lang=fr&refine=comlib%3A%22Sucy-en-Brie%22&timezone=Europe%2FBerlin\"\n\ndon&lt;-geojson_sf(myurl) %&gt;% st_as_sf()\n\nsel&lt;-don %&gt;% select(id = insnumeroinstall,\n                    ins = insnom,\n                    equ = equnom,\n                    typ =  equipementtypelib,\n                    anc = equanneeservice,\n                    sup = equsurfaceevolution\n                    ) %&gt;%\n              mutate(anc=as.numeric(anc),\n                     sup=as.numeric(sup)) %&gt;%\n              filter(is.na(anc)==F,\n                     is.na(sup)==F)\n\n\nkable(head(sel))\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nins\nequ\ntyp\nanc\nsup\ngeometry\n\n\n\n\n940710003\nAire de Proximite des Noyers\nCity Stade\nPlateau EPS/Multisports/city-stades\n1999\n364\nPOINT (2.50918 48.77929)\n\n\n940710018\nParc des Sports de Sucy en Brie\n2 Courts de Tennis Exterieurs 1 et 2\nCourt de tennis\n1969\n648\nPOINT (2.53637 48.75876)\n\n\n940710002\nStade Paul Meyer\n2 Terrains de Football D et E Eclaires\nTerrain de football\n1980\n6825\nPOINT (2.50398 48.77557)\n\n\n940710002\nStade Paul Meyer\nTerrain de Rugby Honneur A Non Eclaire\nTerrain de rugby\n1980\n8400\nPOINT (2.50548 48.77563)\n\n\n940710016\nGymnase du Piple\nLe Gymnase\nSalle multisports\n1996\n800\nPOINT (2.52598 48.75997)\n\n\n940710018\nParc des Sports de Sucy en Brie\nTerrain de Rugby 2\nTerrain de rugby\n1988\n7080\nPOINT (2.54191 48.7595)\n\n\n\n\n\nOn décide de repérer uniquement les terrains de rugby, de football et de tennis\n\nsel &lt;- sel %&gt;% filter(typ %in% c(\"Court de tennis\",\"Terrain de football\",\"Terrain de rugby\")) %&gt;%\n              mutate(typ=as.factor(typ))\nsummary(sel)\n\n      id                ins                equ           \n Length:27          Length:27          Length:27         \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                  typ          anc            sup                geometry \n Court de tennis    :11   Min.   :1969   Min.   : 640   POINT        :27  \n Terrain de football:11   1st Qu.:1980   1st Qu.: 648   epsg:4326    : 0  \n Terrain de rugby   : 5   Median :1980   Median :5225   +proj=long...: 0  \n                          Mean   :1983   Mean   :4166                     \n                          3rd Qu.:1980   3rd Qu.:7005                     \n                          Max.   :2016   Max.   :8625                     \n\n\n\n\nCartographie des localisations\nOn commence par créer une carte des localisations des installations sportives avec AddCircleMarkers()\n\n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77, lng=2.53, zoom = 13) %&gt;%\n             addCircleMarkers(data=sel)\n\nmap\n\n\n\n\n\n\n\nRéglage de la taille des cercles\nOn règle la taille des cercles en fonction de la surface des installations\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77, lng=2.53, zoom = 13) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,    # diamètre\n                              stroke=FALSE,         # pas de bordure           \n                              fillOpacity = 0.5)    # opacité \n            \n                              \n\nmap\n\n\n\n\n\n\n\nRéglage de la couleur des cercles\nOn fait varier la couleur des cercles en fonction due l’ancienneté des installations\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n\n# Choix des classes \n    mycut&lt;-c(1960,1970,1980,2000,2010,2016)\n    \n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('Spectral', \n                       reverse = T,\n                       sel$anc,\n                       bins=mycut)\n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77, lng=2.53, zoom = 13) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,    # diamètre\n                              stroke=TRUE,          # bordure   \n                              weight=1  ,           # épaisseur de la bordure\n                              color= \"black\",      # couleur de la bordure\n                              opacity = 0.7  ,       # opacité de la bordure \n                              fillOpacity = 0.5,    # opacité \n                              fillColor = ~mypal(anc)\n                              )    %&gt;%\n              addLegend(data = sel,\n                      pal = mypal, \n                      title = \"Ancienneté\",\n                      values =~anc, \n                      position = 'topright') \n            \n                              \n\nmap\n\n\n\n\n\n\n\nAjout d’un popup d’information\nOn rajoute un popup pour afficher toutes les informations sur chaque terrain\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n\n# Choix des classes \n    mycut&lt;-c(1960,1970,1980,2000,2010,2016)\n    \n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('Spectral', \n                       reverse = T,\n                       sel$anc,\n                       bins=mycut)\n# Préparation des popups\n      mypopups &lt;- lapply(seq(nrow(sel)), function(i) {\n      paste0(  paste(\"Installation: \" ,sel$ins[i]), '&lt;br&gt;', \n               paste(\"Equipement  : \" ,sel$equ[i]), '&lt;br&gt;', \n               paste(\"Type        : \" ,sel$typ[i]), '&lt;br&gt;',               \n               paste(\"Surface     : \", sel$sup[i]), '&lt;br&gt;',\n               paste(\"Ancienneté  : \" ,sel$anc[i]))\n            \n            })\n      mypopups&lt;-lapply(mypopups, htmltools::HTML)  \n      \n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n            addProviderTiles('Esri.WorldTopoMap') %&gt;%\n            setView(lat = 48.77, lng=2.53, zoom = 13) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,       # diamètre\n                              stroke=TRUE,             # bordure   \n                              weight=1  ,              # épaisseur de la bordure\n                              color= \"black\",          # couleur de la bordure\n                              opacity = 0.7  ,         # opacité de la bordure \n                              fillOpacity = 0.5,       # opacité du remplissage\n                              fillColor = ~mypal(anc), # couleur de remplissage\n                               popup = mypopups,       # Popup !\n                              )    %&gt;%\n              addLegend(data = sel,\n                      pal = mypal, \n                      title = \"Ancienneté\",\n                      values =~anc, \n                      position = 'topright') \n            \n                              \n\nmap\n\n\n\n\n\n\n\nChoix des tuiles\nOn fait varier les tuiles pour offrir la possibilité de visualiser la position des maisons sur un plan ou sur une photo aérienne.\n\n# Calcul du diamètre des cercles\n  sel$myradius &lt;-10*sqrt(sel$sup/max(sel$sup,na.rm=T))\n\n# Choix des classes \n    mycut&lt;-c(1960,1970,1980,2000,2010,2016)\n    \n# Choix de la palette (c'est une fonction !)\n   mypal &lt;- colorBin('Spectral', \n                       reverse = T,\n                       sel$anc,\n                       bins=mycut)\n# Préparation des popups\n      mypopups &lt;- lapply(seq(nrow(sel)), function(i) {\n      paste0(  paste(\"Installation: \" ,sel$ins[i]), '&lt;br&gt;', \n               paste(\"Equipement  : \" ,sel$equ[i]), '&lt;br&gt;', \n               paste(\"Type        : \" ,sel$typ[i]), '&lt;br&gt;',               \n               paste(\"Surface     : \", sel$sup[i]), '&lt;br&gt;',\n               paste(\"Ancienneté  : \" ,sel$anc[i]))\n            \n            })\n      mypopups&lt;-lapply(mypopups, htmltools::HTML)  \n      \n  \n# Réalisation de la carte\nmap &lt;- leaflet() %&gt;% \n               # Tuiles\n               addTiles(group = \"OSM \") %&gt;%\n               addProviderTiles('Esri.WorldTopoMap', group = \"ESRI topo.\") %&gt;%\n               addProviderTiles('Esri.WorldImagery', group = \"ESRI photo.\") %&gt;%\n              # Contrôle des tuiles\n               addLayersControl( baseGroups = c(\"OSM\",\"ESRI topo.\",\"ESRI photo.\"),\n                                 position = \"bottomright\") %&gt;%\n            setView(lat = 48.77, lng=2.53, zoom = 13) %&gt;%\n  \n             addCircleMarkers(data=sel,\n                              radius= ~myradius,       # diamètre\n                              stroke=TRUE,             # bordure   \n                              weight=1  ,              # épaisseur de la bordure\n                              color= \"black\",          # couleur de la bordure\n                              opacity = 0.7  ,         # opacité de la bordure \n                              fillOpacity = 0.5,       # opacité du remplissage\n                              fillColor = ~mypal(anc), # couleur de remplissage\n                               popup = mypopups,       # Popup !\n                              )    %&gt;%\n              addLegend(data = sel,\n                      pal = mypal, \n                      title = \"Ancienneté\",\n                      values =~anc, \n                      position = 'topright') \n            \n                              \n\nmap"
  },
  {
    "objectID": "23-CARTO-leaflet.html#exercice-dapplication",
    "href": "23-CARTO-leaflet.html#exercice-dapplication",
    "title": "Carto-leaflet",
    "section": "Exercice d’application",
    "text": "Exercice d’application\nConstruire une carte interactive de la localisation des courts de tennis en Ile de France en utilisant les données les plus récentes.\n\nAcquisition des données\nImportez un fichier de tous les courts de tennisde France au format geojson que vous transformerez au format sf. Puis sélectionnez les quatre départements 75, 92, 93, 94\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ncom\nins\nequ\ntyp\nanc\nsup\ngeometry\n\n\n\n\n920040011\n92004\nTennis Club du Menil\nCourt de Tennis Couvert\nCourt de tennis\n1983\n648\nPOINT (2.28549 48.92151)\n\n\n920250007\n92025\nTennis Club Amiot\nMini Tennis\nCourt de tennis\n2004\n93\nPOINT (2.24056 48.92773)\n\n\n920400006\n92040\nTennis de Issy-Les-Moulineaux\nCourts de Tennis N° 2, 3, 4, 5\nCourt de tennis\n1987\n608\nPOINT (2.25639 48.81656)\n\n\n920400047\n92040\nHalle des Sports Christiane Guillaume\nTerrains de Tennis Decouverts\nCourt de tennis\n2007\n594\nPOINT (2.26426 48.82562)\n\n\n930620002\n93062\nCentre Boulevard du Nord\nCourts de Tennis 4\nCourt de tennis\n1990\n648\nPOINT (2.51619 48.90288)\n\n\n930630003\n93063\nComplexe Sportif Paul Baldit\nMini Tennis\nCourt de tennis\n1966\n135\nPOINT (2.44047 48.88761)\n\n\n\n\n\n\n\nPremière carte : localisation\nConstruisez une première carte indiquant simplement la localisation des courts de tennis sous la forme de cercles rouge de rayon 4 pixels et d’opacité 0.5. La carte devra être centrée sur Paris et couvrir Paris et la Petite Couronne.\n\n\n\n\n\n\n\n\nDeuxième carte : Ancienneté\nConstruisez une seconde carte permettant de repérer l’ancienneté des terrains de tennis."
  },
  {
    "objectID": "10-API-INTRO.html",
    "href": "10-API-INTRO.html",
    "title": "Introduction aux API",
    "section": "",
    "text": "library(knitr,warn.conflicts = T,quietly = T)\nlibrary(dplyr, warn.conflicts = T,quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "10-API-INTRO.html#introduction",
    "href": "10-API-INTRO.html#introduction",
    "title": "Introduction aux API",
    "section": "Introduction",
    "text": "Introduction\n\nDéfinition\nOn peut partir de la définition suivante:\n\nEn informatique, API est l’acronyme d’Application Programming Interface, que l’on traduit en français par interface de programmation applicative ou interface de programmation d’application. L’API peut être résumée à une solution informatique qui permet à des applications de communiquer entre elles et de s’échanger mutuellement des services ou des données. Il s’agit en réalité d’un ensemble de fonctions qui facilitent, via un langage de programmation, l’accès aux services d’une application. (Source : Journal du Net)\n\n\n\nFonctions\nUne API peut remplir des fonctions très diverses :\n\nDans le domaine d’internet, l’API permet aux développeurs de pouvoir utiliser un programme sans avoir à se soucier du fonctionnement complexe d’une application. Les API peuvent par exemple être utilisées pour déclencher des campagnes publicitaires d’e-mailing de façon automatique sans avoir à passer par la compréhension d’une telle application (c’est le cas avec l’API AdWords de Google, par exemple). On les retrouve aujourd’hui dans de nombreux logiciels, en particulier dans les systèmes d’exploitation, les serveurs d’applications, dans le monde du graphisme (OpenGL), dans les applications SaaS (Office 365, G Suite, Salesforce…), les bases de données, l’open data, etc.(Source : Journal du Net)\n\n\n\nProtocoles\nD’une manière générale, les API supposent un échange d’informations entre un client et un serveur.\n\nCes échanges d’informations suivent un protocole c’est-à-dire un ensemble de règles. Il existe deux grands protocoles de communication sur lesquels s’adossent les API : Simple Object Access Protocol (SOAP) et Representational State Transfer (REST). Le second s’est désormais largement imposé face au premier car il est plus flexible. Il a donné naissance aux API dites REST ou RESTful (Source : Journal du Net)\n\n\n\nAPI et Data Science\nLe métier de data analyst implique presque nécessairement l’emploi d’API. Les langages de programmation R ou Python ont donc l’un comme l’autre mis au point des packages pour faciliter l’envoi de requêtes sur des serveurs dotés d’API.\n\n«API» est un terme général désignant le lieu où un programme informatique interagit avec un autre ou avec lui-même. Dans ce didacticiel, nous travaillerons spécifiquement avec des API Web, où deux ordinateurs différents - un client et un serveur - interagiront l’un avec l’autre pour demander et fournir des données, respectivement.\n\n\nLes API offrent aux scientifiques des données un moyen raffiné de demander des données propres et organisées à partir d’un site Web. Lorsqu’un site Web comme Facebook met en place une API, il met essentiellement en place un ordinateur qui attend les demandes de données.\n\n\nUne fois que cet ordinateur reçoit une demande de données, il effectuera son propre traitement des données et les enverra à l’ordinateur qui l’a demandé. De notre point de vue en tant que demandeur, nous devrons écrire du code dans R qui crée la demande et indique à l’ordinateur exécutant l’API ce dont nous avons besoin. Cet ordinateur lira ensuite notre code, traitera la requête et renverra des données bien formatées qui peuvent être facilement analysées par les bibliothèques R existantes.\n\n\nPourquoi est-ce précieux? Comparez l’approche API au scraping Web pur. Lorsqu’un programmeur gratte une page Web, il reçoit les données dans un morceau de HTML désordonné. Bien qu’il existe certainement des bibliothèques qui facilitent l’analyse du texte HTML, ce sont toutes des étapes de nettoyage qui doivent être prises avant même de mettre la main sur les données que nous voulons!\n\n\nSouvent, nous pouvons immédiatement utiliser les données que nous obtenons d’une API, ce qui nous fait gagner du temps et de la frustration.\n\nSource : Traduction française d’un billet de Pascual C., 2020"
  },
  {
    "objectID": "10-API-INTRO.html#lapi-de-la-nasa",
    "href": "10-API-INTRO.html#lapi-de-la-nasa",
    "title": "Introduction aux API",
    "section": "l’API de la NASA",
    "text": "l’API de la NASA\nA titre d’exemple, C. Pascual propose de travailler avec l’API Open Notify, qui donne accès à des données sur divers projets de la NASA. À l’aide de l’API Open Notify, nous pouvons notamment en savoir plus sur l’emplacement de la Station spatiale internationale et sur le nombre de personnes actuellement dans l’espace.\n\nInstaller les packages jsonlite et httr\nPour travailler avec des API dans R, nous devons intégrer certaines bibliothèques (library). Ces bibliothèques prennent toutes les complexités d’une requête d’API et les enveloppent dans des fonctions que nous pouvons utiliser dans des lignes de code uniques. Les bibliothèques R que nous utiliserons sont httr et jsonlite. Elles remplissent des rôles différents dans notre introduction des API, mais les deux sont essentiels.Si vous ne disposez pas de ces bibliothèques dans votre console R ou RStudio, vous devez d’abord les télécharger.\n\nlibrary(httr)\nlibrary(jsonlite)\n\n\n\nFormulation d’une requête GET()\nUne requête adressé à une API va suivre le schéma suivant :\n\nknitr::include_graphics(\"img/API_GET.png\",)\n\n\n\n\nIl existe plusieurs types de requêtes que l’on peut adresser à un serveur API. Pour nos besoins, nous allons simplement demander des données, ce qui correspond à une demande GET. Les autres types de requêtes sont POST et PUT, mais nous n’avons pas à nous en préoccuper dans l’immédiat\nAfin de créer une requête GET, nous devons utiliser la fonction GET() de la bibliothèque httr. La fonction GET() nécessite une URL, qui spécifie l’adresse du serveur auquel la demande doit être envoyée.\nNotre programme télécharge les données disponibles à l’adresse du serveur et les stocke dans un objet auquel on peut donner le nom que l’on souhaite, par exemple ovni dans la mesure où le résultat est de prime abord assez mystérieux…\n\novni &lt;- GET(\"http://api.open-notify.org/astros.json\")\nclass(ovni)\n\n[1] \"response\"\n\n\nOn sait que la classe de l’objet est de type response ce qui ne nous avance pas beaucoup.\nToutefois, si on demande à l’objet de s’afficher il nous apporte quatre renseignements utiles\n\novni\n\nResponse [http://api.open-notify.org/astros.json]\n  Date: 2024-03-23 16:17\n  Status: 200\n  Content-Type: application/json\n  Size: 360 B\n\n\n\nDate : le moment exact du téléchargement, très utile pour suivre les mises à jour\nStatus : le code informatique de résultat de la requête. La valeur 200 indique un succès alors que les autres valeurs signaleront un problème.\nContent-Type : le type d’information recueillie. Ici, une application au format json\nSize : la taille du fichier résultant du transfert.\n\nOn poursuit notre enquête en tapant la commande str() qui permet d’avoir plus de détail sur le contenu de l’objet.\n\nstr(ovni)\n\nList of 10\n $ url        : chr \"http://api.open-notify.org/astros.json\"\n $ status_code: int 200\n $ headers    :List of 6\n  ..$ server                     : chr \"nginx/1.10.3\"\n  ..$ date                       : chr \"Sat, 23 Mar 2024 16:17:00 GMT\"\n  ..$ content-type               : chr \"application/json\"\n  ..$ content-length             : chr \"360\"\n  ..$ connection                 : chr \"keep-alive\"\n  ..$ access-control-allow-origin: chr \"*\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ all_headers:List of 1\n  ..$ :List of 3\n  .. ..$ status : int 200\n  .. ..$ version: chr \"HTTP/1.1\"\n  .. ..$ headers:List of 6\n  .. .. ..$ server                     : chr \"nginx/1.10.3\"\n  .. .. ..$ date                       : chr \"Sat, 23 Mar 2024 16:17:00 GMT\"\n  .. .. ..$ content-type               : chr \"application/json\"\n  .. .. ..$ content-length             : chr \"360\"\n  .. .. ..$ connection                 : chr \"keep-alive\"\n  .. .. ..$ access-control-allow-origin: chr \"*\"\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ cookies    :'data.frame':    0 obs. of  7 variables:\n  ..$ domain    : logi(0) \n  ..$ flag      : logi(0) \n  ..$ path      : logi(0) \n  ..$ secure    : logi(0) \n  ..$ expiration: 'POSIXct' num(0) \n  ..$ name      : logi(0) \n  ..$ value     : logi(0) \n $ content    : raw [1:360] 7b 22 6d 65 ...\n $ date       : POSIXct[1:1], format: \"2024-03-23 16:17:00\"\n $ times      : Named num [1:6] 0 0.0363 0.1878 0.1878 0.3444 ...\n  ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n $ request    :List of 7\n  ..$ method    : chr \"GET\"\n  ..$ url       : chr \"http://api.open-notify.org/astros.json\"\n  ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. ..- attr(*, \"names\")= chr \"Accept\"\n  ..$ fields    : NULL\n  ..$ options   :List of 2\n  .. ..$ useragent: chr \"libcurl/8.1.2 r-curl/5.0.2 httr/1.4.7\"\n  .. ..$ httpget  : logi TRUE\n  ..$ auth_token: NULL\n  ..$ output    : list()\n  .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  ..- attr(*, \"class\")= chr \"request\"\n $ handle     :Class 'curl_handle' &lt;externalptr&gt; \n - attr(*, \"class\")= chr \"response\"\n\n\nNous savons désormais que notre objet ovni est une liste comportant 10 branches, elles-mêmes divisées en sous branches qui peuvent être elles-même des listes…\n\n\nRemarque sur les listes\nLes listes sont des objets complexes mais fondamentaux pour la programmation en R. On peut accèder aux branches d’une liste soit en utilisant une série de $ soit en se servant de doubles crochets [[ ]]. Par exemple, si on veut accèder à la date de la réponse on peut taper au choix :\n\novni$headers$date\n\n[1] \"Sat, 23 Mar 2024 16:17:00 GMT\"\n\novni[[\"headers\"]][[\"date\"]]\n\n[1] \"Sat, 23 Mar 2024 16:17:00 GMT\"\n\n\nOn peut également afficher les noms des branches en partant de la racine puis en suivant l’arbre à l’aide de l’instruction names()\n\nnames(ovni$headers)\n\n[1] \"server\"                      \"date\"                       \n[3] \"content-type\"                \"content-length\"             \n[5] \"connection\"                  \"access-control-allow-origin\"\n\n\n\nnames(ovni$fields)\n\nNULL\n\n\n\n\nExtraction des données\nLes données contenues dans la réponse ont été stockées au format JSON (JavaScript Object Notation) qui est devenu un standard pour les échanges de données. Mais elles ont été ensuite comprimées en format binaire pour limiter la taille du fichier transféré. Il va donc falloir procéder en quatre étapes pour les extraire\n\nétape 1 : récupérer les données au format binaire\nOn extrait le champ de données dans la liste. Le résultat est assez étrange :\n\nlibrary(rvest)\ndon_bin&lt;-ovni$content\ndon_bin\n\n  [1] 7b 22 6d 65 73 73 61 67 65 22 3a 20 22 73 75 63 63 65 73 73 22 2c 20 22 70\n [26] 65 6f 70 6c 65 22 3a 20 5b 7b 22 6e 61 6d 65 22 3a 20 22 4a 61 73 6d 69 6e\n [51] 20 4d 6f 67 68 62 65 6c 69 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53\n [76] 22 7d 2c 20 7b 22 6e 61 6d 65 22 3a 20 22 41 6e 64 72 65 61 73 20 4d 6f 67\n[101] 65 6e 73 65 6e 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 2c 20\n[126] 7b 22 6e 61 6d 65 22 3a 20 22 53 61 74 6f 73 68 69 20 46 75 72 75 6b 61 77\n[151] 61 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 2c 20 7b 22 6e 61\n[176] 6d 65 22 3a 20 22 4b 6f 6e 73 74 61 6e 74 69 6e 20 42 6f 72 69 73 6f 76 22\n[201] 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 2c 20 7b 22 6e 61 6d 65\n[226] 22 3a 20 22 4f 6c 65 67 20 4b 6f 6e 6f 6e 65 6e 6b 6f 22 2c 20 22 63 72 61\n[251] 66 74 22 3a 20 22 49 53 53 22 7d 2c 20 7b 22 6e 61 6d 65 22 3a 20 22 4e 69\n[276] 6b 6f 6c 61 69 20 43 68 75 62 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53\n[301] 53 22 7d 2c 20 7b 22 6e 61 6d 65 22 3a 20 22 4c 6f 72 61 6c 20 4f 27 48 61\n[326] 72 61 22 2c 20 22 63 72 61 66 74 22 3a 20 22 49 53 53 22 7d 5d 2c 20 22 6e\n[351] 75 6d 62 65 72 22 3a 20 37 7d\n\n\n\n\nétape 2 : convertir les données binaires au format caractère\nLa conversion est effectuée à l’aide de la fonction rawToChar() qui fait partie de R-Base.\n\n# conversion du contenu de toto en mode character\ndon_car&lt;-rawToChar(don_bin)\ndon_car\n\n[1] \"{\\\"message\\\": \\\"success\\\", \\\"people\\\": [{\\\"name\\\": \\\"Jasmin Moghbeli\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Andreas Mogensen\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Satoshi Furukawa\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Konstantin Borisov\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Oleg Kononenko\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Nikolai Chub\\\", \\\"craft\\\": \\\"ISS\\\"}, {\\\"name\\\": \\\"Loral O'Hara\\\", \\\"craft\\\": \\\"ISS\\\"}], \\\"number\\\": 7}\"\n\n\nOn commence à mieux voir le résultat mais ce n’est pas encore très lisible car il s’agit de données au format JSON\n\n\nétape 3 : convertir les données JSON en objet R\nOn convertit les données de type JSON en données utilisables par R à l’aide de la fonction fromJson() du package jsonlite()\n\ndon_R &lt;- fromJSON(don_car)\nstr(don_R)\n\nList of 3\n $ message: chr \"success\"\n $ people :'data.frame':    7 obs. of  2 variables:\n  ..$ name : chr [1:7] \"Jasmin Moghbeli\" \"Andreas Mogensen\" \"Satoshi Furukawa\" \"Konstantin Borisov\" ...\n  ..$ craft: chr [1:7] \"ISS\" \"ISS\" \"ISS\" \"ISS\" ...\n $ number : int 7\n\n\nOn obtient finalement une liste de trois éléments dont le dernier est un data.frame décrivant les astronautes présents dans la station spatiale internationale au moment de l’execution du programme.\n\n\nétape 4 : Récupérer le tableau de résultats\n\ntab&lt;-don_R$people\nkable(tab,caption = \"Passagers de l'ISS en temps réel\")\n\n\nPassagers de l’ISS en temps réel\n\n\nname\ncraft\n\n\n\n\nJasmin Moghbeli\nISS\n\n\nAndreas Mogensen\nISS\n\n\nSatoshi Furukawa\nISS\n\n\nKonstantin Borisov\nISS\n\n\nOleg Kononenko\nISS\n\n\nNikolai Chub\nISS\n\n\nLoral O’Hara\nISS\n\n\n\n\n\n\n\n\nEcriture d’une fonction\nUne fois que l’on a bien compris la procédure d’extraction de cette API, on peut construire une fonction d’extraction pour simplifier la tâche et l’automatiser :\n\n## Fonction\nextract_ISS &lt;- function(){\n  ovni &lt;- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin&lt;-ovni$content\n  don_char&lt;-rawToChar(don_bin)\n  don_R&lt;-fromJSON(don_char)\n  tab&lt;-don_R$people\n  return(tab)\n}\n\n## Application\nextract_ISS()\n\n                name craft\n1    Jasmin Moghbeli   ISS\n2   Andreas Mogensen   ISS\n3   Satoshi Furukawa   ISS\n4 Konstantin Borisov   ISS\n5     Oleg Kononenko   ISS\n6       Nikolai Chub   ISS\n7       Loral O'Hara   ISS\n\n\nOn peut améliorer la fonction en lui faisant ajouter un champ qui indique la date à laquelle a été effectué le relevé :\n\n## Fonction\nextract_ISS2 &lt;- function(){\n  ovni &lt;- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin&lt;-ovni$content\n  don_char&lt;-rawToChar(don_bin)\n  don_R&lt;-fromJSON(don_char)\n  tab&lt;-don_R$people\n  tab$date&lt;-ovni$headers$date\n  return(tab)\n}\n\n## Application\nextract_ISS2()\n\n                name craft                          date\n1    Jasmin Moghbeli   ISS Sat, 23 Mar 2024 16:17:01 GMT\n2   Andreas Mogensen   ISS Sat, 23 Mar 2024 16:17:01 GMT\n3   Satoshi Furukawa   ISS Sat, 23 Mar 2024 16:17:01 GMT\n4 Konstantin Borisov   ISS Sat, 23 Mar 2024 16:17:01 GMT\n5     Oleg Kononenko   ISS Sat, 23 Mar 2024 16:17:01 GMT\n6       Nikolai Chub   ISS Sat, 23 Mar 2024 16:17:01 GMT\n7       Loral O'Hara   ISS Sat, 23 Mar 2024 16:17:01 GMT\n\n\nEt si on est à l’aise avec les listes, on peut aussi exporter les résultats sous la forme d’une liste plutôt que d’un tableau, ce qui évite de répéter plusieurs fois la date d’extraction des données\n\n## Fonction\nextract_ISS3 &lt;- function(){\n  ovni &lt;- GET(\"http://api.open-notify.org/astros.json\") \n  don_bin&lt;-ovni$content\n  don_char&lt;-rawToChar(don_bin)\n  don_R&lt;-fromJSON(don_char)\n  tab&lt;-don_R$people\n  date&lt;-ovni$headers$date\n  result&lt;-list(\"Update\" = date,\"Data\" =tab)\n  return(result)\n}\n\n## Application\nx&lt;-extract_ISS3()\nkable(x$Data, caption=paste(\"Passagers de l'ISS :\", x$Update))\n\n\nPassagers de l’ISS : Sat, 23 Mar 2024 16:17:01 GMT\n\n\nname\ncraft\n\n\n\n\nJasmin Moghbeli\nISS\n\n\nAndreas Mogensen\nISS\n\n\nSatoshi Furukawa\nISS\n\n\nKonstantin Borisov\nISS\n\n\nOleg Kononenko\nISS\n\n\nNikolai Chub\nISS\n\n\nLoral O’Hara\nISS\n\n\n\n\n\n\n\nAPI et mise à jour en temps réel\nSur le site web du billet proposé par C. Pascual en février 2020, on trouve une autre liste ne comportant que 6 passagers et avec des noms totalement différents :\n\n\n\nPassagers de l’ISS en février 2020\n\n\ncraft\nname\n\n\n\n\nISS\nChristina Koch\n\n\nISS\nAlexander Skvortsov\n\n\nISS\nLuca Parmitano\n\n\nISS\nAndrew Morgan\n\n\nISS\nOleg Skripochka\n\n\nISS\nJessica Meir\n\n\n\n\n\nEn effet, l’API renvoie les résultats au moment de l’execution de la fonction GET() ce qui correspond à février 2020 pour le billet de blog. Or, les astronautes sont remplacés au plus tous les six mois ce qui explique que tous les noms soient différents un an après.\nNB : Cet exemple permet de mettre en évidence une fonction centrale des API qui est la mise à jour en temps réel des données !"
  },
  {
    "objectID": "22-CARTO-mapsf.html",
    "href": "22-CARTO-mapsf.html",
    "title": "Carto. statique",
    "section": "",
    "text": "Le package mapsf permet de réaliser des cartes statiques de très haute qualité. Il a en effet été mis au point par des cartographes et des géomaticiens professionnels de l’UMS RIATE. Il prend la suite du package cartography dont la maintenance demeurera assuré quelque temps encore mais ne fera plus l’objet de développements futurs. Le package mapsf présente l’avantage d’être totalement compatibvle avec le package sf ce qui n’était pas autant le cas pour le package cartography, plus ancien, et créé pour être compatible avec l’ancien package sp.\nOn trouvera la documentation du package mapsf à l’adresse suivante :\nhttps://riatelab.github.io/mapsf/index.html"
  },
  {
    "objectID": "22-CARTO-mapsf.html#le-package-map_sf",
    "href": "22-CARTO-mapsf.html#le-package-map_sf",
    "title": "Carto. statique",
    "section": "",
    "text": "Le package mapsf permet de réaliser des cartes statiques de très haute qualité. Il a en effet été mis au point par des cartographes et des géomaticiens professionnels de l’UMS RIATE. Il prend la suite du package cartography dont la maintenance demeurera assuré quelque temps encore mais ne fera plus l’objet de développements futurs. Le package mapsf présente l’avantage d’être totalement compatibvle avec le package sf ce qui n’était pas autant le cas pour le package cartography, plus ancien, et créé pour être compatible avec l’ancien package sp.\nOn trouvera la documentation du package mapsf à l’adresse suivante :\nhttps://riatelab.github.io/mapsf/index.html"
  },
  {
    "objectID": "22-CARTO-mapsf.html#création-dun-template-cartographique",
    "href": "22-CARTO-mapsf.html#création-dun-template-cartographique",
    "title": "Carto. statique",
    "section": "Création d’un template cartographique",
    "text": "Création d’un template cartographique\nNous allons dans un premier temps apprendre à créer un fonds de carte vierge mais comportant tout l’habillage nécessaire (“template”). Pour cela nous allons charger différentes couches cartographiques correspondant respectivement au département, aux communes et aux iris.\nAfin d’éviter les déformations, les fonds de carte sont projetés selon la projection de référence en France (code 2154)\n\nmap_iris&lt;-readRDS(\"data/RP/map_iris_csp.RDS\") %&gt;% st_transform(crs=2154)\nmap_com &lt;-readRDS(\"data/RP/map_com_csp.RDS\") %&gt;% st_transform(crs=2154)\nmap_dep &lt;-readRDS(\"data/RP/map_dep.RDS\") %&gt;% st_transform(crs=2154)\n\n\ntracé d’un fonds de carte vierge\n\n mf_map(map_iris, type = \"base\")\n\n\n\n\n\n\nSuperposition de couches\nOn peut toutefois ajouter toute une série de paramètres supplémentaire (col=, border=, lwd=, …) et superposer plusieurs fonds de carte avec le paramètre add = TRUE. L’ajout de la fonction layout permet de rajouter un cadre une légende.\n\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\n# Ajoute un cadre, un titre et des sources\nmf_layout(title = \"Paris et Petite Couronne\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\n\n\nAjout d’un thème\nOn peut finalement modifier l’ensemble de la carte en lui ajoutant une instruction mf_theme() qui peut reprendre des styles existants ( “default”, “brutal”, “ink”, “dark”, “agolalight”, “candy”, “darkula”, “iceberg”, “green”, “nevermind”, “jsk”, “barcelona”) mais aussi créer ses propres thèmes\n\n#Choix du thème\nmf_theme(\"dark\")\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\nmf_layout(title = \"Theme dark\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\nAutre exemple\n\n#Choix du thème\nmf_theme(\"agolalight\")\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\nmf_layout(title = \"Theme agolalight\", \n          credits = \"Sources : IGN et INSEE\")\n\n\n\n\n\n\nAjout de texte\nOn peut ajouter une couche de texte avec la fonction mf_label(). Par exemple, on va ajouter à la carte précédente le nom des communes\n\n#Choix du thème\nmf_theme(\"agolalight\")\n# Trace les Iris avec des paramètres\nmf_map(map_iris,  type = \"base\", \n       col = \"lightyellow\", border=\"gray80\",lwd=0.3)\n# Ajoute les contours des communes\nmf_map(map_com,  type = \"base\", \n       col = NA,border=\"black\",lwd=0.6,\n       add = TRUE)\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,border=\"red\",lwd=1,\n       add = TRUE)\n\n# Ajoute les noms des départements\nmf_label(map_dep, \n         var=\"dep_name\",\n         cex=0.8, \n         col=\"blue\",\n         overlap = FALSE)\n\n# Ajoute un cadre, un titre et des sources\nmf_layout(title = \"Communes et Iris de Paris + PC en 2019\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-de-stock",
    "href": "22-CARTO-mapsf.html#carte-de-stock",
    "title": "Carto. statique",
    "section": "Carte de stock",
    "text": "Carte de stock\nUne carte de stock représente la localisation de quantités que l’on peut aditionner et dont le total a un sens. Par exemple un nombre d’habitants, un nombre de ménages, un nombre d’automobiles. Ce quantités doivent être représentées par des figures (cercles, carrés, …) dont la surface est proportionelle au stock afin que l’oeil du lecteur puisse les aditionner visuellement.\nDans le package mapsf, on réalise ce type de carte à l’aide de la fonction mf_map()en lui donnant le paramètre type=\"prop\".\nOn va tenter à titre d’exemple de représenter la distribution des actifs et du taux de chômage dans le Val de Marne:\n\nmap_iris_94 &lt;- map_iris %&gt;% filter(dep_code==\"94\")\nmap_com_94 &lt;- map_com %&gt;% filter(dep_code==\"94\")\nmap_dep_94 &lt;- map_dep %&gt;% filter(dep_code==\"94\")\nmap_iris_94$ACT&lt;-map_iris_94$CHO+map_iris_94$EMP\n\n\nCarte de stock minimale\nLes instructions minimales sont les suivantes :\n\n# Trace les contours des communes\nmf_map(x= map_iris_94, \n       type = \"base\")\n\n# Ajoute le nombre d'actifs\nmf_map(x =map_iris_94, \n      type =\"prop\",\n      var = \"ACT\",\n      add=TRUE)\n\n13 'NA' values are not plotted on the map.\n\n\n\n\n\nMais le résultat est peu satisfaisant car les cercles sont trop grands. Il faut en pratique toujours effectuer un réglage de ceux-ci avec l’instruction inches=\n\n\nCarte de stock habillée\n\nmf_theme(\"agolalight\")\nmf_map(map_iris_94, type = \"base\",  \n       col = \"lightyellow\",border=\"gray80\", lwd=0.3)\nmf_map(map_com_94, type = \"base\", \n       col = NA,border=\"black\",lwd=1,add = TRUE)\n\nmf_map(map_iris_94, var = \"ACT\",type = \"prop\",\n  inches = 0.1, col = \"red\",leg_pos = \"left\",  \n  leg_title = \"Nombre d'actifs\", add=TRUE)\n\n13 'NA' values are not plotted on the map.\n\nmf_layout(title = \"Distribution des actifs en 2019\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-choroplèthe",
    "href": "22-CARTO-mapsf.html#carte-choroplèthe",
    "title": "Carto. statique",
    "section": "Carte choroplèthe",
    "text": "Carte choroplèthe\nUne carte choroplèthe ou d’intensité représente un phénomène relatif dont la somme n’a pas de sens. Par exemple, il serait absurde d’aditionner les % de logement HLM des IRIS du Val de Marne. Ces variables d’intensité caractèrisent donc l’état général d’une zone (choros) et elles vont être représentées par une couleur appliquée à toute la surface de la zone, d’où leur nom de cartes choroplèthes.\nLa fonction du package mapsf adaptée aux variables d’intensité est la fonction mf_map()munie du paramètre type = \"choro\".\nOn va prendre l’exemple du taux de chômage\n\nmap_iris_94$TxCHO&lt;-100*map_iris_94$CHO/map_iris_94$ACT\n\n\nCarte choroplèthe minimale\nSi on ne précise rien, la carte est réalisée à l’aide de la palette par défaut avec un découpage des classes en quantiles (effectifs égaux).\n\n# Carte choroplèthe\nmf_map(\n  x = map_iris_94, \n  var = \"TxCHO\",\n  type = \"choro\")\n\n\n\n\n\n\nChoix d’une palette\nPlusieus packages proposent des palettes de couleurs. On prendra ici l’exemple du package RcolorBrewer. On commence par examiner la liste des palettes disponibles.\n\nlibrary(RColorBrewer)\ndisplay.brewer.all()\n\n\n\n\nPuis on créer une palette personelle en indiquant son nom et le nombre de classes. Ici on choisit la palette orange-vert mais on va l’inverser pour que l’orange corresponde aux valeurs fortes\n\ndisplay.brewer.pal(n = 10,name = \"RdYlGn\")\n\n\n\nmypal&lt;-rev(brewer.pal(n = 10,name = \"RdYlGn\"))\n\n\n\nCarte choroplèthe habillée\nOn peut arriver à une carte beaucoup plus satisfaisante en contrôlant l’ensemble des paramètres de couleur et de découpage des classes. Puis en superposant les contours de communes au dessus de la carte des IRIS pour faciliter le repérage.\n\n# Choisir les classes et la palette\nmybreaks = c(0, 4, 6, 8, 10, 12, 14, 16, 18,20,30)\n\n# Tracer la carte choroplèthe\nmf_map( map_iris_94, var = \"TxCHO\",type = \"choro\",\n  breaks = mybreaks,pal = mypal,\n  border=\"white\",col_na = \"gray80\",\n leg_title = \"% chômeurs\",\n leg_val_rnd = 0)\n# Ajouter les contours des communes\nmf_map(map_com_94, type = \"base\", col = NA,\n       border=\"black\",lwd=1,add = TRUE)\n# Ajouter un cadre, un titre et des sources\nmf_layout(title = \"Taux de chômage en 2019\", \n          frame = TRUE,\n          credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#carte-stock-choroplèthe",
    "href": "22-CARTO-mapsf.html#carte-stock-choroplèthe",
    "title": "Carto. statique",
    "section": "Carte stock + choroplèthe",
    "text": "Carte stock + choroplèthe\nMais on peut aussi utiliser le type prop_choro\n\nmf_theme(\"agolalight\")\nmybreaks = c(0, 4, 6, 8, 10, 12, 14, 16, 18,20,30)\n\nmf_map(map_iris_94, type = \"base\",  \n       col = \"gray80\",border=\"white\", lwd=0.3)\nmf_map(map_com_94, type = \"base\", \n       col = NA,border=\"white\",lwd=1,add = TRUE)\nmf_prop_choro( x = map_iris_94,  var = c(\"ACT\", \"TxCHO\"), \n  inches = 0.08, col_na = \"grey\", pal=mypal,\n  breaks = mybreaks, nbreaks = 4, lwd = 0.1,\n  leg_pos = c(\"right\", \"left\"),leg_val_rnd = c(0,0),\n  leg_title = c(\"nb. actifs\", \"% chômeurs\"),\n  add = TRUE)\n\n13 'NA' values are not plotted on the map.\n\nmf_layout(title = \"Les actifs au chômage dans le Val de Marne au RP 2019\",\n        frame = TRUE, credits = \"Sources : IGN et INSEE\")"
  },
  {
    "objectID": "22-CARTO-mapsf.html#typologie",
    "href": "22-CARTO-mapsf.html#typologie",
    "title": "Carto. statique",
    "section": "Typologie",
    "text": "Typologie\nOn se propose d’examiner le cas d’une variable qualitative résultant d’une classification ascendante hiérarchique. On travaille cette fois-ci à l’échelle des communes\n\nExtraction du tableau de contingence\nOn élimine la géométrie et on extrait le tableau de contingence des actifs :\n\n# Extrait les colonnes utiles\ntab&lt;-map_com %&gt;% st_drop_geometry() %&gt;% select(com_code, CHO, DIV, EMP, ETU, RET) %&gt;% filter(is.na(CHO)==F)\n\n\n# Transforme en matrice de % en ligne\nmat&lt;-as.matrix(tab[,-1])\nrownames(mat)&lt;-tab$com_code\n\nmatpct&lt;-100*prop.table(mat,1)\n\n\n\nCalcul de l’ACP et de la CAH\n\n# Calcule l'AFC puis la CAH\nlibrary(FactoMineR)\nacp&lt;-PCA(matpct)\n\n\n\n\n\n\ncah&lt;-HCPC(acp,nb.clust =4)\n\n\n\n\n\n\n\n\n\n# Récupère les résultats\ntab$typo &lt;- cah$data.clust$clust\n\n# analyse les profils\ntabres&lt;-cah$data.clust\nplot.catdes(catdes(tabres,6,proba = 1),level = 1,barplot = T)\n\n\n\n\n\n\n\n\n\nCartographie des résultats\n\n# Ajoute la typo au fonds de carte\nmap_com_typo &lt;-map_com %&gt;% select(com_code,com_name, geometry) %&gt;%\n                                left_join(tab)\n\nJoining with `by = join_by(com_code)`\n\n# Transforme la typo en facteur\nmap_com_typo$typoqual&lt;-as.factor(map_com_typo$typo)\nlevels(map_com_typo$typoqual) &lt;- c(\"(1) Chômeurs et inactifs\",\n                                   \"(2) Profil moyen\",\n                                   \"(3) Actifs en emploi\",\n                                   \"(4) Etudiants et retraités\")\n\n# Carte de typologie\nmf_theme(\"darkula\")\nmf_map(map_com_typo, \n       type = \"typo\",\n       var = \"typoqual\",\n       pal= c(\"orange\",\"lightyellow\",\"lightgreen\",\"lightblue\"),\n       leg_title = \"Spécificités\",\n       col_na = \"gray70\",\n       leg_no_data = \"Données manquantes\")\n# Ajoute les contours des départements\nmf_map(map_dep,  type = \"base\", \n       col = NA,lwd=2,\n       add = TRUE)\n# Ajoute les noms des départements\nmf_label(map_dep, \n         var=\"dep_name\",\n         cex=0.8, \n         col=\"black\",\n         overlap = FALSE)\n\nmf_layout(title = \"Typologie des profls activités des communes de Paris et Petite Couronne en 2019\",\n        frame = TRUE, credits = \"Sources : IGN et INSEE RP 2019\",\n        arrow = F\n        )"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html",
    "href": "11-API-OPENDATASOFT.html",
    "title": "Pratique des API",
    "section": "",
    "text": "Le but de ce chapitre n’est pas d’apprendre en détail l’ensemble des possibilités qu’offrent les API pour des utilisateurs avancés, mais de fournir aux étudiants en data mining un certain nombre de solutions simples (mais efficaces) pour extraire des données de façon interactive et assurer leur mise à jour régulière.\nOn charge les packages utiles :\nknitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE, error=FALSE)\n\n## Affichage de tableaux\nlibrary(knitr)\n\n## Requêtes web\nlibrary(httr)\nlibrary(jsonlite)\n\n## Tidyverse & co\nlibrary(dplyr, warn.conflicts = T, quietly = T)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#choix-dune-api",
    "href": "11-API-OPENDATASOFT.html#choix-dune-api",
    "title": "Pratique des API",
    "section": "Choix d’une API",
    "text": "Choix d’une API\nLa première étape consiste à choisir l’API qui nous intéresse parmi plus de 600.\n\nLe site public.opendatasoft\nNous allons centrer notre chapitre sur le site public.opendatasoft qui permet d’accèder à des centaines d’API à l’aide de requêtes normalisées. Sans apprendre en détail le fonctionnement de cette API, on va montrer comment créer de petites fonctions facilitant le travail d’exportation des variables ou des données.\nOn peut se rendre sur le site pour parcourir les API proposées en allant à l’adresse : https://public.opendatasoft.com\n\n\n\n\n\n\n\nCatalogue des API\nPlutôt que de pacourir le site web, on peut télécharger le catalogue général des bases de données du site public.opendatasoft … en se servant d’une requête API\n\nx&lt;-GET('https://public.opendatasoft.com/api/datasets/1.0/search/?q=&rows=1000&start=0')\ny&lt;-fromJSON(rawToChar((x$content)))\ncat&lt;-y$datasets$metas\nrow.names(cat)&lt;-y$datasets$datasetid\nkable(head(cat[,c(12,1,6,7,8)]),row.names = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\nkeyword\ndomain\nmodified\nlicense\npublisher\n\n\n\n\ninventaire-matieres-dechets-radioactifs\nRadioactif, Déchets , Nucléaire\npublic\n2018-10-25T22:08:37+00:00\nOpen License v1.0\nANDRA\n\n\nlinked-open-vocabularies-classes\nSemantic , Linked Data, Vocabulary , Ontology\npublic\n2018-09-17T09:59:42+00:00\nCC BY 4.0\nOntology Engineering Group - UPM\n\n\naire-geographique-des-igp\nIGP\npublic\n2022-08-10T08:02:00+00:00\nOpen License v1.0\nInstitut National de l’Origine et de la qualité\n\n\nliste-des-etablissements-recenses-dans-la-base-openccam\nEtablissement, FINESS , OpenCCAM\npublic\n2019-04-23T09:20:45+00:00\nOpen License v1.0\nAssurance Maladie\n\n\nunix_domaine_professionnel_v324_utf8\nNULL\npublic\n2020-01-29T13:16:48+00:00\nOpen License v1.0\nPôle Emploi\n\n\ngeoref-switzerland-bezirk-millesime\nSwitzerland, swisstopo , district , Bezirk , Suisse , Schweiz\npublic\n2023-09-07T11:39:30+00:00\nOpendata.swiss BY ASK\nOpendatasoft\n\n\n\n\n\nOn a donc récupéré un tableau qui comporte 605 lignes correspondant à 605 bases de données. Le nom des lignes du tableau indique le code de la base de données que l’on va utiliser ensuite dans les requêtes.\n\n\nChoix d’un tableau de données\nOn suppose que le choix s’est porté sur la base de données dont le nom de code est prix-des-carburants-j-1\n\n\n\n\n\nL’onglet information nous indique qu’il s’agit d’un site produit par le minstère de l’économie et des finances pour faciliter l’accès en temps réel au prix des carburants dans les stations services. Le but est d’informer les conosmmateurs des stations les moins chères à proximité de son domicile afin de stimuler la concurrence et faire baisser les prix.\nIl est indiqué que la base se limite aux prix des douze derniers mois mais nous avons pu vérifier qu’on trouve en fait des données sur plus de trois ans.\n\n\nListe des variables\nAvant de télécharger les données, on regarde précisément la liste des variables disponibles. On peut le faire sur le site web en parcourant les onglets. Mais il est également possible de lancer une requête pour connaître les variables du tableau que l’on va télécharger ainsi que les variables pouvant servir de “facettes” c’est-à-dire permettant d’effectuer des requêtes.\n\ntab&lt;-\"prix-des-carburants-j-1\"\nurl&lt;-paste(\"https://public.opendatasoft.com/api/v2/catalog/datasets/\",tab,\"?\",sep=\"\")\nx&lt;-GET(url)\ny&lt;-fromJSON(rawToChar(x$content))\nvar&lt;-y$dataset$fields\n\nhead(var)\n\n            name description annotations.facet annotations.multivalued\n1             id          NA                NA                    &lt;NA&gt;\n2             cp          NA              TRUE                    &lt;NA&gt;\n3            pop          NA              TRUE                    &lt;NA&gt;\n4        address          NA                NA                    &lt;NA&gt;\n5   com_arm_name          NA              TRUE                    &lt;NA&gt;\n6 automate_24_24          NA              TRUE                    &lt;NA&gt;\n  annotations.facetsort annotations.timeserie_precision annotations.unit\n1                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n2                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n3                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n4                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n5                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n6                  &lt;NA&gt;                            &lt;NA&gt;             &lt;NA&gt;\n  annotations.decimals\n1                   NA\n2                   NA\n3                   NA\n4                   NA\n5                   NA\n6                   NA\n                                                      label type\n1                                               Identifiant text\n2                                               Code Postal text\n3                                                  Présence text\n4                                                   Adresse text\n5 Nom Officiel Commune / Arrondissement Municipal Majuscule text\n6                                            Automate 24-24 text\n\n\nOn extrait du tableau les colonnes qui fournissent le nom des variables, leur définition et leur type\n\nvar &lt;- var  %&gt;% select(name, label, type)\nkable(var)\n\n\n\n\n\n\n\n\n\nname\nlabel\ntype\n\n\n\n\nid\nIdentifiant\ntext\n\n\ncp\nCode Postal\ntext\n\n\npop\nPrésence\ntext\n\n\naddress\nAdresse\ntext\n\n\ncom_arm_name\nNom Officiel Commune / Arrondissement Municipal Majuscule\ntext\n\n\nautomate_24_24\nAutomate 24-24\ntext\n\n\ntimetable\nTimetable\ntext\n\n\nfuel\nCarburant\ntext\n\n\nshortage\nRupture\ntext\n\n\nupdate\nMise à jour\ndatetime\n\n\nprice_gazole\nPrix Gazole\ndouble\n\n\nprice_sp95\nPrix SP95\ndouble\n\n\nprice_sp98\nPrix SP98\ndouble\n\n\nprice_gplc\nPrix GPLc\ndouble\n\n\nprice_e10\nPrix E10\ndouble\n\n\nprice_e85\nPrix E85\ndouble\n\n\nservices\nServices\ntext\n\n\nbrand\nMarque\ntext\n\n\nname\nNom\ntext\n\n\ngeo_point\nGeo Point\ngeo_point_2d\n\n\ncom_arm_code\nCode officiel commune ou arrondissement\ntext\n\n\nepci_code\nCode Officiel EPCI\ntext\n\n\nepci_name\nNom Officiel EPCI\ntext\n\n\ndep_code\nCode Officiel Département\ntext\n\n\ndep_name\nNom Officiel Département\ntext\n\n\nreg_code\nCode Officiel Région\ntext\n\n\nreg_name\nNom Officiel Région\ntext\n\n\n\n\n\nOn peut transformer le programme que l’on vient d’executer en fonction pour un usage plus simple :\n\nget_variables&lt;-function(idtab = \"prix-des-carburants-j-1\") {\n  url&lt;-paste(\"https://public.opendatasoft.com/api/v2/catalog/datasets/\",idtab,\"?\",sep=\"\")\n  x&lt;-GET(url)\n  y&lt;-fromJSON(rawToChar((x$content)))\n  var&lt;-y$dataset$fields\n  var &lt;- var %&gt;% select(name, label, type)\n  return(var)\n}\n\nOn peut désormais appliquer notre fonction sur n’importe quel autre tableau du catalogue. Par exemple, si on choisit le tableau qualite_de-lair-france on obtient la liste de variables suivante :\n\nvar&lt;-get_variables(\"qualite-de-lair-france\")\nkable(var)\n\n\n\n\nname\nlabel\ntype\n\n\n\n\ncountry\nCountry Code\ntext\n\n\ncity\nCity\ntext\n\n\nlocation\nLocation\ntext\n\n\ncoordinates\nCoordinates\ngeo_point_2d\n\n\nmeasurements_parameter\nPollutant\ntext\n\n\nmeasurements_sourcename\nSource Name\ntext\n\n\nmeasurements_unit\nUnit\ntext\n\n\nmeasurements_value\nValue\ndouble\n\n\nmeasurements_lastupdated\nLast Updated\ndatetime\n\n\ncountry_name_en\nCountry Label\ntext"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#récupération-des-données",
    "href": "11-API-OPENDATASOFT.html#récupération-des-données",
    "title": "Pratique des API",
    "section": "Récupération des données",
    "text": "Récupération des données\nPour des utilisateurs non spécialiste, il est difficile de lancer une requête complexe qui suppose une maîtrise avancée des API et des protocoles de requête SOAP et REST. Nous allons opter ici pour une stratégie pragmatique (mais efficace) qui consiste à :\n\nUtiliser l’interface public.opendatasoft pour rédiger une requête\nRécupérer le lien de téléchargement\nTélécharger les données correspondant à la requête\nEffectuer les opérations de nettoyage des données et réaliser un graphique\nModifier le lien et effectuer à nouveau le étapes 3 et 4\nConstruire une fonction paramétrique de téléchargement + nettoyage + visualisation …\n\nPour illustrer cette stratégie, nous allons essayer de créer dans R une fonction automatisée qui télécharge le prix du carburant d’une commune et produit un graphique montrant son évolution au cours du temps dans les dfférentes stations. Nous allons ainsi essayer de reconstituer une application assez proche de celle du ministère de l’économie intitulée “essence pas cher”.\n\n\n\nEssence pas cher\n\n\nNous ne chercherons toutefois pas à obtenir uniquement le dernier prix en date des stations mais plutôt à voir lesquelles sont les plus ou les mons chers sur une période de quelques années.\n\n1. Rédaction d’une requête sur public opendatasoft\nOn utilise les filtres de l’interface pour sélectionner la commune cible à l’aide de son code postal (ex. 94370 = Sucy-en-Brie) et du type carburant (ex. Gazole) :\n\n\n\nFiltres\n\n\n\n\n2. Récupération du lien de téléchargement\nUne fois terminée la mise en place des filtres, on se déplace vers la fenêtre “Export” et on choisit le type de format de sortie que l’on souhaite obtenir. Nous pourrions obtenir des fichiers au format texte (.csv) ou tableur (.xls) mais nous allons adopter ici le format .json qui est plus universel dans le domaine de la data science et qui simplifie les transferts de données entre utilisateurs de différents langages de programmation tels que R ou Python.\nUn click de souris sur le lien nous permet de récupérer l’URL de téléchargement :\n\n\n\nURL\n\n\nMême si certains caractères spéciaux sont difficiles à comprendre comme %3A ou %22 on devine assez facilement la fonction des différents segments de la chaine de caractère qui constitue l’URL de requête :\n\nadresse du site web opendatasoft : https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/\nchoix de la base de données : prix-des-carburants-j-1\nformat d’export et langue : exports/json?lang=fr\nselection du carburant : &refine=fuel%3A%22Gazole%22\nselection de la commune par son code postal : &qv1=(94370)\nfuseau horaire (pour dater la requête) : &timezone=Europe%2FParis\n\n\n\n3. Recupération des données à partir de l’URL\nNous pouvons maintenant rédiger un petit programme très simple qui va récupérer les données à partir de ce lien\n\nlink&lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(94370)&timezone=Europe%2FParis\"\ny&lt;-fromJSON(link)\nhead(y)\n\n        id    cp pop                     address com_arm_name automate_24_24\n1 94370008 94370   R 63/71 AV DU GENERAL LECLERC SUCY-EN-BRIE            Oui\n2 94370007 94370   R     13 Rue Maurice Berteaux SUCY-EN-BRIE            Non\n3 94370008 94370   R 63/71 AV DU GENERAL LECLERC SUCY-EN-BRIE            Oui\n4 94370003 94370   R              1 Rue de Paris SUCY-EN-BRIE            Oui\n5 94370003 94370   R              1 Rue de Paris SUCY-EN-BRIE            Oui\n6 94370008 94370   R 63/71 AV DU GENERAL LECLERC SUCY-EN-BRIE            Oui\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               timetable\n1 {\"Dimanche\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Jeudi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Lundi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mardi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mercredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Samedi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Vendredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}}\n2 {\"Dimanche\": {\"fermeture\": \"22.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Jeudi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Lundi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Mardi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Mercredi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Samedi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}, \"Vendredi\": {\"fermeture\": \"23.00\", \"ouvert\": 1, \"ouverture\": \"06.00\"}}\n3 {\"Dimanche\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Jeudi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Lundi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mardi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mercredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Samedi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Vendredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}}\n4                                                                                                                                                                                                                                                                                                                     {\"Dimanche\": {\"ouvert\": 1}, \"Jeudi\": {\"ouvert\": 1}, \"Lundi\": {\"ouvert\": 1}, \"Mardi\": {\"ouvert\": 1}, \"Mercredi\": {\"ouvert\": 1}, \"Samedi\": {\"ouvert\": 1}, \"Vendredi\": {\"ouvert\": 1}}\n5                                                                                                                                                                                                                                                                                                                     {\"Dimanche\": {\"ouvert\": 1}, \"Jeudi\": {\"ouvert\": 1}, \"Lundi\": {\"ouvert\": 1}, \"Mardi\": {\"ouvert\": 1}, \"Mercredi\": {\"ouvert\": 1}, \"Samedi\": {\"ouvert\": 1}, \"Vendredi\": {\"ouvert\": 1}}\n6 {\"Dimanche\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Jeudi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Lundi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mardi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Mercredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}, \"Samedi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"08.00\"}, \"Vendredi\": {\"fermeture\": \"21.00\", \"ouvert\": 1, \"ouverture\": \"07.00\"}}\n               fuel                   shortage                    update\n1            Gazole E85, SP95, GPLc, E10, SP98 2022-10-24T00:01:00+02:00\n2 Gazole, E10, SP98      SP95, E85, SP95, GPLc 2022-11-08T00:01:00+01:00\n3 Gazole, E10, SP98            SP95, E85, GPLc 2022-12-06T00:01:00+01:00\n4 Gazole, E10, SP98                       SP95 2022-12-21T17:40:00+01:00\n5 Gazole, E10, SP98                       SP95 2023-01-07T02:46:00+01:00\n6 Gazole, E10, SP98            SP95, E85, GPLc 2023-01-18T00:01:00+01:00\n  price_gazole price_sp95 price_sp98 price_gplc price_e10 price_e85\n1     0.001818         NA         NA         NA        NA        NA\n2     0.001847         NA   0.001679         NA  0.001569        NA\n3     0.001833         NA   0.001759         NA  0.001649        NA\n4     0.001778         NA   0.001691         NA  0.001611        NA\n5     0.001915         NA   0.001903         NA  0.001823        NA\n6     0.001961         NA   0.001970         NA  0.001882        NA\n                                                                                                                                                                                                                              services\n1                     Boutique alimentaire, Boutique non alimentaire, Station de gonflage, Carburant additivé, Lavage automatique, Lavage manuel, Vente de gaz domestique (Butane, Propane), DAB (Distributeur automatique de billets)\n2 Boutique alimentaire, Boutique non alimentaire, Restauration à emporter, Vente de fioul domestique, Station de gonflage, Carburant additivé, Lavage automatique, Vente de gaz domestique (Butane, Propane), Wifi, Automate CB 24, 24\n3                     Boutique alimentaire, Boutique non alimentaire, Station de gonflage, Carburant additivé, Lavage automatique, Lavage manuel, Vente de gaz domestique (Butane, Propane), DAB (Distributeur automatique de billets)\n4                                                                                                                                                                                                                                 NULL\n5                                                                                                                                                                                                                                 NULL\n6                     Boutique alimentaire, Boutique non alimentaire, Station de gonflage, Carburant additivé, Lavage automatique, Lavage manuel, Vente de gaz domestique (Butane, Propane), DAB (Distributeur automatique de billets)\n         brand              name geo_point.lon geo_point.lat com_arm_code\n1         &lt;NA&gt;              &lt;NA&gt;            NA            NA         &lt;NA&gt;\n2        Total       SARL DURMUS       2.51743      48.77333        94071\n3         &lt;NA&gt;              &lt;NA&gt;            NA            NA         &lt;NA&gt;\n4 Esso Express ESSO PETIT MARAIS       2.49956      48.77306        94071\n5 Esso Express ESSO PETIT MARAIS       2.49956      48.77306        94071\n6         &lt;NA&gt;              &lt;NA&gt;            NA            NA         &lt;NA&gt;\n  epci_code                epci_name dep_code     dep_name reg_code\n1      &lt;NA&gt;                     &lt;NA&gt;     &lt;NA&gt;         &lt;NA&gt;     &lt;NA&gt;\n2 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n3      &lt;NA&gt;                     &lt;NA&gt;     &lt;NA&gt;         &lt;NA&gt;     &lt;NA&gt;\n4 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n5 200054781 Métropole du Grand Paris       94 Val-de-Marne       11\n6      &lt;NA&gt;                     &lt;NA&gt;     &lt;NA&gt;         &lt;NA&gt;     &lt;NA&gt;\n       reg_name\n1          &lt;NA&gt;\n2 Île-de-France\n3          &lt;NA&gt;\n4 Île-de-France\n5 Île-de-France\n6          &lt;NA&gt;\n\n\nA la différence de la méthode GET vue au chapitre précédent, nous récupérons directement le fichier de données sans avoir besoin d’effectuer des transformations de type RawToChar. C’est donc beaucoup plus simple mais, en contrepartie, nous perdons toute une série d’informations qu’apportait la procédure dans les règles de l’art (date de téléchargement, messages d’erreur, version des données, etc.).\n\n\n4. Nettoyage des données\nNous procédons ensuite à un petit nettoyage pour ne garder que les variables utiles :\n\nnames(y)\n\n [1] \"id\"             \"cp\"             \"pop\"            \"address\"       \n [5] \"com_arm_name\"   \"automate_24_24\" \"timetable\"      \"fuel\"          \n [9] \"shortage\"       \"update\"         \"price_gazole\"   \"price_sp95\"    \n[13] \"price_sp98\"     \"price_gplc\"     \"price_e10\"      \"price_e85\"     \n[17] \"services\"       \"brand\"          \"name\"           \"geo_point\"     \n[21] \"com_arm_code\"   \"epci_code\"      \"epci_name\"      \"dep_code\"      \n[25] \"dep_name\"       \"reg_code\"       \"reg_name\"      \n\ndon &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\nIl y a toutefois une mauvaise surprise … les données semblent erronées à partir d’une certaine date\n\nggplot(don) +aes(x=update, y=price, col=address) + geom_point()\n\n\n\n\nEn fait … les chiffres qui sont fournis après le 26 mars ont été divisés mystérieusement par 1000. Il faut donc corriger ce problème :\n\nlibrary(ggplot2)\ndon&lt;-don %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\nggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\n\n\n\nOn note qu’il este une valeur aberrante mais sinon il est désormais possible de bien suivre l’évolution des prix au cours des trois dernières années et de repérer quelles est la station la moins chèr aux différentes dates.\n\n\n5. Changement de lien\nEssayons maintenant de reprendre l’ensemble de notre programme en changeant juste de commune dans le lien initial. On va ici soigner la rédaction du programme car nous comptons ensuite le transformer en fonction\nOn remplace le code postal de Sucy-en-Brie (94370) par celui d’Ivry-sur-Seine(94200).\n\n# Choix du lien (changement du code postal)\nlink&lt;-\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(94200)&timezone=Europe%2FParis\"\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ndon &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ndon&lt;-don %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\n# Réalisation d'un graphique\nggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\n\n\n\n\n\n6. Rédaction d’une Fonction\nOn peut maintenant écrire une fonction qui ne va dépendre que du code postal et va fournir en sortie le tableau de données. Tout ce que nous avons à faire est de modifier le lien en fonction du code postal qui sera le paramètre de la fonction.\nPour cela nous utilisons la commande R pasteO()qui permet de coller des chaînes de caractères sans ajouter d’expaces. Ici nous recollons le début de l’URL, le code de la commune que nous avons modifié et la fin de l’URL.\n\ngazole_tab &lt;- function(code=\"94370\") { \n# Choix du lien (changement du code postal)\nlink&lt;-paste0(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(\", code,\")&timezone=Europe%2FParis\")\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ntab &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ntab&lt;-tab %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\nreturn(tab)\n\n}\n\nPour tester notre fonction gazole_tab(), on prend en exemple une nouvelle commune, par exemple Saint-Maur des Fossés (94100) :\n\nres&lt;-gazole_tab(\"94100\")\nhead(res)\n\n              name            address     update price price_OK\n1             &lt;NA&gt;   57 BD DE CRETEIL 2021-02-18 1.499    1.499\n2 Carrefour Market    57, Rue Delenue 2021-02-18 1.366    1.366\n3             &lt;NA&gt;  29 bvd de créteil 2021-02-18 1.452    1.452\n4        ESSO FOCH 99/101 Avenue Foch 2021-02-18 1.366    1.366\n5 Carrefour Market    57, Rue Delenue 2021-02-19 1.371    1.371\n6        ESSO FOCH 99/101 Avenue Foch 2021-02-19 1.371    1.371\n\n\nMais on pourrait aussi faire une fonction gazole_graph()qui renvoie non pas le tableau mais le graphique :\n\ngazole_graph &lt;- function(code=\"94370\") { \n# Choix du lien (changement du code postal)\nlink&lt;-paste0(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(\", code,\")&timezone=Europe%2FParis\")\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ndon &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ndon&lt;-don %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\n# Réalisation d'un graphique\ngraph&lt;-ggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\nreturn(graph)\n\n}\n\nOn teste la fonction sur Saint-Maur des Fossés (94100) :\n\ngazole_graph(\"94100\")\n\n\n\n\nMais le plus intéressant est de faire une fonction unique gazole()qui permet de renvoyer à la fois le tableau et le graphique en indiquant en sortie une liste d’objets comprenant à la fois le tableau (objet de type data.frame) et le graphique (objet de type ggplot2).\n\ngazole &lt;- function(code=\"94370\") { \n# Choix du lien (changement du code postal)\nlink&lt;-paste0(\"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/prix-des-carburants-j-1/exports/json?lang=fr&refine=fuel%3A%22Gazole%22&qv1=(\", code,\")&timezone=Europe%2FParis\")\n\n# Importation des données\ny&lt;-fromJSON(link)\n\n# Selection des variables\ntab &lt;- y %&gt;% select(name,address, update, price = price_gazole ) %&gt;% \n  mutate(update =as.Date(update)) %&gt;%\n  arrange(update)\n\n# Nettoyage des erreurs principales\ntab&lt;-tab %&gt;%  mutate(price_OK = case_when(price ==0 ~ NA,\n                             price &lt; 1 ~ price*1000,\n                             TRUE ~ price))\n\n# Réalisation d'un graphique\ngraph&lt;-ggplot(don) +aes(x=update, y=price_OK, col=address) + geom_point()\n\nreturn(list(\"tab\"=tab, \"graph\"=graph))\n\n}\n\nIl suffit maintenant d’executer une seule fois la fonction (un seul appel de l’API) pour pouvoir ensuite au choix utiliser le tableau ou afficher le graphique.\n\nres&lt;-gazole(\"94100\")\nhead(res$tab)\n\n              name            address     update price price_OK\n1             &lt;NA&gt;   57 BD DE CRETEIL 2021-02-18 1.499    1.499\n2 Carrefour Market    57, Rue Delenue 2021-02-18 1.366    1.366\n3             &lt;NA&gt;  29 bvd de créteil 2021-02-18 1.452    1.452\n4        ESSO FOCH 99/101 Avenue Foch 2021-02-18 1.366    1.366\n5 Carrefour Market    57, Rue Delenue 2021-02-19 1.371    1.371\n6        ESSO FOCH 99/101 Avenue Foch 2021-02-19 1.371    1.371\n\nres$graph"
  },
  {
    "objectID": "11-API-OPENDATASOFT.html#conclusion",
    "href": "11-API-OPENDATASOFT.html#conclusion",
    "title": "Pratique des API",
    "section": "Conclusion",
    "text": "Conclusion\nCe chapitre a permis de combiner trois apprentissages fondamentaux du data mining qui seront repris ensuie à plusieurs reprises :\n\nUtiliser des API pour récupérer directement ses données sans effectuer de téléchargement “à la main”.\nNettoyer les données reçues avant de les utiliser et automatiser autant que possible les procédures de nettoyages.\nCréer ses propres fonctions pour automatiser les tâches de récupération des données, nettoyage et production de tableaux ou graphiques."
  }
]